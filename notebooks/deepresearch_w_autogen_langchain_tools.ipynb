{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bc3cfa",
   "metadata": {},
   "source": [
    "# Orchestrate Multiple-Agents for High-Quality Research with AutoGen and LangChain Tools\n",
    "\n",
    "This notebook showcases how to harness the combined power of **AutoGen** and **LangChain** tools to automate and elevate deep research workflows. At its core, the system coordinates a network of specialized agents‚Äîeach executing a distinct role in the research and report generation workflow. Together, these agents collect data, analyze findings, and produce polished, insight-driven reports.\n",
    "\n",
    "\n",
    "[Open in Colab](https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb) <a href=\"https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "## üß† Agent Roles Overview\n",
    "\n",
    "- **üß≠ Planner Agent**  \n",
    "  Defines the research scope, objectives, and key questions.  \n",
    "  ‚Üí Anchors the process by structuring it around a well-defined `__TASK_QUERY`.\n",
    "\n",
    "- **üîç Researcher Agent**  \n",
    "  Gathers information using tools like `wiki_search` and `duckduckgo_search`.  \n",
    "  ‚Üí Supplies the system with relevant, factual data.\n",
    "\n",
    "- **üß™ Critic Agent**  \n",
    "  Reviews the research plan, gathered evidence, and drafted reports.  \n",
    "  ‚Üí Provides feedback to enforce analytical rigor and clarity.\n",
    "\n",
    "- **‚úçÔ∏è Editor Agent**  \n",
    "  Refines the final report's language, structure, and presentation.  \n",
    "  ‚Üí Ensures clarity, polish, and alignment with stakeholder expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "%pip install -qU ipykernel\n",
    "%pip install -qU autogen-agentchat\n",
    "%pip install -qU autogen-ext\n",
    "\n",
    "%pip install -qU loguru\n",
    "\n",
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-community\n",
    "%pip install -qU wikipedia\n",
    "%pip install -qU lxml\n",
    "%pip install -qU ddgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %aimport -langchain_community\n",
    "# Automatically reload modules before executing code\n",
    "\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import asyncio\n",
    "import sys\n",
    "\n",
    "# import logging\n",
    "# logger = logging.getLogger(\"\")\n",
    "\n",
    "\n",
    "# # Remove all existing handlers\n",
    "# for handler in logger.handlers[:]:\n",
    "#     logger.removeHandler(handler)\n",
    "\n",
    "# REMOVE ALL EXISTING HANDLERS for LOGURU\n",
    "if len(logger._core.handlers) > 1:\n",
    "    logger.configure(handlers=[])\n",
    "\n",
    "logger.add(\n",
    "    sys.stderr,\n",
    "    format=\"{time:HH:mm:ss:SSS} | {level} | {name}:{line} | {message}\",\n",
    "    level=\"INFO\",\n",
    "    colorize=True,\n",
    ")\n",
    "\n",
    "# Configure file logging with better settings\n",
    "\n",
    "# notebook_dir = Path.cwd()\n",
    "# log_file = notebook_dir / \"logs\" / \"llm_execution.log\"\n",
    "# log_file.parent.mkdir(exist_ok=True)\n",
    "# logger.add(\n",
    "#     log_file,\n",
    "#     format=\"{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} | {message}\",\n",
    "#     level=\"DEBUG\",\n",
    "#     rotation=\"10 MB\",\n",
    "#     retention=\"7 days\",\n",
    "#     compression=\"zip\",\n",
    "#     enqueue=True,\n",
    "# )\n",
    "logger.info(f\"‚úÖ Logging configured - File: {log_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef193373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "\n",
    "# Confirm the API key is set\n",
    "assert os.environ[\"GEMINI_API_KEY\"], \"GEMINI_API_KEY is not set\"\n",
    "assert os.environ[\"GEMINI_MODEL_NAME\"], \"GEMINI_MODEL_NAME is not set\"\n",
    "assert os.environ[\"GEMINI_BASE_URL\"], \"GEMINI_BASE_URL is not set\"\n",
    "assert os.environ[\"RATE_LIMIT_GEMINI_RPM\"], \"RATE_LIMIT_GEMINI_RPM is not set\"\n",
    "assert os.environ[\"RATE_LIMIT_GEMINI_RPD\"], \"RATE_LIMIT_GEMINI_RPD is not set\"\n",
    "\n",
    "\n",
    "model_info = ModelInfo(\n",
    "    vision=True,\n",
    "    function_calling=True,\n",
    "    json_output=True,\n",
    "    family=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    structured_output=True,\n",
    ")\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    base_url=os.environ[\"GEMINI_BASE_URL\"],\n",
    "    model_info=model_info,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, json, os\n",
    "import tenacity\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.messages import StopMessage\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "from ddgs import DDGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent Tools\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "# Wiki Search Tool\n",
    "wiki_api = WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=2000)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api)\n",
    "\n",
    "\n",
    "def wiki_search(q: str) -> dict:\n",
    "    \"\"\"Return structured output including text and source.\"\"\"\n",
    "    try:\n",
    "        result = wiki_tool.run(q)\n",
    "        return {\"text\": result, \"source\": \"Wikipedia\"}\n",
    "    except Exception as e:\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None}\n",
    "\n",
    "# DuckDuckGo Search Tool\n",
    "def duckduckgo_search(q: str) -> dict:\n",
    "    \"\"\"Search the web using DuckDuckGo for information.\"\"\"\n",
    "    try:\n",
    "        results = DDGS().text(q, region=\"us-en\", safesearch=\"off\", max_results=12)\n",
    "        return {\n",
    "            \"text\": results,\n",
    "            \"source\": \"DuckDuckGo\",\n",
    "            \"query\": q,\n",
    "            \"results_found\": len(results),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None}\n",
    "\n",
    "def save_report(content: str, task_description: str, reports_dir: str = \"reports\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Save a report to disk with automatic filename generation.\n",
    "    \n",
    "    This tool creates a timestamped Markdown file in the reports directory.\n",
    "    Perfect for preserving research findings, analysis results, or final reports.\n",
    "    \n",
    "    Args:\n",
    "        content (str): The report content to save. Can be plain text or Markdown.\n",
    "                      If no title (# header) is present, one will be auto-generated.\n",
    "        task_description (str): Brief description of the task/topic for filename.\n",
    "                               Example: \"AI impact on power sector analysis\"\n",
    "        reports_dir (str, optional): Directory to save reports. Defaults to \"reports\".\n",
    "                                   Directory will be created if it doesn't exist.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: Result dictionary containing:\n",
    "            - status: \"success\" or \"error\"\n",
    "            - filepath: Full path to saved file (if successful)\n",
    "            - filename: Just the filename (if successful)\n",
    "            - error: Error message (if failed)\n",
    "    \n",
    "    Example Usage for Agents:\n",
    "        # Save research findings\n",
    "        result = save_report(\n",
    "            content=\"# Market Analysis\\\\n\\\\nKey findings: ...\",\n",
    "            task_description=\"cryptocurrency market trends 2024\"\n",
    "        )\n",
    "        \n",
    "        # Save final report\n",
    "        result = save_report(\n",
    "            content=my_report_text,\n",
    "            task_description=\"climate change impact assessment\"\n",
    "        )\n",
    "        \n",
    "        # Check if save was successful\n",
    "        if result[\"status\"] == \"success\":\n",
    "            print(f\"Report saved as: {result['filename']}\")\n",
    "        else:\n",
    "            print(f\"Save failed: {result['error']}\")\n",
    "    \n",
    "    Generated Filename Format:\n",
    "        YYYYMMDD_HHMM_meaningful_task_words.md\n",
    "        Example: 20250819_1430_ai_power_sector.md\n",
    "    \n",
    "    Note: If file exists, automatic numbering prevents overwrites:\n",
    "          20250819_1430_ai_power_sector_1.md, _2.md, etc.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure reports directory exists\n",
    "        reports_path = Path(reports_dir)\n",
    "        reports_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Generate timestamped filename\n",
    "        timestamp = datetime.now()\n",
    "        date_time = timestamp.strftime(\"%Y%m%d_%H%M\")\n",
    "        task_name = _extract_task_name(task_description)\n",
    "        \n",
    "        filename = f\"{date_time}_{task_name}.md\"\n",
    "        filepath = reports_path / filename\n",
    "        \n",
    "        # Handle filename conflicts with counter\n",
    "        counter = 1\n",
    "        while filepath.exists():\n",
    "            filename = f\"{date_time}_{task_name}_{counter}.md\"\n",
    "            filepath = reports_path / filename\n",
    "            counter += 1\n",
    "        \n",
    "        # Format content with title if needed\n",
    "        formatted_content = _format_content(content, task_description, timestamp)\n",
    "        \n",
    "        # Save to disk\n",
    "        filepath.write_text(formatted_content, encoding='utf-8')\n",
    "        logger.info(f\"üìÑ Report saved: {filepath}\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"filepath\": str(filepath),\n",
    "            \"filename\": filename,\n",
    "            \"timestamp\": timestamp.isoformat()\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to save report: {str(e)}\"\n",
    "        logger.error(f\"‚ùå {error_msg}\")\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error\": error_msg,\n",
    "            \"task\": task_description\n",
    "        }\n",
    "\n",
    "\n",
    "def _extract_task_name(task: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract 2-3 meaningful words from task description for filename.\n",
    "    \n",
    "    Args:\n",
    "        task: The task description string\n",
    "        \n",
    "    Returns:\n",
    "        Underscore-separated words suitable for filename\n",
    "    \"\"\"\n",
    "    # Clean special characters and normalize\n",
    "    clean_task = re.sub(r'[^\\w\\s]', ' ', task.lower())\n",
    "    words = [w for w in clean_task.split() if len(w) > 2]\n",
    "    \n",
    "    # Filter common stop words\n",
    "    stop_words = {\n",
    "        'the', 'and', 'for', 'with', 'from', 'about', 'into', 'through',\n",
    "        'during', 'before', 'after', 'above', 'below', 'over', 'under'\n",
    "    }\n",
    "    meaningful = [w for w in words if w not in stop_words][:3]\n",
    "    \n",
    "    return '_'.join(meaningful) if meaningful else 'report'\n",
    "\n",
    "\n",
    "def _format_content(content: str, task: str, timestamp: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Format content with title and timestamp if needed.\n",
    "    \n",
    "    Args:\n",
    "        content: Raw content to format\n",
    "        task: Task description for title generation\n",
    "        timestamp: When the report was created\n",
    "        \n",
    "    Returns:\n",
    "        Formatted Markdown content\n",
    "    \"\"\"\n",
    "    # If content already has a Markdown title, use as-is\n",
    "    if content.strip().startswith('#'):\n",
    "        return content\n",
    "    \n",
    "    # Add title and timestamp for plain text content\n",
    "    formatted_title = f\"# Report: {task}\"\n",
    "    timestamp_line = f\"*Generated: {timestamp.strftime('%Y-%m-%d %H:%M')}*\"\n",
    "    \n",
    "    return f\"{formatted_title}\\n\\n{timestamp_line}\\n\\n{content}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert os.environ[\"OPENAI_API_KEY\"], \"OPENAI_API_KEY is not set\"\n",
    "# model_client = OpenAIChatCompletionClient(\n",
    "#     model=\"gpt-4o\", api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    "# )\n",
    "\n",
    "# ---------- Agents ----------\n",
    "supervisor = AssistantAgent(\n",
    "    name=\"Supervisor\",\n",
    "    description=\"Oversees the process, approves final output, requests retries if needed.\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You monitor progress and decide when to terminate the task.\",\n",
    ")\n",
    "\n",
    "planner = AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    model_client=model_client,\n",
    "    system_message=(\n",
    "        \"You are a meticulous planner. Create a clear, step-by-step plan for the request.\"\n",
    "        \"Seek critical review from the critic.\"\n",
    "        \"Agree on the final plan.\"\n",
    "        \"End with PLAN_COMPLETE after reviews are successfully completed.\"\n",
    "    ),\n",
    "    description=\"Creates detailed step-by-step plans for tasks\",\n",
    ")\n",
    "\n",
    "researcher = AssistantAgent(\n",
    "    name=\"Researcher\",\n",
    "    description=\"Expert research agent that strategically uses multiple tools to gather comprehensive, factual evidence and produces evidence-based draft reports.\",\n",
    "    model_client=model_client,\n",
    "    tools=[wiki_search, duckduckgo_search],\n",
    "    system_message=\"\"\"You are a Senior Research Analyst with expertise in systematic information gathering and evidence synthesis. Your mission: collect comprehensive, factual data using strategic tool selection and produce well-structured draft reports.\n",
    "\n",
    "    ============================\n",
    "**üéØ RESEARCH METHODOLOGY**\n",
    "\n",
    "**TOOL SELECTION STRATEGY**\n",
    "- **wiki_search**: Use for authoritative background information, definitions, historical context, and established facts\n",
    "  - Best for: academic topics, historical events, biographical info, scientific concepts\n",
    "  - Example queries: \"renewable energy market trends\", \"Federal Reserve policy history\"\n",
    "\n",
    "- **duckduckgo_search**: Use for current events, recent developments, market data, and diverse perspectives  \n",
    "  - Best for: breaking news, current market conditions, recent reports, real-time data\n",
    "  - Example queries: \"sectoral investment returns 2024\", \"trade tariffs impact economy 2025\"\n",
    "\n",
    "\n",
    "**RESEARCH EXECUTION PROTOCOL**\n",
    "a) **Foundation Research** (wiki_search first)\n",
    "b) **Current Intelligence** (duckduckgo_search)  \n",
    "c) **Cross-Validation** and source verification\n",
    "\n",
    "**SEARCH QUERY OPTIMIZATION**\n",
    "- Use specific, targeted queries rather than broad terms\n",
    "- Include relevant timeframes: \"2024\", \"2025\", \"recent\"\n",
    "- Try multiple query variations to capture different angles\n",
    "- Use industry terminology and specific metrics\n",
    "\n",
    "**3. OUTPUT FORMAT - EVIDENCE SUMMARY (NOT A REPORT)**\n",
    "Your job is to produce organized evidence, not polished reports:\n",
    "\n",
    "```\n",
    "# Evidence Summary: [Topic]\n",
    "\n",
    "## Key Findings\n",
    "‚Ä¢ [Fact 1 with source attribution]\n",
    "‚Ä¢ [Fact 2 with source attribution]\n",
    "‚Ä¢ [Fact 3 with source attribution]\n",
    "\n",
    "## Background Data\n",
    "- [Historical context and definitions]\n",
    "- [Industry overview and key players]\n",
    "\n",
    "## Current Market Intelligence\n",
    "- [Recent developments and trends]\n",
    "- [Expert opinions and forecasts]\n",
    "- [Market data and metrics]\n",
    "\n",
    "## Source Assessment\n",
    "- [High confidence sources]\n",
    "- [Areas of uncertainty or conflicting information]\n",
    "- [Data gaps identified]\n",
    "\n",
    "## Research Queries Performed\n",
    "- [List of searches conducted]\n",
    "- [Tools used and rationale]\n",
    "```\n",
    "\n",
    "**4. COLLABORATION HANDOFF**\n",
    "- Provide comprehensive evidence to Critic for validation\n",
    "- Respond to feedback with additional research\n",
    "- DO NOT attempt to write final reports - that's Editor's role\n",
    "- Focus on evidence quality, not presentation polish\n",
    "\n",
    "**RESEARCH MANTRA**: \"Gather evidence systematically, organize logically, source reliably.\"\n",
    "\n",
    "Your output feeds the Editor who transforms evidence into polished reports\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "critic = AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=(\n",
    "        \"\"\"\n",
    "You are a domain-agnostic Critic Agent. Your role: produce a concise, evidence-based critique of the provided artifact (plan, report, code, design, or prompt). Follow this exact process and style rules.\n",
    "\n",
    "Process:\n",
    "1. IDENTIFY: State artifact type, asserted goal, and audience (1 line).\n",
    "2. SUMMARIZE: Give a 1‚Äì2 line neutral summary of content and intent.\n",
    "3. STRENGTHS: List up to 5 concise strengths with line/section references.\n",
    "4. ISSUES: For each issue, provide:\n",
    "   - Title (one line)\n",
    "   - Severity: {Critical, Major, Minor}\n",
    "   - Evidence: exact quote / line numbers / code snippet\n",
    "   - Impact: one sentence on consequences\n",
    "   - Fix: Suggest corrective actions.\n",
    "   - Tests to verify fix (if applicable)\n",
    "5. PRIORITY LIST: Rank recommended fixes (highest impact first).\n",
    "6. VERDICT: Single-line overall recommendation (Accept / Accept with changes / Major revision / Reject) and confidence level (High/Med/Low).\n",
    "7. CLARIFY: If essential facts are missing for critical judgments, list the minimal questions required.\n",
    "8. VERACITY: Assess the truthfulness and reliability of the information presented. Request sources or evidence for claims. Preferred format: [source](URL).\n",
    "9. TRADEOFFS: Implore second-order consequences for unverified assumptions.\n",
    "\n",
    "Style rules:\n",
    "- Use active voice and action verbs.\n",
    "- Keep each bullet ‚â§ 20 words.\n",
    "- Use numbered lists and bullets.\n",
    "- Cite exact lines or code references for claims.\n",
    "- Challenge assumptions and seek clarification.\n",
    "- End with a the author can act on.\n",
    "\n",
    "Length limits:\n",
    "- Summary: ‚â§ 40 words.\n",
    "- Strengths: ‚â§ 5 bullets.\n",
    "- Issues: ‚â§ 10 bullets.\n",
    "- Overall critique: ‚â§ 500 words.\n",
    "\n",
    "Tone: professional, concise, constructive.\n",
    "\"\"\"\n",
    "        \"Do NOT APPROVE without addressing all concerns.\"\n",
    "        \"Respond with 'APPROVED: [...]' when your feedback is addressed.\"\n",
    "    ),\n",
    "    description=\"Reviews and provides constructive criticism; outputs 'APPROVED: [...]' when ready.\",\n",
    ")\n",
    "\n",
    "\n",
    "editor = AssistantAgent(\n",
    "    name=\"Editor\",\n",
    "    description=\"Formats approved drafts with proper citations, adapts structure to content type.\",\n",
    "    model_client=model_client,\n",
    "    tools=[save_report],\n",
    "    system_message=(\n",
    "        \"\"\"You are the Editor Agent - applying editorial rigor while adapting to content needs.\n",
    "\n",
    "\n",
    "\n",
    "**EDITORIAL STANDARDS(Always Apply)**\n",
    "- **Synthesis Over Summary**: Connect evidence into insights. Review Researcher's evidence summary and Critic's validation.\n",
    "- **Quantify Impact**: Include specific percentages and timeframes. Identify key insights; first and second order implications.\n",
    "- **Professional Polish**: Clear, confident, actionable language\n",
    "- **Source Attribution**: Proper citations for all claims [1], [2], etc.\n",
    "- **Clear Structure**: Use appropriate headings for logical flow\n",
    "- **Professional Tone**: Clear, objective, and accessible language\n",
    "- **Evidence-Based**: Distinguish facts from analysis/opinion. Call out opinions as such, when evidence is lacking.\n",
    "- **Report Structure**: Determine optimal report structure for the content type\n",
    "\n",
    "**Flexible Formatting Guidelines**:\n",
    "\n",
    "\n",
    "**For Analysis/Research Reports**:\n",
    "- Use: Executive Summary[Main conclusion with specific metrics], Key Findings, Analysis, Risk Assessment[Key risks and timeframe], Conclusions[Actionable recommendations], References\n",
    "- Structure: ## Main topics, ### Subtopics as needed\n",
    "\n",
    "**For News/Current Events**:\n",
    "- Use: Overview, Current Situation, Impact Analysis, References\n",
    "- Lead with most important information first\n",
    "\n",
    "**For Technical/Process Reports**:\n",
    "- Use: Overview, Methodology, Results, Implementation, References\n",
    "- Focus on actionable insights\n",
    "\n",
    "**For Comparative Studies**:\n",
    "- Use: Introduction, Comparison Framework, Analysis, Recommendations, References\n",
    "- Tables and bullet points for comparisons\n",
    "\n",
    "**Citation Rules (Flexible)**:\n",
    "- Factual claims: \"Power sector emissions increased 15%[1]\"\n",
    "- Trends: \"Studies indicate growing adoption[2][3]\" \n",
    "- Analysis: \"Based on available data[1][2], this suggests...\"\n",
    "- Web sources: Include URLs when available\n",
    "\n",
    "**Reference Format (Adaptable)**:\n",
    "```\n",
    "## References\n",
    "- [1]: Source Name. \"Content/Query.\" Platform. [URL if available]\n",
    "- [2]: Author/Organization. \"Title.\" Retrieved from [Platform] search.\n",
    "```\n",
    "\n",
    "**QUALITY CHECK**:\n",
    "- Is the structure logical for this content type?\n",
    "- Are sources properly attributed?\n",
    "- Is the language clear and professional?\n",
    "- Does it serve the reader's needs?\n",
    "\n",
    "**SAVE PROTOCOL**\n",
    "- Always use `save_report` tool for final output\n",
    "- Use descriptive task descriptions for filenames\n",
    "- Confirm successful save with \"REPORT_SAVED\"\n",
    "\n",
    "**TERMINATION SIGNAL**\n",
    "After successful save: \"Report successfully saved. REPORT_SAVED. TASK_COMPLETED. TERMINATE\"\n",
    "\n",
    "\n",
    "Adapt the structure to best serve the content and audience - not every report needs the same format.\"\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ---------- Selector prompt with few-shot examples ----------\n",
    "selector_prompt = \"\"\"You are the selector agent. Choose exactly one agent name from {participants} to speak next based on the conversation history and their roles.\n",
    "\n",
    "Few-shot examples:\n",
    "\n",
    "Example 1:\n",
    "History: Researcher produced a draft; Critic says 'Needs more sources and clarity'.\n",
    "Selected agent: Researcher\n",
    "\n",
    "Example 2:\n",
    "History: Researcher produced a draft; Critic says 'APPROVED'.\n",
    "Selected agent: Editor\n",
    "\n",
    "Roles:\n",
    "{roles}\n",
    "\n",
    "Conversation history:\n",
    "{history}\n",
    "\n",
    "Rules:\n",
    "- Pick the agent whose role most advances completion.\n",
    "\n",
    "Return only the agent name (no extra text).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ---------- Termination callable ----------\n",
    "max_messages = 30\n",
    "txt_termination = TextMentionTermination(\"TERMINATE\")\n",
    "termination_condition = (\n",
    "    MaxMessageTermination(max_messages=max_messages) | txt_termination\n",
    ")\n",
    "\n",
    "# ---------- Build SelectorGroupChat ----------\n",
    "team = SelectorGroupChat(\n",
    "    participants=[supervisor, planner, researcher, critic, editor],\n",
    "    model_client=model_client,\n",
    "    selector_prompt=selector_prompt,\n",
    "    termination_condition=termination_condition,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tenacity.retry(\n",
    "#     wait=tenacity.wait_exponential(multiplier=1, min=60, max=120),\n",
    "#     stop=tenacity.stop_after_attempt(2),\n",
    "#     retry=tenacity.retry_if_exception_type(Exception),\n",
    "# )\n",
    "async def run_task(task_text: str):\n",
    "    \"\"\"\n",
    "    Execute a multi-agent research task with proper termination handling.\n",
    "\n",
    "    Args:\n",
    "        task_text (str): The research task description\n",
    "\n",
    "    Returns:\n",
    "        str | None: Final report content or None if task incomplete\n",
    "    \"\"\"\n",
    "    final_report = None\n",
    "    task_completed = False\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"üöÄ Starting task: {task_text}\\n\\n\")\n",
    "\n",
    "        async for event in team.run_stream(task=task_text):\n",
    "            logger.info(f\"üìù Event: {event}\\n\\n\")\n",
    "\n",
    "            # Check for TERMINATE keyword in message content\n",
    "            if hasattr(event, \"content\") and isinstance(event.content, str):\n",
    "                if \"TERMINATE\" in event.content:\n",
    "                    final_report = event.content.split(\"TERMINATE\", 1)[0].strip()\n",
    "                    task_completed = True\n",
    "                    logger.info(\"\\n\\n\\n\\n‚úÖ Task completed with TERMINATE signal\\n\\n\\n\\n\")\n",
    "                    break\n",
    "\n",
    "\n",
    "            # Simple delay between each agent call\n",
    "            logger.info(\"\\n\\n\\n\\n‚è≥ Waiting 30s to avoid rate limits...\")\n",
    "            await asyncio.sleep(25)\n",
    "\n",
    "        return final_report if task_completed else None\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"\\n\\n‚ùå Exception during task execution: {e}\\n\\n\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # Save final state on completion\n",
    "        await _save_team_state()\n",
    "\n",
    "\n",
    "async def _save_team_state():\n",
    "    \"\"\"Helper function to save team state with error handling.\"\"\"\n",
    "    try:\n",
    "        state = await team.save_state()\n",
    "        with open(\"team_state.json\", \"w\") as f:\n",
    "            json.dump(state, f, indent=2)\n",
    "        logger.info(\"üíæ Team state saved successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to save team state: {e}\")\n",
    "\n",
    "\n",
    "async def resume_from_saved_state():\n",
    "    \"\"\"Resume execution from previously saved team state.\"\"\"\n",
    "    try:\n",
    "        with open(\"team_state.json\", \"r\") as f:\n",
    "            saved_state = json.load(f)\n",
    "\n",
    "        await team.load_state(saved_state)\n",
    "        logger.info(\"üîÑ Resuming from saved state\")\n",
    "\n",
    "        async for event in team.run_stream():\n",
    "            logger.info(f\"üìù Resume Event: {event}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"‚ùå No saved state file found\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to resume from saved state: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb513d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    __SAMPLE_QUERY_1 = \"Indian steel sector growth post modernization and growth prospects in an era of US tariffs and reduce government protection through trade barriers and cheaper import options from China\"\n",
    "\n",
    "    __SAMPLE_QUERY_2 = \"How government and governance factors improved economy and lives of indians during Modi and Pre-Modi starting from 1991\"\n",
    "\n",
    "    __SAMPLE_QUERY_3 = \"Sectoral growth based on cyclics for 2025 and macro economic pressure and trade tariffs and uncertainty, which sectors are best poised for maximum investment returns in terms of % for the next year for a moderate to average risk profile investments\"\n",
    "\n",
    "    __SAMPLE_QUERY_4 = \"Hyperscaler investments in data centers and cloud infrastructure for AI growth is not matching the proposed productivity gains in GDP. Are we witnessing a bubble? Is % of global GDP being invested in AI infrastructure matches the productivity gain percentages?\"\n",
    "\n",
    "    __SAMPLE_QUERY_5 = \"If neural networks are foundation of LLMs and based on the human brain; Are LLMs given tools during training? Humans learn with tool usage, What are current trends on tool usage in LLM training?\"\n",
    "\n",
    "    try:\n",
    "        output = asyncio.run(run_task(__SAMPLE_QUERY_1))\n",
    "        if output:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"üéØ FINAL REPORT\")\n",
    "            print(\"=\" * 60)\n",
    "            print(output)\n",
    "        else:\n",
    "            print(\"‚ùå Task did not complete successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Fatal error: {e}\")\n",
    "        print(f\"‚ùå Execution failed: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
