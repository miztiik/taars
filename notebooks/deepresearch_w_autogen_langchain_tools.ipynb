{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bc3cfa",
   "metadata": {},
   "source": [
    "# Orchestrate Multiple-Agents for High-Quality Research with AutoGen and LangChain Tools\n",
    "\n",
    "This notebook showcases how to harness the combined power of **AutoGen** and **LangChain** tools to automate and elevate deep research workflows. At its core, the system coordinates a network of specialized agents—each executing a distinct role in the research and report generation workflow. Together, these agents collect data, analyze findings, and produce polished, insight-driven reports.\n",
    "\n",
    "\n",
    "[Open in Colab](https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb) <a href=\"https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "## 🧠 Agent Roles Overview\n",
    "\n",
    "- **🧭 Planner Agent**  \n",
    "  Defines the research scope, objectives, and key questions.  \n",
    "  → Anchors the process by structuring it around a well-defined `__TASK_QUERY`.\n",
    "\n",
    "- **🔍 Researcher Agent**  \n",
    "  Gathers information using tools like `wiki_search` and `duckduckgo_search`.  \n",
    "  → Supplies the system with relevant, factual data.\n",
    "\n",
    "- **🧪 Critic Agent**  \n",
    "  Reviews the research plan, gathered evidence, and drafted reports.  \n",
    "  → Provides feedback to enforce analytical rigor and clarity.\n",
    "\n",
    "- **✍️ Editor Agent**  \n",
    "  Refines the final report's language, structure, and presentation.  \n",
    "  → Ensures clarity, polish, and alignment with stakeholder expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -q autogen-agentchat \n",
    "%pip install -U -q autogen-ext\n",
    "\n",
    "%pip install -U -q langchain \n",
    "%pip install -U -q langchain-community\n",
    "%pip install lxml\n",
    "%pip install ddgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import sys\n",
    "\n",
    "# import logging\n",
    "# logger = logging.getLogger(\"\")\n",
    "\n",
    "\n",
    "# # Remove all existing handlers\n",
    "# for handler in logger.handlers[:]:\n",
    "#     logger.removeHandler(handler)\n",
    "\n",
    "# REMOVE ALL EXISTING HANDLERS for LOGURU\n",
    "if len(logger._core.handlers) > 1:\n",
    "    logger.configure(handlers=[])\n",
    "\n",
    "logger.add(\n",
    "    sys.stderr,\n",
    "    format=\"{time:HH:mm:ss:SSS} | {level} | {name}:{line} | {message}\",\n",
    "    level=\"INFO\",\n",
    "    colorize=True,\n",
    ")\n",
    "\n",
    "# Configure file logging with better settings\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "log_file = notebook_dir / \"logs\" / \"llm_execution.log\"\n",
    "log_file.parent.mkdir(exist_ok=True)\n",
    "logger.add(\n",
    "    log_file,\n",
    "    format=\"{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} | {message}\",\n",
    "    level=\"DEBUG\",\n",
    "    rotation=\"10 MB\",\n",
    "    retention=\"7 days\",\n",
    "    compression=\"zip\",\n",
    "    enqueue=True,\n",
    ")\n",
    "logger.info(f\"✅ Logging configured - File: {log_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef193373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "\n",
    "# Confirm the API key is set\n",
    "assert os.environ[\"GEMINI_API_KEY\"], \"GEMINI_API_KEY is not set\"\n",
    "assert os.environ[\"GEMINI_MODEL_NAME\"], \"GEMINI_MODEL_NAME is not set\"\n",
    "assert os.environ[\"RATE_LIMIT_GEMINI_RPM\"], \"RATE_LIMIT_GEMINI_RPM is not set\"\n",
    "assert os.environ[\"RATE_LIMIT_GEMINI_RPD\"], \"RATE_LIMIT_GEMINI_RPD is not set\"\n",
    "assert os.environ[\"GEMINI_BASE_URL\"], \"GEMINI_BASE_URL is not set\"\n",
    "\n",
    "\n",
    "model_info = ModelInfo(\n",
    "    vision=True,\n",
    "    function_calling=True,\n",
    "    json_output=True,\n",
    "    family=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    structured_output=True,\n",
    ")\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    base_url=os.environ[\"GEMINI_BASE_URL\"],\n",
    "    model_info=model_info,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, json, os\n",
    "from regex import D\n",
    "import tenacity\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.messages import StopMessage\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "from ddgs import DDGS\n",
    "\n",
    "\n",
    "# assert os.environ[\"OPENAI_API_KEY\"], \"OPENAI_API_KEY is not set\"\n",
    "# model_client = OpenAIChatCompletionClient(\n",
    "#     model=\"gpt-4o\", api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    "# )\n",
    "\n",
    "# Tool definitions\n",
    "wiki_api = WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=2000)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api)\n",
    "\n",
    "\n",
    "def wiki_search(q: str) -> dict:\n",
    "    \"\"\"Return structured output including text and source.\"\"\"\n",
    "    try:\n",
    "        result = wiki_tool.run(q)\n",
    "        return {\"text\": result, \"source\": \"Wikipedia\"}\n",
    "    except Exception as e:\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None}\n",
    "\n",
    "\n",
    "@tool\n",
    "def duckduckgo_search(q: str) -> dict:\n",
    "    \"\"\"Search the web using DuckDuckGo for information.\"\"\"\n",
    "    try:\n",
    "        results = DDGS().text(q, region=\"us-en\", safesearch=\"off\", max_results=12)\n",
    "        return {\n",
    "            \"text\": results,\n",
    "            \"source\": \"DuckDuckGo\",\n",
    "            \"query\": q,\n",
    "            \"results_found\": len(results),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None}\n",
    "\n",
    "\n",
    "# ---------- Agents ----------\n",
    "supervisor = AssistantAgent(\n",
    "    name=\"Supervisor\",\n",
    "    description=\"Oversees the process, approves final output, requests retries if needed.\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You monitor progress and decide when to terminate the task.\",\n",
    ")\n",
    "\n",
    "planner = AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    model_client=model_client,\n",
    "    system_message=(\n",
    "        \"You are a meticulous planner. Create a clear, step-by-step plan for the request. \"\n",
    "        \"End with PLAN_COMPLETE.\"\n",
    "    ),\n",
    "    description=\"Creates detailed step-by-step plans for tasks\",\n",
    ")\n",
    "\n",
    "researcher = AssistantAgent(\n",
    "    name=\"Researcher\",\n",
    "    description=\"Collects factual evidence using wiki_search, duckduckgo_search, produces text drafts.\",\n",
    "    model_client=model_client,\n",
    "    tools=[wiki_search, duckduckgo_search],\n",
    "    system_message=\"Research and produce a concise draft on the given topic using facts.\",\n",
    ")\n",
    "\n",
    "critic = AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=(\n",
    "        \"\"\"\n",
    "You are a domain-agnostic Critic Agent. Your role: produce a concise, evidence-based critique of the provided artifact (plan, report, code, design, or prompt). Follow this exact process and style rules.\n",
    "\n",
    "Process:\n",
    "1. IDENTIFY: State artifact type, asserted goal, and audience (1 line).\n",
    "2. SUMMARIZE: Give a 1–2 line neutral summary of content and intent.\n",
    "3. STRENGTHS: List up to 5 concise strengths with line/section references.\n",
    "4. ISSUES: For each issue, provide:\n",
    "   - Title (one line)\n",
    "   - Severity: {Critical, Major, Minor}\n",
    "   - Evidence: exact quote / line numbers / code snippet\n",
    "   - Impact: one sentence on consequences\n",
    "   - Fix: Suggest corrective actions.\n",
    "   - Tests to verify fix (if applicable)\n",
    "5. PRIORITY LIST: Rank recommended fixes (highest impact first).\n",
    "6. VERDICT: Single-line overall recommendation (Accept / Accept with changes / Major revision / Reject) and confidence level (High/Med/Low).\n",
    "7. CLARIFY: If essential facts are missing for critical judgments, list the minimal questions required.\n",
    "8. VERACITY: Assess the truthfulness and reliability of the information presented. Request sources or evidence for claims. Preferred format: [source](URL).\n",
    "9. TRADEOFFS: Implore second-order consequences for unverified assumptions.\n",
    "\n",
    "Style rules:\n",
    "- Use active voice and action verbs.\n",
    "- Keep each bullet ≤ 20 words.\n",
    "- Use numbered lists and bullets.\n",
    "- Cite exact lines or code references for claims.\n",
    "- Challenge assumptions and seek clarification.\n",
    "- End with a the author can act on.\n",
    "\n",
    "Length limits:\n",
    "- Summary: ≤ 40 words.\n",
    "- Strengths: ≤ 5 bullets.\n",
    "- Issues: ≤ 10 bullets.\n",
    "- Overall critique: ≤ 500 words.\n",
    "\n",
    "Tone: professional, concise, constructive.\n",
    "\"\"\"\n",
    "        \"Do NOT APPROVE without addressing all concerns.\"\n",
    "        \"Respond with 'APPROVED: [...]' when your feedback is addressed.\"\n",
    "    ),\n",
    "    description=\"Reviews and provides constructive criticism; outputs 'APPROVED: [...]' when ready.\",\n",
    ")\n",
    "\n",
    "editor = AssistantAgent(\n",
    "    name=\"Editor\",\n",
    "    description=\"Formats an approved draft into Markdown, and appends 'TERMINATE'.\",\n",
    "    model_client=model_client,\n",
    "    system_message=(\n",
    "        \"Format Critic approved content output in Markdown format.\"\n",
    "        \"Focus on clarity, coherence, and conciseness.\"\n",
    "        \"Use bullets and tables where appropriate.\"\n",
    "        \"append 'TERMINATE' to signal completion.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ---------- Selector prompt with few-shot examples ----------\n",
    "selector_prompt = \"\"\"You are the selector agent. Choose exactly one agent name from {participants} to speak next based on the conversation history and their roles.\n",
    "\n",
    "Few-shot examples:\n",
    "\n",
    "Example 1:\n",
    "History: Researcher produced a draft; Critic says 'Needs more sources and clarity'.\n",
    "Selected agent: Researcher\n",
    "\n",
    "Example 2:\n",
    "History: Researcher produced a draft; Critic says 'APPROVED'.\n",
    "Selected agent: Editor\n",
    "\n",
    "Roles:\n",
    "{roles}\n",
    "\n",
    "Conversation history:\n",
    "{history}\n",
    "\n",
    "Rules:\n",
    "- Pick the agent whose role most advances completion.\n",
    "\n",
    "Return only the agent name (no extra text).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ---------- Termination callable ----------\n",
    "max_messages = 25\n",
    "txt_termination = TextMentionTermination(\"TERMINATE\")\n",
    "termination_condition = (\n",
    "    MaxMessageTermination(max_messages=max_messages) | txt_termination\n",
    ")\n",
    "\n",
    "# ---------- Build SelectorGroupChat ----------\n",
    "team = SelectorGroupChat(\n",
    "    participants=[supervisor, planner, editor, researcher, critic],\n",
    "    model_client=model_client,\n",
    "    selector_prompt=selector_prompt,\n",
    "    termination_condition=termination_condition,\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Selector validation ----------\n",
    "def validate_selector_choice(raw_choice, participants):\n",
    "    \"\"\"Ensure selector returns a canonical agent name.\"\"\"\n",
    "    choice = raw_choice.strip().splitlines()[0].strip()\n",
    "    for p in participants:\n",
    "        if choice.lower() == p.name.lower():\n",
    "            return p.name\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tenacity.retry(\n",
    "    wait=tenacity.wait_exponential(multiplier=1, min=1, max=20),\n",
    "    stop=tenacity.stop_after_attempt(2),\n",
    "    retry=tenacity.retry_if_exception_type(Exception),\n",
    ")\n",
    "async def run_task(task_text: str):\n",
    "    final_report = None\n",
    "    try:\n",
    "        async for ev in team.run_stream(task=task_text):\n",
    "            logger.info(ev)\n",
    "            if await termination_condition([ev]):\n",
    "                if isinstance(ev, TextMessage):\n",
    "                    final_report = ev.content.split(\"TERMINATE\", 1)[0].strip()\n",
    "                    break\n",
    "        # Save final state\n",
    "        state = await team.save_state()\n",
    "        with open(\"team_state.json\", \"w\") as f:\n",
    "            json.dump(state, f)\n",
    "    except Exception as e:\n",
    "        print(\"Exception during run:\", e)\n",
    "        # Save state on failure\n",
    "        state = await team.save_state()\n",
    "        with open(\"team_state.json\", \"w\") as f:\n",
    "            json.dump(state, f)\n",
    "        raise\n",
    "    return final_report\n",
    "\n",
    "\n",
    "async def resume_from_saved_state():\n",
    "    with open(\"team_state.json\", \"r\") as f:\n",
    "        saved = json.load(f)\n",
    "    await team.load_state(saved)\n",
    "    async for ev in team.run_stream():\n",
    "        logger.info(ev)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    __TASK_QUERY = \"AI , Macro economic pressure, tarrifs on indian power sector\"\n",
    "    output = asyncio.run(run_task(__TASK_QUERY))\n",
    "    if output:\n",
    "        print(\"\\nFinal Report:\\n\", output)\n",
    "    else:\n",
    "        print(\"Task did not complete successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bef71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
