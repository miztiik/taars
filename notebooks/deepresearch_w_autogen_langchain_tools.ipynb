{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bc3cfa",
   "metadata": {},
   "source": [
    "# ü§ñ Multi-Agent Deep Research System\n",
    "\n",
    "This notebook showcases how to harness the combined power of **AutoGen** and **LangChain** tools to automate and elevate deep research workflows. At its core, the system coordinates a network of specialized agents‚Äîeach executing a distinct role in the research and report generation workflow. Together, these agents collect data, analyze findings, and produce polished, insight-driven reports.\n",
    "\n",
    "[Open in Colab](https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb) <a href=\"https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## üß† Agent Roles\n",
    "\n",
    "- **üß≠ Planner**: Defines research scope, objectives, and success criteria\n",
    "- **üîç Researcher**: Gathers evidence using `wiki_search`, `web_search` and `web_fetch` for content extraction\n",
    "- **üß™ Critic**: Reviews plans and outputs for quality and completeness\n",
    "- **‚úçÔ∏è Editor**: Formats final reports with proper citations and structure\n",
    "\n",
    "## üîÑ System Architecture\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User Query] --> B[üß≠ Planner]\n",
    "    B --> C[üîç Researcher]\n",
    "    C --> D[üß™ Critic]\n",
    "    D --> E[‚úçÔ∏è Editor]\n",
    "    E --> F[üìÑ Final Report]\n",
    "\n",
    "    B -.-> D\n",
    "    C -.-> B\n",
    "    D -.-> C\n",
    "\n",
    "    C --> G[Wiki Search]\n",
    "    C --> H[Web Search]\n",
    "    C --> I[Content Fetch]\n",
    "\n",
    "```\n",
    "\n",
    "## üöÄ Quick Start\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Set environment variables:\n",
    "\n",
    "```bash\n",
    "# Required: Gemini API (or configure other models in cells below)\n",
    "export GEMINI_API_KEY=\"your_api_key\"\n",
    "export GEMINI_MODEL_NAME=\"gemini-1.5-flash\"\n",
    "export GEMINI_BASE_URL=\"https://generativelanguage.googleapis.com/v1beta/\"\n",
    "```\n",
    "\n",
    "### Run Research Task\n",
    "\n",
    "1. **Execute all cells** in sequence\n",
    "2. **Modify the query** in the final cell:\n",
    "   ```python\n",
    "   output = asyncio.run(run_task(\"Your research question here\"))\n",
    "   ```\n",
    "3. **Monitor progress** in real-time through cell outputs\n",
    "\n",
    "## üìã Example Queries\n",
    "\n",
    "- **Financial Analysis**: `\"Indian steel sector growth prospects in an era of US tariffs\"`\n",
    "- **Economic Research**: `\"Government factors that improved Indian economy during Modi era\"`\n",
    "- **Tech Industry**: `\"Are we witnessing an AI infrastructure bubble? GDP investment vs productivity gains\"`\n",
    "- **AI/ML Trends**: `\"Current trends in tool usage during LLM training\"`\n",
    "\n",
    "## üìä Outputs & Monitoring\n",
    "\n",
    "| Output Type | Location                         | Description                               |\n",
    "| ----------- | -------------------------------- | ----------------------------------------- |\n",
    "| **Reports** | `./reports/`                     | Timestamped Markdown reports (auto-saved) |\n",
    "| **Logs**    | `./logs/deep_research_agent.log` | Detailed execution logs with token usage  |\n",
    "| **State**   | `./team_state.json`              | Conversation state for resume capability  |\n",
    "\n",
    "## üìù TODO & Roadmap\n",
    "\n",
    "- [ ] **Specialized Models**: Different LLMs for different agent roles (planning vs research vs writing)\n",
    "- [ ] **Semantic Depth Search**: Advanced content extraction with semantic similarity scoring\n",
    "- [ ] **Source Verification**: Cross-reference validation and fact-checking workflows\n",
    "- [ ] **Domain-Specific Tools**: Specialized research tools for finance, science, law, etc.\n",
    "- [ ] **Agent Control Flow Logging**: Meaningful event logging for agent-to-agent handoffs\n",
    "- [ ] **Organic Flow Orchestration**: Improved prompts for natural, adaptive conversation flow\n",
    "- [ ] **Streaming UI**: Real-time progress visualization and intervention capability\n",
    "- [ ] **Performance Metrics**: Research quality scoring and optimization analytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57d4c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "htmldate 1.9.3 requires lxml<6,>=5.3.0; platform_system != \"Darwin\" or python_version > \"3.8\", but you have lxml 6.0.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "%pip install -qU ipykernel\n",
    "%pip install -qU autogen-agentchat\n",
    "%pip install -qU autogen-ext\n",
    "\n",
    "%pip install -qU loguru\n",
    "\n",
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-community\n",
    "%pip install -qU wikipedia\n",
    "%pip install -qU selenium unstructured\n",
    "%pip install -qU lxml\n",
    "%pip install -qU ddgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4222bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GOOGLE COLAB LINE WRAPPING\n",
    "# https://stackoverflow.com/questions/58890109/line-wrapping-in-collaboratory-google-results\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def set_css():\n",
    "    display(\n",
    "        HTML(\n",
    "            \"\"\"\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "get_ipython().events.register(\"pre_run_cell\", set_css)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %aimport -langchain_community\n",
    "# Automatically reload modules before executing code\n",
    "\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48776430",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERIC IMPORTS\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Annotated\n",
    "\n",
    "import nest_asyncio\n",
    "import tenacity\n",
    "from loguru import logger\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS\n",
    "\n",
    "## LOG CONFIG\n",
    "LOG_ROTATION_SIZE = \"10 MB\"\n",
    "LOG_RETENTION_DAYS = \"7 days\"\n",
    "\n",
    "## AUTOGEN CONFIG\n",
    "CONVERSATION_BUFFER_SIZE = 10\n",
    "TASK_TERMINATION_MAX_MESSAGES = 30\n",
    "API_CALL_DELAY_SECONDS = int(\n",
    "    os.environ.get(\"API_CALL_DELAY_SECONDS\", \"45\")\n",
    ")  # 45 seconds = 1.33 RPM\n",
    "NON_API_EVENT_DELAY = 0.5  # Small delay for non-API events\n",
    "\n",
    "## TOOL CONFIG\n",
    "WIKI_MAX_RESULTS = 5\n",
    "WIKI_MAX_CHARS = 5000\n",
    "WIKIPEDIA_MAX_DOCS = 2\n",
    "DDGS_MAX_RESULTS = 10\n",
    "WEB_CONTENT_MAX_LENGTH = 15000\n",
    "WEB_CONTENT_MIN_LENGTH = 50\n",
    "WEB_BATCH_MAX_URLS = 10\n",
    "SELENIUM_WINDOW_SIZE = \"1920,1080\"\n",
    "BROWSER_USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\"\n",
    "TITLE_SLICE_LENGTH = 50\n",
    "TOP_RESULTS_COUNT = 3\n",
    "TASK_MAX_MEANINGFUL_WORDS = 3\n",
    "CRITIC_MAX_WORDS = 500\n",
    "URL_FETCH_DELAY = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOGGING CONFIG\n",
    "notebook_dir = Path.cwd()\n",
    "log_dir = notebook_dir / \"logs\"\n",
    "log_file = log_dir / \"deep_research_agent.log\"\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if not getattr(sys, \"_loguru_configured\", False):\n",
    "    logger.remove()\n",
    "    logger.add(\n",
    "        str(log_file),\n",
    "        level=\"DEBUG\",\n",
    "        rotation=\"10 MB\",\n",
    "        retention=\"7 days\",\n",
    "        compression=\"zip\",\n",
    "        enqueue=True,\n",
    "    )\n",
    "    logger.add(\n",
    "        sys.stderr,\n",
    "        colorize=True,\n",
    "    )\n",
    "    sys._loguru_configured = True\n",
    "\n",
    "logger.info(f\"‚úÖ Logging configured successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.messages import StopMessage\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_core.model_context import BufferedChatCompletionContext\n",
    "from autogen_core.tools import Tool\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_community.document_loaders import SeleniumURLLoader\n",
    "from ddgs import DDGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef193373",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GEMINI MODEL CLIENT\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "\n",
    "# Confirm the API key is set\n",
    "assert os.environ[\"GEMINI_API_KEY\"], \"GEMINI_API_KEY is not set\"\n",
    "assert os.environ[\"GEMINI_MODEL_NAME\"], \"GEMINI_MODEL_NAME is not set\"\n",
    "assert os.environ[\"GEMINI_BASE_URL\"], \"GEMINI_BASE_URL is not set\"\n",
    "\n",
    "\n",
    "gemini_model_info = ModelInfo(\n",
    "    vision=False,\n",
    "    function_calling=True,\n",
    "    json_output=True,\n",
    "    family=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    structured_output=True,\n",
    ")\n",
    "\n",
    "gemini_model_client = OpenAIChatCompletionClient(\n",
    "    model=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    base_url=os.environ[\"GEMINI_BASE_URL\"],\n",
    "    model_info=gemini_model_info,\n",
    "    max_retries=2,\n",
    "    parallel_tool_calls=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30311843",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AZURE OPENAI MODEL CLIENT\n",
    "# from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "## Confirm the API key is set\n",
    "# assert os.environ[\"AZURE_OAI_DEPLOYMENT\"], \"AZURE_OAI_DEPLOYMENT is not set\"\n",
    "# assert os.environ[\"AZURE_OAI_MODEL_NAME\"], \"AZURE_OAI_MODEL_NAME is not set\"\n",
    "# assert os.environ[\"AZURE_OAI_MODEL_VERSION\"], \"AZURE_OAI_MODEL_VERSION is not set\"\n",
    "# assert os.environ[\"AZURE_OAI_BASE_URL\"], \"AZURE_OAI_BASE_URL is not set\"\n",
    "\n",
    "# az_oai_model_client = AzureOpenAIChatCompletionClient(\n",
    "#     azure_deployment=os.environ[\"AZURE_OAI_DEPLOYMENT\"],\n",
    "#     model=os.environ[\"AZURE_OAI_MODEL_NAME\"],\n",
    "#     api_version=os.environ[\"AZURE_OAI_MODEL_VERSION\"],\n",
    "#     azure_endpoint=os.environ[\"AZURE_OAI_BASE_URL\"],\n",
    "\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGENT TOOLS\n",
    "\n",
    "# Wiki Search Tool\n",
    "wiki_api = WikipediaAPIWrapper(\n",
    "    top_k_results=WIKI_MAX_RESULTS, doc_content_chars_max=WIKI_MAX_CHARS\n",
    ")\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api)\n",
    "\n",
    "\n",
    "def wiki_full_search(input: str) -> str:\n",
    "    \"\"\"Search Wikipedia for a query and return maximum 2 results.\"\"\"\n",
    "    logger.info(f\"üîç wiki_full_search: Starting search for '{input}'\")\n",
    "\n",
    "    try:\n",
    "        search_docs = WikipediaLoader(\n",
    "            query=input, load_max_docs=WIKIPEDIA_MAX_DOCS\n",
    "        ).load()\n",
    "\n",
    "        if not search_docs:\n",
    "            logger.warning(f\"‚ö†Ô∏è wiki_full_search: No documents found for '{input}'\")\n",
    "            return f\"No Wikipedia articles found for query: {input}\"\n",
    "\n",
    "        logger.info(\n",
    "            f\"‚úÖ wiki_full_search: Found {len(search_docs)} documents for '{input}'\"\n",
    "        )\n",
    "\n",
    "        formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "            [\n",
    "                f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "                for doc in search_docs\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        content_length = len(formatted_search_docs)\n",
    "        logger.info(\n",
    "            f\"üìä wiki_full_search: Returning {content_length} characters for '{input}'\"\n",
    "        )\n",
    "\n",
    "        return formatted_search_docs\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå wiki_full_search failed for '{input}': {str(e)}\")\n",
    "        return f\"Error searching Wikipedia for '{input}': {str(e)}\"\n",
    "\n",
    "\n",
    "def wiki_search(q: str) -> dict:\n",
    "    \"\"\"Return structured output including text and source.\"\"\"\n",
    "    logger.info(f\"üîç wiki_search: Starting search for '{q}'\")\n",
    "\n",
    "    try:\n",
    "        result = wiki_tool.run(q)\n",
    "\n",
    "        if not result or result.strip() == \"\":\n",
    "            logger.warning(f\"‚ö†Ô∏è wiki_search: Empty result for '{q}'\")\n",
    "            return {\"text\": \"No results found\", \"source\": \"Wikipedia\", \"query\": q}\n",
    "\n",
    "        result_length = len(result)\n",
    "        logger.info(f\"‚úÖ wiki_search: Retrieved {result_length} characters for '{q}'\")\n",
    "\n",
    "        return {\"text\": result, \"source\": \"Wikipedia\", \"query\": q}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå wiki_search failed for '{q}': {str(e)}\")\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None, \"query\": q}\n",
    "\n",
    "\n",
    "# Web Search Tool\n",
    "def web_search(q: str) -> dict:\n",
    "    \"\"\"Search the web using DuckDuckGo for information.\"\"\"\n",
    "    logger.info(f\"üåê web_search: Starting web search for '{q}'\")\n",
    "\n",
    "    try:\n",
    "        results = DDGS().text(\n",
    "            q, region=\"us-en\", safesearch=\"off\", max_results=DDGS_MAX_RESULTS\n",
    "        )\n",
    "\n",
    "        if not results:\n",
    "            logger.warning(f\"‚ö†Ô∏è web_search: No results found for '{q}'\")\n",
    "            return {\n",
    "                \"text\": [],\n",
    "                \"source\": \"DuckDuckGo\",\n",
    "                \"query\": q,\n",
    "                \"results_found\": 0,\n",
    "            }\n",
    "\n",
    "        logger.info(f\"‚úÖ web_search: Found {len(results)} results for '{q}'\")\n",
    "\n",
    "        # Log sample of top results for debugging\n",
    "        if results:\n",
    "            top_titles = [\n",
    "                r.get(\"title\", \"No title\")[:TITLE_SLICE_LENGTH]\n",
    "                for r in results[:TOP_RESULTS_COUNT]\n",
    "            ]\n",
    "            logger.debug(f\"üìã web_search: Top results for '{q}': {top_titles}\")\n",
    "\n",
    "        return {\n",
    "            \"text\": results,\n",
    "            \"source\": \"DuckDuckGo\",\n",
    "            \"query\": q,\n",
    "            \"results_found\": len(results),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå web_search failed for '{q}': {str(e)}\")\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None, \"query\": q}\n",
    "\n",
    "\n",
    "def web_fetch(\n",
    "    url: str, max_content_length: int = WEB_CONTENT_MAX_LENGTH\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch web page content using Selenium for JavaScript-heavy sites.\n",
    "\n",
    "    Args:\n",
    "        url: The URL to fetch content from\n",
    "        max_content_length: Maximum content length to return. Defaults to WEB_CONTENT_MAX_LENGTH\n",
    "\n",
    "    Returns:\n",
    "        Dict with keys: content, url, status, error (if any)\n",
    "    \"\"\"\n",
    "    logger.info(\n",
    "        f\"üåê web_fetch: Starting fetch for {url} (max_length: {max_content_length})\"\n",
    "    )\n",
    "\n",
    "    loader = None\n",
    "\n",
    "    try:\n",
    "        # Validate URL\n",
    "        if not url or not url.startswith((\"http://\", \"https://\")):\n",
    "            return {\n",
    "                \"content\": \"\",\n",
    "                \"url\": url,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"Invalid URL format\",\n",
    "            }\n",
    "\n",
    "        # Configure Selenium loader\n",
    "        loader = SeleniumURLLoader(\n",
    "            urls=[url],\n",
    "            continue_on_failure=True,\n",
    "            arguments=_get_selenium_arguments(),\n",
    "            browser=\"chrome\",\n",
    "        )\n",
    "\n",
    "        # Load content\n",
    "        logger.info(f\"üì• web_fetch: Loading content from {url}\")\n",
    "        documents = loader.load()\n",
    "\n",
    "        if not documents:\n",
    "            logger.warning(f\"‚ö†Ô∏è web_fetch: No documents loaded from {url}\")\n",
    "            return {\n",
    "                \"content\": \"\",\n",
    "                \"url\": url,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"No content could be loaded from URL\",\n",
    "            }\n",
    "\n",
    "        # Process content\n",
    "        content = documents[0].page_content.strip()\n",
    "        original_length = len(content)\n",
    "\n",
    "        logger.debug(f\"üìä web_fetch: Loaded {original_length} characters from {url}\")\n",
    "\n",
    "        if len(content) < WEB_CONTENT_MIN_LENGTH:\n",
    "            logger.warning(\n",
    "                f\"‚ö†Ô∏è web_fetch: Content too short ({len(content)} chars) from {url}\"\n",
    "            )\n",
    "            return {\n",
    "                \"content\": content,\n",
    "                \"url\": url,\n",
    "                \"status\": \"warning\",\n",
    "                \"error\": \"Content appears too short, may indicate loading issues\",\n",
    "            }\n",
    "\n",
    "        # Truncate if too long\n",
    "        if len(content) > max_content_length:\n",
    "            content = content[:max_content_length] + \"\\n\\n[Content truncated...]\"\n",
    "            logger.info(\n",
    "                f\"‚úÇÔ∏è web_fetch: Content truncated from {original_length} to {max_content_length} chars for {url}\"\n",
    "            )\n",
    "\n",
    "        logger.info(\n",
    "            f\"‚úÖ web_fetch: Successfully fetched {len(content)} characters from {url}\"\n",
    "        )\n",
    "\n",
    "        return {\"content\": content, \"url\": url, \"status\": \"success\", \"error\": None}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå web_fetch failed for {url}: {str(e)}\")\n",
    "        return {\n",
    "            \"content\": \"\",\n",
    "            \"url\": url,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": f\"Failed to fetch content: {str(e)}\",\n",
    "        }\n",
    "\n",
    "    finally:\n",
    "        # CRITICAL: Clean up browser resources\n",
    "        if loader and hasattr(loader, \"web_driver\") and loader.web_driver:\n",
    "            try:\n",
    "                loader.web_driver.quit()\n",
    "                logger.debug(f\"üßπ web_fetch: Browser cleaned up for {url}\")\n",
    "            except Exception as cleanup_error:\n",
    "                logger.warning(f\"‚ö†Ô∏è web_fetch: Browser cleanup failed: {cleanup_error}\")\n",
    "\n",
    "\n",
    "def _get_selenium_arguments() -> List[str]:\n",
    "    \"\"\"Get optimized Selenium browser arguments for reliability and stealth.\n",
    "    Returns:\n",
    "        List of browser arguments\n",
    "    \"\"\"\n",
    "    return [\n",
    "        # Core stability\n",
    "        \"--headless\",\n",
    "        \"--no-sandbox\",\n",
    "        \"--disable-dev-shm-usage\",\n",
    "        \"--disable-gpu\",\n",
    "        f\"--window-size={SELENIUM_WINDOW_SIZE}\",\n",
    "        # Performance\n",
    "        \"--disable-extensions\",\n",
    "        \"--disable-plugins\",\n",
    "        \"--disable-images\",\n",
    "        \"--disable-javascript\",\n",
    "        # Stealth and compatibility\n",
    "        \"--disable-blink-features=AutomationControlled\",\n",
    "        f\"--user-agent={BROWSER_USER_AGENT}\",\n",
    "        # GDPR/Cookie banner handling\n",
    "        \"--disable-notifications\",\n",
    "        \"--disable-infobars\",\n",
    "        \"--disable-default-apps\",\n",
    "        # Security bypasses (use cautiously)\n",
    "        \"--ignore-certificate-errors\",\n",
    "        \"--ignore-ssl-errors\",\n",
    "        \"--allow-running-insecure-content\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def web_fetch_multiple(\n",
    "    urls: List[str], max_content_length: int = WEB_CONTENT_MAX_LENGTH\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch content from multiple URLs efficiently.\n",
    "\n",
    "    Args:\n",
    "        urls: List of URLs to fetch\n",
    "        max_content_length: Maximum content length per URL\n",
    "\n",
    "    Returns:\n",
    "        Dict with results for each URL and summary statistics\n",
    "    \"\"\"\n",
    "    logger.info(f\"üåê web_fetch_multiple: Starting batch fetch for {len(urls)} URLs\")\n",
    "\n",
    "    if not urls or len(urls) > WEB_BATCH_MAX_URLS:\n",
    "        logger.warning(\n",
    "            f\"‚ö†Ô∏è web_fetch_multiple: Invalid URL list - {len(urls) if urls else 0} URLs (max {WEB_BATCH_MAX_URLS})\"\n",
    "        )\n",
    "        return {\n",
    "            \"results\": [],\n",
    "            \"status\": \"error\",\n",
    "            \"error\": f\"Invalid URL list (empty or too many URLs, max {WEB_BATCH_MAX_URLS})\",\n",
    "        }\n",
    "\n",
    "    results = []\n",
    "    success_count = 0\n",
    "\n",
    "    logger.debug(\n",
    "        f\"üìã web_fetch_multiple: Processing URLs: {[f'{url[:TITLE_SLICE_LENGTH]}...' if len(url) > TITLE_SLICE_LENGTH else url for url in urls]}\"\n",
    "    )\n",
    "\n",
    "    for i, url in enumerate(urls, 1):\n",
    "        logger.debug(f\"üîÑ web_fetch_multiple: Processing URL {i}/{len(urls)}: {url}\")\n",
    "\n",
    "        result = web_fetch(url, max_content_length)\n",
    "        results.append(result)\n",
    "\n",
    "        if result[\"status\"] == \"success\":\n",
    "            success_count += 1\n",
    "            logger.debug(f\"‚úÖ web_fetch_multiple: URL {i}/{len(urls)} successful\")\n",
    "        else:\n",
    "            logger.debug(\n",
    "                f\"‚ùå web_fetch_multiple: URL {i}/{len(urls)} failed: {result.get('error', 'Unknown error')}\"\n",
    "            )\n",
    "\n",
    "        # Brief delay to be respectful\n",
    "        time.sleep(URL_FETCH_DELAY)\n",
    "\n",
    "    logger.info(\n",
    "        f\"üèÅ web_fetch_multiple: Completed batch - {success_count}/{len(urls)} successful\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"total_urls\": len(urls),\n",
    "        \"successful\": success_count,\n",
    "        \"failed\": len(urls) - success_count,\n",
    "        \"status\": \"completed\",\n",
    "    }\n",
    "\n",
    "\n",
    "def save_report(\n",
    "    content: str, task_description: str, reports_dir: str = \"reports\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Save timestamped Markdown report to disk with auto-generated filename.\n",
    "\n",
    "    Args:\n",
    "        content: Report content (plain text or Markdown). Auto-adds title if missing.\n",
    "        task_description: Brief task description for filename generation.\n",
    "        reports_dir: Output directory (default: \"reports\"). Created if missing.\n",
    "\n",
    "    Returns:\n",
    "        Dict with keys: status (\"success\"/\"error\"), filepath, filename, error\n",
    "\n",
    "    Examples:\n",
    "        save_report(\"# Analysis\\n\\nFindings...\", \"market research 2024\")\n",
    "        # ‚Üí reports/20250821_1430_market_research.md\n",
    "\n",
    "        save_report(draft_text, \"AI impact assessment\")\n",
    "        # ‚Üí reports/20250821_1431_ai_impact.md\n",
    "\n",
    "    Filename: YYYYMMDD_HHMM_key_words.md (auto-numbered if exists)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure reports directory exists\n",
    "        reports_path = Path(reports_dir)\n",
    "        reports_path.mkdir(exist_ok=True)\n",
    "\n",
    "        # Generate timestamped filename\n",
    "        timestamp = datetime.now()\n",
    "        date_time = timestamp.strftime(\"%Y%m%d_%H%M\")\n",
    "        task_name = _extract_task_name(task_description)\n",
    "\n",
    "        filename = f\"{date_time}_{task_name}.md\"\n",
    "        filepath = reports_path / filename\n",
    "\n",
    "        # Handle filename conflicts with counter\n",
    "        counter = 1\n",
    "        while filepath.exists():\n",
    "            filename = f\"{date_time}_{task_name}_{counter}.md\"\n",
    "            filepath = reports_path / filename\n",
    "            counter += 1\n",
    "\n",
    "        # Format content with title if needed\n",
    "        formatted_content = _format_content(content, task_description, timestamp)\n",
    "\n",
    "        # Save to disk using Path object\n",
    "        filepath.write_text(formatted_content, encoding=\"utf-8\")\n",
    "        logger.info(f\"üìÑ Report saved: {filepath}\")\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"filepath\": str(filepath),\n",
    "            \"filename\": filename,\n",
    "            \"timestamp\": timestamp.isoformat(),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to save report: {str(e)}\"\n",
    "        logger.error(f\"‚ùå {error_msg}\")\n",
    "        return {\"status\": \"error\", \"error\": error_msg, \"task\": task_description}\n",
    "\n",
    "\n",
    "def _extract_task_name(task: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract 2-3 meaningful words from task description for filename.\n",
    "\n",
    "    Args:\n",
    "        task: The task description string\n",
    "\n",
    "    Returns:\n",
    "        Underscore-separated words suitable for filename\n",
    "    \"\"\"\n",
    "    # Clean special characters and normalize\n",
    "    clean_task = re.sub(r\"[^\\w\\s]\", \" \", task.lower())\n",
    "    words = [w for w in clean_task.split() if len(w) > 2]\n",
    "\n",
    "    # Filter common stop words\n",
    "    stop_words = {\n",
    "        \"the\",\n",
    "        \"and\",\n",
    "        \"for\",\n",
    "        \"with\",\n",
    "        \"from\",\n",
    "        \"about\",\n",
    "        \"into\",\n",
    "        \"through\",\n",
    "        \"during\",\n",
    "        \"before\",\n",
    "        \"after\",\n",
    "        \"above\",\n",
    "        \"below\",\n",
    "        \"over\",\n",
    "        \"under\",\n",
    "    }\n",
    "    meaningful = [w for w in words if w not in stop_words][:TASK_MAX_MEANINGFUL_WORDS]\n",
    "\n",
    "    return \"_\".join(meaningful) if meaningful else \"report\"\n",
    "\n",
    "\n",
    "def _format_content(content: str, task: str, timestamp: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Format content with title and timestamp if needed.\n",
    "\n",
    "    Args:\n",
    "        content: Raw content to format\n",
    "        task: Task description for title generation\n",
    "        timestamp: When the report was created\n",
    "\n",
    "    Returns:\n",
    "        Formatted Markdown content\n",
    "    \"\"\"\n",
    "    # If content already has a Markdown title, use as-is\n",
    "    if content.strip().startswith(\"#\"):\n",
    "        return content\n",
    "\n",
    "    # Add title and timestamp for plain text content\n",
    "    formatted_title = f\"# Report: {task}\"\n",
    "    timestamp_line = f\"*Generated: {timestamp.strftime('%Y-%m-%d %H:%M')}*\"\n",
    "\n",
    "    return f\"{formatted_title}\\n\\n{timestamp_line}\\n\\n{content}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291cb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REGISTER FUNCTIONS AS TOOLS\n",
    "\n",
    "wiki_search_tool = Tool.from_function(wiki_search, name=\"wiki_search\")\n",
    "web_search_tool = Tool.from_function(web_search, name=\"web_search\")\n",
    "web_fetch_tool = Tool.from_function(web_fetch, name=\"web_fetch\")\n",
    "web_fetch_multiple_tool = Tool.from_function(\n",
    "    web_fetch_multiple, name=\"web_fetch_multiple\"\n",
    ")\n",
    "save_report_tool = Tool.from_function(save_report, name=\"save_report\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SYSTEM PROMPTS\n",
    "\n",
    "### References\n",
    "# https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\n",
    "# https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/prompt-engineering-for-openai%E2%80%99s-o1-and-o3-mini-reasoning-models/4374010\n",
    "\n",
    "today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "PLANNER_SYSTEM_PROMPT = f\"\"\"You are a Strategic Research Planner. Define research scope and success criteria. Today is {today_str}.\n",
    "\n",
    "ROLE FOCUS:\n",
    "- Define WHAT needs to be researched (scope, objectives, key questions)\n",
    "- Set measurable success criteria\n",
    "- Identify critical knowledge gaps to fill\n",
    "- DO NOT specify search strategies or tools (Researcher's domain)\n",
    "- You ONLY plan and delegate tasks - you do not execute them yourself.\n",
    "- Your TEAM MEMBERS are:\n",
    "    - Researcher: Gathers evidence and conducts analysis\n",
    "    - Critic: Evaluates plans and outputs\n",
    "    - Editor: Polishes final reports\n",
    "\n",
    "WORKFLOW:\n",
    "1. Analyze user query: Extract core research questions\n",
    "2. Define research objectives with measurable outcomes\n",
    "3. Set success criteria that directly address user needs\n",
    "4. Request Critic review: \"Critic, evaluate this plan against the user query\"\n",
    "5. Declare \"PLAN_COMPLETE\" only after Critic approval\n",
    "\n",
    "REPLANNING (when research fails):\n",
    "1. Analyze what failed and why\n",
    "2. Pivot strategy with new approach\n",
    "3. Request Critic review of revised plan\n",
    "4. Declare \"REVISED_PLAN_COMPLETE\" after approval\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "## Research Objectives\n",
    "[List 3-5 specific objectives]\n",
    "\n",
    "## Key Research Questions\n",
    "[Questions that directly address user query]\n",
    "\n",
    "## Success Criteria\n",
    "[Measurable outcomes that satisfy user requirements]\n",
    "\n",
    "## Critical Knowledge Gaps\n",
    "[What must be discovered to answer user query]\n",
    "\n",
    "Today is {today_str}. Focus on research scope, not execution methodology.\"\"\"\n",
    "\n",
    "RESEARCHER_SYSTEM_PROMPT = f\"\"\"Senior Research Analyst. Gather comprehensive evidence using strategic tool selection. Today is {today_str}. Use this for context when needed.\n",
    "\n",
    "TOOLS:\n",
    "- wiki_search: Background, definitions, historical context\n",
    "- web_search: Current events, market data, recent reports\n",
    "- web_fetch: Deep content extraction from specific URLs (handles JS-heavy sites)\n",
    "- web_fetch_multiple: Batch fetch multiple URLs efficiently\n",
    "\n",
    "EXECUTION WORKFLOW:\n",
    "0. Start only if the plan is approved by critic.\n",
    "1. Foundation research (wiki_search)\n",
    "2. Current intelligence (web_search, web_fetch, web_fetch_multiple)\n",
    "4. Cross-validation and synthesis\n",
    "\n",
    "COMPLETION SIGNALS:\n",
    "- When research is sufficient, end with: \"## RESEARCH COMPLETE\"\n",
    "- For incomplete research, end with: \"## CONTINUING RESEARCH\" \n",
    "- Never hand off raw tool outputs - always synthesize findings first\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "# Evidence Summary: [Topic]\n",
    "## Key Findings\n",
    "[Synthesized insights from multiple sources]\n",
    "## Current Intelligence  \n",
    "[Recent developments and data]\n",
    "## Source Assessment\n",
    "[Quality and reliability of sources used]\n",
    "## Research Gaps\n",
    "[Areas needing further investigation]\n",
    "\n",
    "## RESEARCH COMPLETE\n",
    "[Only when comprehensive evidence gathered]\n",
    "\n",
    "Focus on quality, not presentation. Hand off to Editor for final reports.\n",
    "\"\"\"\n",
    "\n",
    "CRITIC_SYSTEM_PROMPT = \"\"\"You are a Domain-agnostic Critic. Provide concise, evidence-based critique. Adapt evaluation based on artifact type.\n",
    "\n",
    "FORMAT:\n",
    "1. ARTIFACT: Type and goal (1 line)\n",
    "2. STRENGTHS AND CONTEXT CHECK: Does this address the goal? Up to 3 key strengths.\n",
    "3. ISSUES: Highlight unclear or weak sections. Challenge assumptions. Label issues Critical/Major/Minor\n",
    "4. VERACITY: Source verification requests. If sources could not be found, mark as unverified and opinion-based.\n",
    "5. VERDICT: Accept/Revise/Reject + confidence level.\n",
    "6. NEXT ACTIONS: [What needs to happen]\n",
    "\n",
    "Respond \"APPROVED\" only when artifact fully serves user needs. Max 500 words total.\"\"\"\n",
    "\n",
    "EDITOR_SYSTEM_PROMPT = \"\"\"You are a Editorial Agent. Transform evidence into polished reports. Adapt structure to content type. Focus on actionable insights with proper citations.\n",
    "\n",
    "STANDARDS:\n",
    "- Synthesis over summary\n",
    "- Quantify impact with metrics\n",
    "- Professional structure and tone\n",
    "- Proper citations [1], [2]\n",
    "- Use save_report tool for final output\n",
    "\n",
    "CITATION FORMAT:\n",
    "- Use reference IDs from researcher's URL references\n",
    "- Format: \"Key finding from recent study [1]\"\n",
    "- References section with each reference on a separate line. Format: [1] Source (URL)\n",
    "\n",
    "TERMINATION: After save: \"REPORT_SAVED. TASK_COMPLETED. TERMINATE\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGENT SETUP\n",
    "\n",
    "\n",
    "planner = AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    model_client=gemini_model_client,\n",
    "    system_message=PLANNER_SYSTEM_PROMPT,\n",
    "    description=\"Creates and adapts research plans, handles replanning when research hits obstacles\",\n",
    ")\n",
    "\n",
    "researcher = AssistantAgent(\n",
    "    name=\"Researcher\",\n",
    "    description=\"Expert research agent that strategically uses multiple tools to gather comprehensive and factual evidence to produce well-researched draft reports.\",\n",
    "    model_client=gemini_model_client,\n",
    "    tools=[wiki_search_tool, web_search_tool, web_fetch_tool, web_fetch_multiple_tool],\n",
    "    reflect_on_tool_use=False,\n",
    "    system_message=RESEARCHER_SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "critic = AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    model_client=gemini_model_client,\n",
    "    system_message=CRITIC_SYSTEM_PROMPT,\n",
    "    description=\"Reviews and provides constructive criticism; outputs 'APPROVED: [...]' when ready.\",\n",
    ")\n",
    "\n",
    "\n",
    "editor = AssistantAgent(\n",
    "    name=\"Editor\",\n",
    "    description=\"Formats approved drafts with proper citations, adapts structure to content type.\",\n",
    "    model_client=gemini_model_client,\n",
    "    tools=[save_report_tool],\n",
    "    system_message=EDITOR_SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "# ---------- Selector prompt with few-shot examples ----------\n",
    "selector_prompt = \"\"\"Select an agent to perform task.\n",
    "AGENT ROLES: \n",
    "{roles}\n",
    "\n",
    "CONVERSATION HISTORY: \n",
    "{history}\n",
    "\n",
    "RULES:\n",
    "- Return the selected agent's name (no extra text).\n",
    "\n",
    "Read the above conversation, then select an agent from {participants} to perform the next task.\n",
    "When the task is complete, let the user approve or disapprove the task.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Team configuration with constants\n",
    "max_messages = TASK_TERMINATION_MAX_MESSAGES\n",
    "txt_termination = TextMentionTermination(\"TERMINATE\")\n",
    "termination_condition = (\n",
    "    MaxMessageTermination(max_messages=max_messages) | txt_termination\n",
    ")\n",
    "\n",
    "# Build SelectorGroupChat\n",
    "\n",
    "model_context = BufferedChatCompletionContext(buffer_size=CONVERSATION_BUFFER_SIZE)\n",
    "\n",
    "team = SelectorGroupChat(\n",
    "    name=\"Deep Research Team\",\n",
    "    description=\"A team of specialized agents working together to conduct deep research.\",\n",
    "    model_context=model_context,\n",
    "    participants=[planner, researcher, critic, editor],\n",
    "    model_client=gemini_model_client,\n",
    "    selector_prompt=selector_prompt,\n",
    "    termination_condition=termination_condition,\n",
    "    emit_team_events=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETUP TASK RUN\n",
    "\n",
    "\n",
    "# @tenacity.retry(\n",
    "#     wait=tenacity.wait_exponential(multiplier=1, min=60, max=120),\n",
    "#     stop=tenacity.stop_after_attempt(2),\n",
    "#     retry=tenacity.retry_if_exception_type(Exception),\n",
    "# )\n",
    "async def run_task(task_text: str):\n",
    "    \"\"\"\n",
    "    Execute a multi-agent research task with proper termination handling.\n",
    "\n",
    "    Args:\n",
    "        task_text (str): The research task description\n",
    "\n",
    "    Returns:\n",
    "        str | None: Final report content or None if task incomplete\n",
    "    \"\"\"\n",
    "    final_report = None\n",
    "    task_completed = False\n",
    "\n",
    "    # Token tracking variables\n",
    "    total_prompt_tokens = 0\n",
    "    total_completion_tokens = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"üöÄ Starting task: {task_text}\\n\\n\")\n",
    "\n",
    "        async for event in team.run_stream(task=task_text):\n",
    "            logger.info(f\"üìù Event: {event}\\n\\n\")\n",
    "\n",
    "            # Track tokens if available\n",
    "            if hasattr(event, \"models_usage\") and event.models_usage:\n",
    "                current_prompt = event.models_usage.prompt_tokens\n",
    "                current_completion = event.models_usage.completion_tokens\n",
    "                current_total = current_prompt + current_completion\n",
    "\n",
    "                # Update running totals\n",
    "                total_prompt_tokens += current_prompt\n",
    "                total_completion_tokens += current_completion\n",
    "                total_tokens += current_total\n",
    "\n",
    "            logger.info(\n",
    "                f\"\\nüìä Token Usage: \\n\\tPrompts: {total_prompt_tokens} \\n\\tCompletions: {total_completion_tokens} \\n\\tTotal: {total_tokens}\"\n",
    "            )\n",
    "\n",
    "            # Check for TERMINATE keyword in message content\n",
    "            if hasattr(event, \"content\") and isinstance(event.content, str):\n",
    "                if \"TERMINATE\" in event.content:\n",
    "                    final_report = event.content.split(\"TERMINATE\", 1)[0].strip()\n",
    "                    task_completed = True\n",
    "                    logger.info(f\"\\n\\n‚úÖ Task completed with TERMINATE signal\")\n",
    "                    logger.info(\n",
    "                        f\"üìä Final Token Usage - Total: {total_tokens} (prompt: {total_prompt_tokens}, completion: {total_completion_tokens})\"\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "            if hasattr(event, \"models_usage\") and event.models_usage:\n",
    "                # This event involved a model API call - apply rate limiting\n",
    "                logger.info(\n",
    "                    f\"\\n\\n‚è≥ Model API call detected, waiting {API_CALL_DELAY_SECONDS} seconds.\\n\\n\"\n",
    "                )\n",
    "                await asyncio.sleep(API_CALL_DELAY_SECONDS)\n",
    "            else:\n",
    "                # Non-API event (planning, internal processing) - minimal delay\n",
    "                logger.debug(\n",
    "                    f\"\\n\\nüí® Non-API event, brief pause ({NON_API_EVENT_DELAY}s)\\n\\n\"\n",
    "                )\n",
    "                await asyncio.sleep(NON_API_EVENT_DELAY)\n",
    "\n",
    "        # Log final totals even if task didn't complete normally\n",
    "        if not task_completed:\n",
    "            logger.info(\n",
    "                f\"üìä Final Token Usage - Total: {total_tokens} (prompt: {total_prompt_tokens}, completion: {total_completion_tokens})\"\n",
    "            )\n",
    "\n",
    "        return final_report if task_completed else None\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"\\n\\n‚ùå Exception during task execution: {e}\")\n",
    "        logger.info(\n",
    "            f\"üìä Token Usage at Error - Total: {total_tokens} (prompt: {total_prompt_tokens}, completion: {total_completion_tokens})\"\n",
    "        )\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        await _save_team_state()\n",
    "\n",
    "\n",
    "async def _save_team_state():\n",
    "    \"\"\"Helper function to save team state with error handling using Path objects.\"\"\"\n",
    "    try:\n",
    "        state = await team.save_state()\n",
    "        state_file = Path(\"team_state.json\")\n",
    "\n",
    "        with state_file.open(\"w\") as f:\n",
    "            json.dump(state, f, indent=2)\n",
    "        logger.info(\"üíæ Team state saved successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to save team state: {e}\")\n",
    "\n",
    "\n",
    "async def resume_from_saved_state():\n",
    "    \"\"\"Resume execution from previously saved team state using Path objects.\"\"\"\n",
    "    try:\n",
    "        state_file = Path(\"team_state.json\")\n",
    "\n",
    "        with state_file.open(\"r\") as f:\n",
    "            saved_state = json.load(f)\n",
    "\n",
    "        await team.load_state(saved_state)\n",
    "        logger.info(\"üîÑ Resuming from saved state\")\n",
    "\n",
    "        async for event in team.run_stream():\n",
    "            logger.info(f\"üìù Resume Event: {event}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"‚ùå No saved state file found\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to resume from saved state: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb513d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN TASK\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    __SAMPLE_QUERY_1 = \"Indian steel sector growth post modernization and growth prospects in an era of US tariffs and reduce government protection through trade barriers and cheaper import options from China\"\n",
    "\n",
    "    __SAMPLE_QUERY_2 = \"How government and governance factors improved economy and lives of indians during Modi and Pre-Modi starting from 1991\"\n",
    "\n",
    "    __SAMPLE_QUERY_3 = \"Sectoral growth based on cyclics for 2025 and macro economic pressure and trade tariffs and uncertainty, which sectors are best poised for maximum investment returns in terms of % for the next year for a moderate to average risk profile investments\"\n",
    "\n",
    "    __SAMPLE_QUERY_4 = \"Hyperscaler investments in data centers and cloud infrastructure for AI growth is not matching the proposed productivity gains in GDP. Are we witnessing a bubble? Is % of global GDP being invested in AI infrastructure matches the productivity gain percentages?\"\n",
    "\n",
    "    __SAMPLE_QUERY_5 = \"If neural networks are foundation of LLMs and based on the human brain; Are LLMs given tools during training? Humans learn with tool usage, What are current trends on tool usage in LLM training?\"\n",
    "\n",
    "    __SAMPLE_QUERY_6 = f\"Today is {today_str}. Analyze stock price performance of Nvidia in the past month, compare it with top 3 listed POWER Producers in India.\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        output = asyncio.run(run_task(__SAMPLE_QUERY_1))\n",
    "        if output:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"üéØ FINAL REPORT\")\n",
    "            print(\"=\" * 60)\n",
    "            print(output)\n",
    "        else:\n",
    "            print(\"‚ùå Task did not complete successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Fatal error: {e}\")\n",
    "        print(f\"‚ùå Execution failed: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
