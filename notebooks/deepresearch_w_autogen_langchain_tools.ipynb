{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bc3cfa",
   "metadata": {},
   "source": [
    "# Orchestrate Multiple-Agents for High-Quality Research with AutoGen and LangChain Tools\n",
    "\n",
    "This notebook showcases how to harness the combined power of **AutoGen** and **LangChain** tools to automate and elevate deep research workflows. At its core, the system coordinates a network of specialized agents—each executing a distinct role in the research and report generation workflow. Together, these agents collect data, analyze findings, and produce polished, insight-driven reports.\n",
    "\n",
    "\n",
    "[Open in Colab](https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb) <a href=\"https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "## 🧠 Agent Roles Overview\n",
    "\n",
    "- **🧭 Planner Agent**  \n",
    "  Defines the research scope, objectives, and key questions.  \n",
    "  → Anchors the process by structuring it around a well-defined `__TASK_QUERY`.\n",
    "\n",
    "- **🔍 Researcher Agent**  \n",
    "  Gathers information using tools like `wiki_search` and `duckduckgo_search`.  \n",
    "  → Supplies the system with relevant, factual data.\n",
    "\n",
    "- **🧪 Critic Agent**  \n",
    "  Reviews the research plan, gathered evidence, and drafted reports.  \n",
    "  → Provides feedback to enforce analytical rigor and clarity.\n",
    "\n",
    "- **✍️ Editor Agent**  \n",
    "  Refines the final report's language, structure, and presentation.  \n",
    "  → Ensures clarity, polish, and alignment with stakeholder expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "%pip install -qU ipykernel\n",
    "%pip install -qU autogen-agentchat\n",
    "%pip install -qU autogen-ext\n",
    "\n",
    "%pip install -qU loguru\n",
    "\n",
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-community\n",
    "%pip install -qU wikipedia\n",
    "%pip install -qU lxml\n",
    "%pip install -qU ddgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %aimport -langchain_community\n",
    "# Automatically reload modules before executing code\n",
    "\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import asyncio\n",
    "import sys\n",
    "\n",
    "# import logging\n",
    "# logger = logging.getLogger(\"\")\n",
    "\n",
    "\n",
    "# # Remove all existing handlers\n",
    "# for handler in logger.handlers[:]:\n",
    "#     logger.removeHandler(handler)\n",
    "\n",
    "# REMOVE ALL EXISTING HANDLERS for LOGURU\n",
    "# if len(logger._core.handlers) > 1:\n",
    "#     logger.configure(handlers=[])\n",
    "\n",
    "# logger.add(\n",
    "#     sys.stderr,\n",
    "#     format=\"{time:HH:mm:ss:SSS} | {level} | {name}:{line} | {message}\",\n",
    "#     level=\"INFO\",\n",
    "#     colorize=True,\n",
    "# )\n",
    "\n",
    "# Configure file logging with better settings\n",
    "\n",
    "# notebook_dir = Path.cwd()\n",
    "# log_file = notebook_dir / \"logs\" / \"llm_execution.log\"\n",
    "# log_file.parent.mkdir(exist_ok=True)\n",
    "# logger.add(\n",
    "#     log_file,\n",
    "#     format=\"{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} | {message}\",\n",
    "#     level=\"DEBUG\",\n",
    "#     rotation=\"10 MB\",\n",
    "#     retention=\"7 days\",\n",
    "#     compression=\"zip\",\n",
    "#     enqueue=True,\n",
    "# )\n",
    "logger.info(f\"✅ Logging configured successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef193373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "\n",
    "# Confirm the API key is set\n",
    "assert os.environ[\"GEMINI_API_KEY\"], \"GEMINI_API_KEY is not set\"\n",
    "assert os.environ[\"GEMINI_MODEL_NAME\"], \"GEMINI_MODEL_NAME is not set\"\n",
    "assert os.environ[\"GEMINI_BASE_URL\"], \"GEMINI_BASE_URL is not set\"\n",
    "assert os.environ[\"RATE_LIMIT_GEMINI_RPM\"], \"RATE_LIMIT_GEMINI_RPM is not set\"\n",
    "assert os.environ[\"RATE_LIMIT_GEMINI_RPD\"], \"RATE_LIMIT_GEMINI_RPD is not set\"\n",
    "\n",
    "\n",
    "model_info = ModelInfo(\n",
    "    vision=True,\n",
    "    function_calling=True,\n",
    "    json_output=True,\n",
    "    family=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    structured_output=True,\n",
    ")\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    base_url=os.environ[\"GEMINI_BASE_URL\"],\n",
    "    model_info=model_info,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, json, os\n",
    "import tenacity\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.messages import StopMessage\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "from ddgs import DDGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent Tools\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Wiki Search Tool\n",
    "wiki_api = WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=2000)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api)\n",
    "\n",
    "\n",
    "def wiki_search(q: str) -> dict:\n",
    "    \"\"\"Return structured output including text and source.\"\"\"\n",
    "    try:\n",
    "        result = wiki_tool.run(q)\n",
    "        return {\"text\": result, \"source\": \"Wikipedia\"}\n",
    "    except Exception as e:\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None}\n",
    "\n",
    "# DuckDuckGo Search Tool\n",
    "def duckduckgo_search(q: str) -> dict:\n",
    "    \"\"\"Search the web using DuckDuckGo for information.\"\"\"\n",
    "    try:\n",
    "        results = DDGS().text(q, region=\"us-en\", safesearch=\"off\", max_results=12)\n",
    "        return {\n",
    "            \"text\": results,\n",
    "            \"source\": \"DuckDuckGo\",\n",
    "            \"query\": q,\n",
    "            \"results_found\": len(results),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None}\n",
    "\n",
    "def save_report(content: str, task_description: str, reports_dir: str = \"reports\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Save a report to disk with automatic filename generation.\n",
    "    \n",
    "    This tool creates a timestamped Markdown file in the reports directory.\n",
    "    Perfect for preserving research findings, analysis results, or final reports.\n",
    "    \n",
    "    Args:\n",
    "        content (str): The report content to save. Can be plain text or Markdown.\n",
    "                      If no title (# header) is present, one will be auto-generated.\n",
    "        task_description (str): Brief description of the task/topic for filename.\n",
    "                               Example: \"AI impact on power sector analysis\"\n",
    "        reports_dir (str, optional): Directory to save reports. Defaults to \"reports\".\n",
    "                                   Directory will be created if it doesn't exist.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: Result dictionary containing:\n",
    "            - status: \"success\" or \"error\"\n",
    "            - filepath: Full path to saved file (if successful)\n",
    "            - filename: Just the filename (if successful)\n",
    "            - error: Error message (if failed)\n",
    "    \n",
    "    Example Usage for Agents:\n",
    "        # Save research findings\n",
    "        result = save_report(\n",
    "            content=\"# Market Analysis\\\\n\\\\nKey findings: ...\",\n",
    "            task_description=\"cryptocurrency market trends 2024\"\n",
    "        )\n",
    "        \n",
    "        # Save final report\n",
    "        result = save_report(\n",
    "            content=my_report_text,\n",
    "            task_description=\"climate change impact assessment\"\n",
    "        )\n",
    "        \n",
    "        # Check if save was successful\n",
    "        if result[\"status\"] == \"success\":\n",
    "            print(f\"Report saved as: {result['filename']}\")\n",
    "        else:\n",
    "            print(f\"Save failed: {result['error']}\")\n",
    "    \n",
    "    Generated Filename Format:\n",
    "        YYYYMMDD_HHMM_meaningful_task_words.md\n",
    "        Example: 20250819_1430_ai_power_sector.md\n",
    "    \n",
    "    Note: If file exists, automatic numbering prevents overwrites:\n",
    "          20250819_1430_ai_power_sector_1.md, _2.md, etc.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure reports directory exists\n",
    "        reports_path = Path(reports_dir)\n",
    "        reports_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Generate timestamped filename\n",
    "        timestamp = datetime.now()\n",
    "        date_time = timestamp.strftime(\"%Y%m%d_%H%M\")\n",
    "        task_name = _extract_task_name(task_description)\n",
    "        \n",
    "        filename = f\"{date_time}_{task_name}.md\"\n",
    "        filepath = reports_path / filename\n",
    "        \n",
    "        # Handle filename conflicts with counter\n",
    "        counter = 1\n",
    "        while filepath.exists():\n",
    "            filename = f\"{date_time}_{task_name}_{counter}.md\"\n",
    "            filepath = reports_path / filename\n",
    "            counter += 1\n",
    "        \n",
    "        # Format content with title if needed\n",
    "        formatted_content = _format_content(content, task_description, timestamp)\n",
    "        \n",
    "        # Save to disk\n",
    "        filepath.write_text(formatted_content, encoding='utf-8')\n",
    "        logger.info(f\"📄 Report saved: {filepath}\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"filepath\": str(filepath),\n",
    "            \"filename\": filename,\n",
    "            \"timestamp\": timestamp.isoformat()\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to save report: {str(e)}\"\n",
    "        logger.error(f\"❌ {error_msg}\")\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error\": error_msg,\n",
    "            \"task\": task_description\n",
    "        }\n",
    "\n",
    "\n",
    "def _extract_task_name(task: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract 2-3 meaningful words from task description for filename.\n",
    "    \n",
    "    Args:\n",
    "        task: The task description string\n",
    "        \n",
    "    Returns:\n",
    "        Underscore-separated words suitable for filename\n",
    "    \"\"\"\n",
    "    # Clean special characters and normalize\n",
    "    clean_task = re.sub(r'[^\\w\\s]', ' ', task.lower())\n",
    "    words = [w for w in clean_task.split() if len(w) > 2]\n",
    "    \n",
    "    # Filter common stop words\n",
    "    stop_words = {\n",
    "        'the', 'and', 'for', 'with', 'from', 'about', 'into', 'through',\n",
    "        'during', 'before', 'after', 'above', 'below', 'over', 'under'\n",
    "    }\n",
    "    meaningful = [w for w in words if w not in stop_words][:3]\n",
    "    \n",
    "    return '_'.join(meaningful) if meaningful else 'report'\n",
    "\n",
    "\n",
    "def _format_content(content: str, task: str, timestamp: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Format content with title and timestamp if needed.\n",
    "    \n",
    "    Args:\n",
    "        content: Raw content to format\n",
    "        task: Task description for title generation\n",
    "        timestamp: When the report was created\n",
    "        \n",
    "    Returns:\n",
    "        Formatted Markdown content\n",
    "    \"\"\"\n",
    "    # If content already has a Markdown title, use as-is\n",
    "    if content.strip().startswith('#'):\n",
    "        return content\n",
    "    \n",
    "    # Add title and timestamp for plain text content\n",
    "    formatted_title = f\"# Report: {task}\"\n",
    "    timestamp_line = f\"*Generated: {timestamp.strftime('%Y-%m-%d %H:%M')}*\"\n",
    "    \n",
    "    return f\"{formatted_title}\\n\\n{timestamp_line}\\n\\n{content}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "## System Prompts for Agents\n",
    "\n",
    "PLANNER_SYSTEM_PROMPT = \"\"\"You create detailed research plans and handle replanning when obstacles arise.\n",
    "\n",
    "WORKFLOW:\n",
    "1. Draft detailed plan with steps, tools, and success criteria\n",
    "2. Request Critic review: \"Critic, please review this plan\"\n",
    "3. Revise based on feedback\n",
    "4. Declare \"PLAN_COMPLETE\" only after Critic approval\n",
    "\n",
    "REPLANNING (when research fails):\n",
    "1. Analyze what failed and why\n",
    "2. Pivot strategy with new keywords/approach\n",
    "3. Request Critic review of revised plan\n",
    "4. Declare \"REVISED_PLAN_COMPLETE\" after approval\n",
    "\n",
    "Include: objectives, search strategies, tools to use, fallback approaches.\"\"\"\n",
    "\n",
    "RESEARCHER_SYSTEM_PROMPT = \"\"\"Senior Research Analyst. Gather comprehensive evidence using strategic tool selection.\n",
    "\n",
    "TOOLS:\n",
    "- wiki_search: Background, definitions, historical context\n",
    "- duckduckgo_search: Current events, market data, recent reports\n",
    "\n",
    "EXECUTION:\n",
    "1. Foundation research (wiki_search)\n",
    "2. Current intelligence (duckduckgo_search)\n",
    "3. Cross-validation\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "# Evidence Summary: [Topic]\n",
    "## Key Findings\n",
    "## Current Intelligence\n",
    "## Source Assessment\n",
    "## Research Gaps\n",
    "\n",
    "Focus on evidence quality, not presentation. Hand off to Editor for final reports.\"\"\"\n",
    "\n",
    "CRITIC_SYSTEM_PROMPT = \"\"\"Domain-agnostic Critic. Provide concise, evidence-based critique.\n",
    "\n",
    "FORMAT:\n",
    "1. ARTIFACT: Type and goal (1 line)\n",
    "2. STRENGTHS: Up to 3 key strengths\n",
    "3. ISSUES: Critical/Major/Minor with evidence and fixes\n",
    "4. VERDICT: Accept/Revise/Reject + confidence\n",
    "5. VERACITY: Source verification requests\n",
    "\n",
    "Respond \"APPROVED: [summary]\" when satisfied. Max 300 words total.\"\"\"\n",
    "\n",
    "EDITOR_SYSTEM_PROMPT = \"\"\"Editorial Agent. Transform evidence into polished reports.\n",
    "\n",
    "STANDARDS:\n",
    "- Synthesis over summary\n",
    "- Quantify impact with metrics\n",
    "- Professional structure and tone\n",
    "- Proper citations [1], [2]\n",
    "- Use save_report tool for final output\n",
    "\n",
    "TERMINATION: After save: \"REPORT_SAVED. TASK_COMPLETED. TERMINATE\"\n",
    "\n",
    "Adapt structure to content type. Focus on actionable insights.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert os.environ[\"OPENAI_API_KEY\"], \"OPENAI_API_KEY is not set\"\n",
    "# model_client = OpenAIChatCompletionClient(\n",
    "#     model=\"gpt-4o\", api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    "# )\n",
    "\n",
    "# ---------- Agents ----------\n",
    "from regex import R\n",
    "\n",
    "\n",
    "planner = AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    model_client=model_client,\n",
    "    system_message=PLANNER_SYSTEM_PROMPT,\n",
    "    description=\"Creates and adapts research plans, handles replanning when research hits obstacles\",\n",
    ")\n",
    "\n",
    "researcher = AssistantAgent(\n",
    "    name=\"Researcher\",\n",
    "    description=\"Expert research agent that strategically uses multiple tools to gather comprehensive, factual evidence and produces evidence-based draft reports.\",\n",
    "    model_client=model_client,\n",
    "    tools=[wiki_search, duckduckgo_search],\n",
    "    system_message=RESEARCHER_SYSTEM_PROMPT\n",
    ")\n",
    "\n",
    "critic = AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=CRITIC_SYSTEM_PROMPT,\n",
    "    description=\"Reviews and provides constructive criticism; outputs 'APPROVED: [...]' when ready.\",\n",
    ")\n",
    "\n",
    "\n",
    "editor = AssistantAgent(\n",
    "    name=\"Editor\",\n",
    "    description=\"Formats approved drafts with proper citations, adapts structure to content type.\",\n",
    "    model_client=model_client,\n",
    "    tools=[save_report],\n",
    "    system_message=EDITOR_SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "# ---------- Selector prompt with few-shot examples ----------\n",
    "selector_prompt = \"\"\"You are the selector agent. Choose exactly one agent name from {participants} to speak next based on the conversation history and their roles.\n",
    "\n",
    "Few-shot examples:\n",
    "\n",
    "Example 1:\n",
    "History: Researcher produced a draft; Critic says 'Needs more sources and clarity'.\n",
    "Selected agent: Researcher\n",
    "\n",
    "Example 2:\n",
    "History: Researcher produced a draft; Critic says 'APPROVED'.\n",
    "Selected agent: Editor\n",
    "\n",
    "Roles:\n",
    "{roles}\n",
    "\n",
    "Conversation history:\n",
    "{history}\n",
    "\n",
    "Rules:\n",
    "- Pick the agent whose role most advances completion.\n",
    "\n",
    "Return only the agent name (no extra text).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ---------- Termination callable ----------\n",
    "max_messages = 30\n",
    "txt_termination = TextMentionTermination(\"TERMINATE\")\n",
    "termination_condition = (\n",
    "    MaxMessageTermination(max_messages=max_messages) | txt_termination\n",
    ")\n",
    "\n",
    "# ---------- Build SelectorGroupChat ----------\n",
    "team = SelectorGroupChat(\n",
    "    participants=[planner, researcher, critic, editor],\n",
    "    model_client=model_client,\n",
    "    selector_prompt=selector_prompt,\n",
    "    termination_condition=termination_condition,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tenacity.retry(\n",
    "#     wait=tenacity.wait_exponential(multiplier=1, min=60, max=120),\n",
    "#     stop=tenacity.stop_after_attempt(2),\n",
    "#     retry=tenacity.retry_if_exception_type(Exception),\n",
    "# )\n",
    "async def run_task(task_text: str):\n",
    "    \"\"\"\n",
    "    Execute a multi-agent research task with proper termination handling.\n",
    "\n",
    "    Args:\n",
    "        task_text (str): The research task description\n",
    "\n",
    "    Returns:\n",
    "        str | None: Final report content or None if task incomplete\n",
    "    \"\"\"\n",
    "    final_report = None\n",
    "    task_completed = False\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"🚀 Starting task: {task_text}\\n\\n\")\n",
    "\n",
    "        async for event in team.run_stream(task=task_text):\n",
    "            logger.info(f\"📝 Event: {event}\\n\\n\")\n",
    "\n",
    "            # Check for TERMINATE keyword in message content\n",
    "            if hasattr(event, \"content\") and isinstance(event.content, str):\n",
    "                if \"TERMINATE\" in event.content:\n",
    "                    final_report = event.content.split(\"TERMINATE\", 1)[0].strip()\n",
    "                    task_completed = True\n",
    "                    logger.info(\"\\n\\n\\n\\n✅ Task completed with TERMINATE signal\\n\\n\\n\\n\")\n",
    "                    break\n",
    "\n",
    "\n",
    "            # Simple delay between each agent call\n",
    "            logger.info(\"\\n\\n\\n\\n⏳ Waiting to avoid rate limits...\")\n",
    "            await asyncio.sleep(25)\n",
    "\n",
    "        return final_report if task_completed else None\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"\\n\\n❌ Exception during task execution: {e}\\n\\n\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # Save final state on completion\n",
    "        await _save_team_state()\n",
    "\n",
    "\n",
    "async def _save_team_state():\n",
    "    \"\"\"Helper function to save team state with error handling.\"\"\"\n",
    "    try:\n",
    "        state = await team.save_state()\n",
    "        with open(\"team_state.json\", \"w\") as f:\n",
    "            json.dump(state, f, indent=2)\n",
    "        logger.info(\"💾 Team state saved successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to save team state: {e}\")\n",
    "\n",
    "\n",
    "async def resume_from_saved_state():\n",
    "    \"\"\"Resume execution from previously saved team state.\"\"\"\n",
    "    try:\n",
    "        with open(\"team_state.json\", \"r\") as f:\n",
    "            saved_state = json.load(f)\n",
    "\n",
    "        await team.load_state(saved_state)\n",
    "        logger.info(\"🔄 Resuming from saved state\")\n",
    "\n",
    "        async for event in team.run_stream():\n",
    "            logger.info(f\"📝 Resume Event: {event}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"❌ No saved state file found\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to resume from saved state: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb513d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    __SAMPLE_QUERY_1 = \"Indian steel sector growth post modernization and growth prospects in an era of US tariffs and reduce government protection through trade barriers and cheaper import options from China\"\n",
    "\n",
    "    __SAMPLE_QUERY_2 = \"How government and governance factors improved economy and lives of indians during Modi and Pre-Modi starting from 1991\"\n",
    "\n",
    "    __SAMPLE_QUERY_3 = \"Sectoral growth based on cyclics for 2025 and macro economic pressure and trade tariffs and uncertainty, which sectors are best poised for maximum investment returns in terms of % for the next year for a moderate to average risk profile investments\"\n",
    "\n",
    "    __SAMPLE_QUERY_4 = \"Hyperscaler investments in data centers and cloud infrastructure for AI growth is not matching the proposed productivity gains in GDP. Are we witnessing a bubble? Is % of global GDP being invested in AI infrastructure matches the productivity gain percentages?\"\n",
    "\n",
    "    __SAMPLE_QUERY_5 = \"If neural networks are foundation of LLMs and based on the human brain; Are LLMs given tools during training? Humans learn with tool usage, What are current trends on tool usage in LLM training?\"\n",
    "\n",
    "    try:\n",
    "        output = asyncio.run(run_task(__SAMPLE_QUERY_1))\n",
    "        if output:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"🎯 FINAL REPORT\")\n",
    "            print(\"=\" * 60)\n",
    "            print(output)\n",
    "        else:\n",
    "            print(\"❌ Task did not complete successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Fatal error: {e}\")\n",
    "        print(f\"❌ Execution failed: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
