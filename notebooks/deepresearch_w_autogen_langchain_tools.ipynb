{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bc3cfa",
   "metadata": {},
   "source": [
    "# ü§ñ Multi-Agent Deep Research System\n",
    "\n",
    "This notebook showcases how to harness the combined power of **AutoGen** and **LangChain** tools to automate and elevate deep research workflows. At its core, the system coordinates a network of specialized agents‚Äîeach executing a distinct role in the research and report generation workflow. Together, these agents collect data, analyze findings, and produce polished, insight-driven reports.\n",
    "\n",
    "[Open in Colab](https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb) <a href=\"https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## üß† Agent Roles\n",
    "\n",
    "- **üß≠ Planner**: Defines research scope, objectives, and success criteria\n",
    "- **üîç Researcher**: Gathers evidence using `wiki_search`, `web_search` and `web_fetch` for content extraction\n",
    "- **üß™ Critic**: Reviews plans and outputs for quality and completeness\n",
    "- **‚úçÔ∏è Editor**: Formats final reports with proper citations and structure\n",
    "\n",
    "## üîÑ System Architecture\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User Query] --> B[üß≠ Planner]\n",
    "    B --> C[üîç Researcher]\n",
    "    C --> D[üß™ Critic]\n",
    "    D --> E[‚úçÔ∏è Editor]\n",
    "    E --> F[üìÑ Final Report]\n",
    "\n",
    "    B -.-> D\n",
    "    C -.-> B\n",
    "    D -.-> C\n",
    "\n",
    "    C --> G[Wiki Search]\n",
    "    C --> H[Web Search]\n",
    "    C --> I[Content Fetch]\n",
    "\n",
    "```\n",
    "\n",
    "## üöÄ Quick Start\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Set environment variables:\n",
    "\n",
    "```bash\n",
    "# Required: Gemini API (or configure other models in cells below)\n",
    "export GEMINI_API_KEY=\"your_api_key\"\n",
    "export GEMINI_MODEL_NAME=\"gemini-1.5-flash\"\n",
    "export GEMINI_BASE_URL=\"https://generativelanguage.googleapis.com/v1beta/\"\n",
    "```\n",
    "\n",
    "### Run Research Task\n",
    "\n",
    "1. **Execute all cells** in sequence\n",
    "2. **Modify the query** in the final cell:\n",
    "   ```python\n",
    "   output = asyncio.run(run_task(\"Your research question here\"))\n",
    "   ```\n",
    "3. **Monitor progress** in real-time through cell outputs\n",
    "\n",
    "## üìã Example Queries\n",
    "\n",
    "- **Financial Analysis**: `\"Indian steel sector growth prospects in an era of US tariffs\"`\n",
    "- **Economic Research**: `\"Government factors that improved Indian economy during Modi era\"`\n",
    "- **Tech Industry**: `\"Are we witnessing an AI infrastructure bubble? GDP investment vs productivity gains\"`\n",
    "- **AI/ML Trends**: `\"Current trends in tool usage during LLM training\"`\n",
    "\n",
    "## üìä Outputs & Monitoring\n",
    "\n",
    "| Output Type | Location                         | Description                               |\n",
    "| ----------- | -------------------------------- | ----------------------------------------- |\n",
    "| **Reports** | `./reports/`                     | Timestamped Markdown reports (auto-saved) |\n",
    "| **Logs**    | `./logs/deep_research_agent.log` | Detailed execution logs with token usage  |\n",
    "| **State**   | `./team_state.json`              | Conversation state for resume capability  |\n",
    "\n",
    "## üìù TODO & Roadmap\n",
    "\n",
    "- [ ] **Specialized Models**: Different LLMs for different agent roles (planning vs research vs writing)\n",
    "- [ ] **Semantic Depth Search**: Advanced content extraction with semantic similarity scoring\n",
    "- [ ] **Source Verification**: Cross-reference validation and fact-checking workflows\n",
    "- [ ] **Domain-Specific Tools**: Specialized research tools for finance, science, law, etc.\n",
    "- [ ] **Agent Control Flow Logging**: Meaningful event logging for agent-to-agent handoffs\n",
    "- [ ] **Organic Flow Orchestration**: Improved prompts for natural, adaptive conversation flow\n",
    "- [ ] **Streaming UI**: Real-time progress visualization and intervention capability\n",
    "- [ ] **Performance Metrics**: Research quality scoring and optimization analytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d4c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "htmldate 1.9.3 requires lxml<6,>=5.3.0; platform_system != \"Darwin\" or python_version > \"3.8\", but you have lxml 6.0.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "%pip install -qU ipykernel\n",
    "%pip install -qU loguru\n",
    "%pip install -qU python-dotenv\n",
    "\n",
    "%pip install -qU autogen-agentchat\n",
    "%pip install -qU autogen-ext\n",
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-community\n",
    "%pip install -qU wikipedia\n",
    "%pip install -qU selenium unstructured\n",
    "%pip install -qU lxml\n",
    "%pip install -qU ddgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4222bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GOOGLE COLAB LINE WRAPPING\n",
    "# https://stackoverflow.com/questions/58890109/line-wrapping-in-collaboratory-google-results\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def set_css():\n",
    "    display(\n",
    "        HTML(\n",
    "            \"\"\"\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "get_ipython().events.register(\"pre_run_cell\", set_css)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %aimport -langchain_community\n",
    "# Automatically reload modules before executing code\n",
    "\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48776430",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERIC IMPORTS\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Annotated\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import nest_asyncio\n",
    "import tenacity\n",
    "from loguru import logger\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS\n",
    "\n",
    "## LOG CONFIG\n",
    "LOG_ROTATION_SIZE = \"10 MB\"\n",
    "LOG_RETENTION_DAYS = \"7 days\"\n",
    "\n",
    "## AUTOGEN CONFIG\n",
    "CONVERSATION_BUFFER_SIZE = 10\n",
    "TASK_TERMINATION_MAX_MESSAGES = 30\n",
    "API_CALL_DELAY_SECONDS = int(\n",
    "    os.environ.get(\"API_CALL_DELAY_SECONDS\", \"45\")\n",
    ")  # 45 seconds = 1.33 RPM\n",
    "NON_API_EVENT_DELAY = 0.5  # Small delay for non-API events\n",
    "\n",
    "## TOOL CONFIG\n",
    "WIKI_MAX_RESULTS = 5\n",
    "WIKI_MAX_CHARS = 5000\n",
    "WIKIPEDIA_MAX_DOCS = 2\n",
    "DDGS_MAX_RESULTS = 10\n",
    "WEB_CONTENT_MAX_LENGTH = 15000\n",
    "WEB_CONTENT_MIN_LENGTH = 50\n",
    "WEB_BATCH_MAX_URLS = 10\n",
    "SELENIUM_WINDOW_SIZE = \"1920,1080\"\n",
    "BROWSER_USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\"\n",
    "TITLE_SLICE_LENGTH = 50\n",
    "TOP_RESULTS_COUNT = 3\n",
    "TASK_MAX_MEANINGFUL_WORDS = 3\n",
    "CRITIC_MAX_WORDS = 500\n",
    "URL_FETCH_DELAY = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOGGING CONFIG\n",
    "notebook_dir = Path.cwd()\n",
    "log_dir = notebook_dir / \"logs\"\n",
    "log_file = log_dir / \"deep_research_agent.log\"\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if not getattr(sys, \"_loguru_configured\", False):\n",
    "    logger.remove()\n",
    "    logger.add(\n",
    "        str(log_file),\n",
    "        level=\"DEBUG\",\n",
    "        rotation=\"10 MB\",\n",
    "        retention=\"7 days\",\n",
    "        compression=\"zip\",\n",
    "        enqueue=True,\n",
    "    )\n",
    "    logger.add(\n",
    "        sys.stderr,\n",
    "        colorize=True,\n",
    "    )\n",
    "    sys._loguru_configured = True\n",
    "\n",
    "logger.info(f\"‚úÖ Logging configured successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.messages import StopMessage\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_core.model_context import BufferedChatCompletionContext\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_community.document_loaders import SeleniumURLLoader\n",
    "from ddgs import DDGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef193373",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GEMINI MODEL CLIENT\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "load_dotenv(os.path.join(\"..\", \".env\"))\n",
    "\n",
    "# Confirm the API key is set\n",
    "assert os.environ[\"GEMINI_API_KEY\"], \"GEMINI_API_KEY is not set\"\n",
    "assert os.environ[\"GEMINI_MODEL_NAME\"], \"GEMINI_MODEL_NAME is not set\"\n",
    "assert os.environ[\"GEMINI_BASE_URL\"], \"GEMINI_BASE_URL is not set\"\n",
    "\n",
    "\n",
    "gemini_model_info = ModelInfo(\n",
    "    vision=False,\n",
    "    function_calling=True,\n",
    "    json_output=True,\n",
    "    family=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    structured_output=True,\n",
    ")\n",
    "\n",
    "gemini_model_client = OpenAIChatCompletionClient(\n",
    "    model=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    base_url=os.environ[\"GEMINI_BASE_URL\"],\n",
    "    model_info=gemini_model_info,\n",
    "    max_retries=2,\n",
    "    parallel_tool_calls=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30311843",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AZURE OPENAI MODEL CLIENT\n",
    "# from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "## Confirm the API key is set\n",
    "# assert os.environ[\"AZURE_OAI_DEPLOYMENT\"], \"AZURE_OAI_DEPLOYMENT is not set\"\n",
    "# assert os.environ[\"AZURE_OAI_MODEL_NAME\"], \"AZURE_OAI_MODEL_NAME is not set\"\n",
    "# assert os.environ[\"AZURE_OAI_MODEL_VERSION\"], \"AZURE_OAI_MODEL_VERSION is not set\"\n",
    "# assert os.environ[\"AZURE_OAI_BASE_URL\"], \"AZURE_OAI_BASE_URL is not set\"\n",
    "\n",
    "# az_oai_model_client = AzureOpenAIChatCompletionClient(\n",
    "#     azure_deployment=os.environ[\"AZURE_OAI_DEPLOYMENT\"],\n",
    "#     model=os.environ[\"AZURE_OAI_MODEL_NAME\"],\n",
    "#     api_version=os.environ[\"AZURE_OAI_MODEL_VERSION\"],\n",
    "#     azure_endpoint=os.environ[\"AZURE_OAI_BASE_URL\"],\n",
    "\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGENT TOOLS\n",
    "\n",
    "# Wiki Search Tool\n",
    "wiki_api = WikipediaAPIWrapper(\n",
    "    top_k_results=WIKI_MAX_RESULTS, doc_content_chars_max=WIKI_MAX_CHARS\n",
    ")\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api)\n",
    "\n",
    "\n",
    "def wiki_full_search(input: str) -> str:\n",
    "    \"\"\"Search Wikipedia for a query and return maximum 2 results.\"\"\"\n",
    "    logger.info(f\"üîç wiki_full_search: Starting search for '{input}'\")\n",
    "\n",
    "    try:\n",
    "        search_docs = WikipediaLoader(\n",
    "            query=input, load_max_docs=WIKIPEDIA_MAX_DOCS\n",
    "        ).load()\n",
    "\n",
    "        if not search_docs:\n",
    "            logger.warning(f\"‚ö†Ô∏è wiki_full_search: No documents found for '{input}'\")\n",
    "            return f\"No Wikipedia articles found for query: {input}\"\n",
    "\n",
    "        logger.info(\n",
    "            f\"‚úÖ wiki_full_search: Found {len(search_docs)} documents for '{input}'\"\n",
    "        )\n",
    "\n",
    "        formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "            [\n",
    "                f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "                for doc in search_docs\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        content_length = len(formatted_search_docs)\n",
    "        logger.info(\n",
    "            f\"üìä wiki_full_search: Returning {content_length} characters for '{input}'\"\n",
    "        )\n",
    "\n",
    "        return formatted_search_docs\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå wiki_full_search failed for '{input}': {str(e)}\")\n",
    "        return f\"Error searching Wikipedia for '{input}': {str(e)}\"\n",
    "\n",
    "\n",
    "def wiki_search(q: str) -> dict:\n",
    "    \"\"\"Return structured output including text and source.\"\"\"\n",
    "    logger.info(f\"üîç wiki_search: Starting search for '{q}'\")\n",
    "\n",
    "    try:\n",
    "        result = wiki_tool.run(q)\n",
    "\n",
    "        if not result or result.strip() == \"\":\n",
    "            logger.warning(f\"‚ö†Ô∏è wiki_search: Empty result for '{q}'\")\n",
    "            return {\"text\": \"No results found\", \"source\": \"Wikipedia\", \"query\": q}\n",
    "\n",
    "        result_length = len(result)\n",
    "        logger.info(f\"‚úÖ wiki_search: Retrieved {result_length} characters for '{q}'\")\n",
    "\n",
    "        return {\"text\": result, \"source\": \"Wikipedia\", \"query\": q}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå wiki_search failed for '{q}': {str(e)}\")\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None, \"query\": q}\n",
    "\n",
    "\n",
    "# Web Search Tool\n",
    "def web_search(q: str) -> dict:\n",
    "    \"\"\"Search the web using DuckDuckGo for information.\"\"\"\n",
    "    logger.info(f\"üåê web_search: Starting web search for '{q}'\")\n",
    "\n",
    "    try:\n",
    "        results = DDGS().text(\n",
    "            q,\n",
    "            region=\"us-en\",\n",
    "            safesearch=\"off\",\n",
    "            max_results=DDGS_MAX_RESULTS,\n",
    "            backend=\"google, brave, bing, yahoo\",\n",
    "        )\n",
    "\n",
    "        if not results:\n",
    "            logger.warning(f\"‚ö†Ô∏è web_search: No results found for '{q}'\")\n",
    "            return {\n",
    "                \"text\": [],\n",
    "                \"source\": \"DuckDuckGo\",\n",
    "                \"query\": q,\n",
    "                \"results_found\": 0,\n",
    "            }\n",
    "\n",
    "        logger.info(f\"‚úÖ web_search: Found {len(results)} results for '{q}'\")\n",
    "\n",
    "        # Log sample of top results for debugging\n",
    "        if results:\n",
    "            top_titles = [\n",
    "                r.get(\"title\", \"No title\")[:TITLE_SLICE_LENGTH]\n",
    "                for r in results[:TOP_RESULTS_COUNT]\n",
    "            ]\n",
    "            logger.debug(f\"üìã web_search: Top results for '{q}': {top_titles}\")\n",
    "\n",
    "        return {\n",
    "            \"text\": results,\n",
    "            \"source\": \"DuckDuckGo\",\n",
    "            \"query\": q,\n",
    "            \"results_found\": len(results),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå web_search failed for '{q}': {str(e)}\")\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None, \"query\": q}\n",
    "\n",
    "\n",
    "def web_fetch(\n",
    "    url: str, max_content_length: int = WEB_CONTENT_MAX_LENGTH\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch web page content using Selenium for JavaScript-heavy sites.\n",
    "\n",
    "    Args:\n",
    "        url: The URL to fetch content from\n",
    "        max_content_length: Maximum content length to return. Defaults to WEB_CONTENT_MAX_LENGTH\n",
    "\n",
    "    Returns:\n",
    "        Dict with keys: content, url, status, error (if any)\n",
    "    \"\"\"\n",
    "    logger.info(\n",
    "        f\"üåê web_fetch: Starting fetch for {url} (max_length: {max_content_length})\"\n",
    "    )\n",
    "\n",
    "    loader = None\n",
    "\n",
    "    try:\n",
    "        # Validate URL\n",
    "        if not url or not url.startswith((\"http://\", \"https://\")):\n",
    "            return {\n",
    "                \"content\": \"\",\n",
    "                \"url\": url,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"Invalid URL format\",\n",
    "            }\n",
    "\n",
    "        # Configure Selenium loader\n",
    "        loader = SeleniumURLLoader(\n",
    "            urls=[url],\n",
    "            continue_on_failure=True,\n",
    "            arguments=_get_selenium_arguments(),\n",
    "            browser=\"chrome\",\n",
    "        )\n",
    "\n",
    "        # Load content\n",
    "        logger.info(f\"üì• web_fetch: Loading content from {url}\")\n",
    "        documents = loader.load()\n",
    "\n",
    "        if not documents:\n",
    "            logger.warning(f\"‚ö†Ô∏è web_fetch: No documents loaded from {url}\")\n",
    "            return {\n",
    "                \"content\": \"\",\n",
    "                \"url\": url,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"No content could be loaded from URL\",\n",
    "            }\n",
    "\n",
    "        # Process content\n",
    "        content = documents[0].page_content.strip()\n",
    "        original_length = len(content)\n",
    "\n",
    "        logger.debug(f\"üìä web_fetch: Loaded {original_length} characters from {url}\")\n",
    "\n",
    "        if len(content) < WEB_CONTENT_MIN_LENGTH:\n",
    "            logger.warning(\n",
    "                f\"‚ö†Ô∏è web_fetch: Content too short ({len(content)} chars) from {url}\"\n",
    "            )\n",
    "            return {\n",
    "                \"content\": content,\n",
    "                \"url\": url,\n",
    "                \"status\": \"warning\",\n",
    "                \"error\": \"Content appears too short, may indicate loading issues\",\n",
    "            }\n",
    "\n",
    "        # Truncate if too long\n",
    "        if len(content) > max_content_length:\n",
    "            content = content[:max_content_length] + \"\\n\\n[Content truncated...]\"\n",
    "            logger.info(\n",
    "                f\"‚úÇÔ∏è web_fetch: Content truncated from {original_length} to {max_content_length} chars for {url}\"\n",
    "            )\n",
    "\n",
    "        logger.info(\n",
    "            f\"‚úÖ web_fetch: Successfully fetched {len(content)} characters from {url}\"\n",
    "        )\n",
    "\n",
    "        return {\"content\": content, \"url\": url, \"status\": \"success\", \"error\": None}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå web_fetch failed for {url}: {str(e)}\")\n",
    "        return {\n",
    "            \"content\": \"\",\n",
    "            \"url\": url,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": f\"Failed to fetch content: {str(e)}\",\n",
    "        }\n",
    "\n",
    "    finally:\n",
    "        # CRITICAL: Clean up browser resources\n",
    "        if loader and hasattr(loader, \"web_driver\") and loader.web_driver:\n",
    "            try:\n",
    "                loader.web_driver.quit()\n",
    "                logger.debug(f\"üßπ web_fetch: Browser cleaned up for {url}\")\n",
    "            except Exception as cleanup_error:\n",
    "                logger.warning(f\"‚ö†Ô∏è web_fetch: Browser cleanup failed: {cleanup_error}\")\n",
    "\n",
    "\n",
    "def _get_selenium_arguments() -> List[str]:\n",
    "    \"\"\"Get optimized Selenium browser arguments for reliability and stealth.\n",
    "    Returns:\n",
    "        List of browser arguments\n",
    "    \"\"\"\n",
    "    return [\n",
    "        # Core stability\n",
    "        \"--headless\",\n",
    "        \"--no-sandbox\",\n",
    "        \"--disable-dev-shm-usage\",\n",
    "        \"--disable-gpu\",\n",
    "        f\"--window-size={SELENIUM_WINDOW_SIZE}\",\n",
    "        # Performance\n",
    "        \"--disable-extensions\",\n",
    "        \"--disable-plugins\",\n",
    "        \"--disable-images\",\n",
    "        \"--disable-javascript\",\n",
    "        # Stealth and compatibility\n",
    "        \"--disable-blink-features=AutomationControlled\",\n",
    "        f\"--user-agent={BROWSER_USER_AGENT}\",\n",
    "        # GDPR/Cookie banner handling\n",
    "        \"--disable-notifications\",\n",
    "        \"--disable-infobars\",\n",
    "        \"--disable-default-apps\",\n",
    "        # Security bypasses (use cautiously)\n",
    "        \"--ignore-certificate-errors\",\n",
    "        \"--ignore-ssl-errors\",\n",
    "        \"--allow-running-insecure-content\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def web_fetch_multiple(\n",
    "    urls: List[str], max_content_length: int = WEB_CONTENT_MAX_LENGTH\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch content from multiple URLs efficiently.\n",
    "\n",
    "    Args:\n",
    "        urls: List of URLs to fetch\n",
    "        max_content_length: Maximum content length per URL\n",
    "\n",
    "    Returns:\n",
    "        Dict with results for each URL and summary statistics\n",
    "    \"\"\"\n",
    "    logger.info(f\"üåê web_fetch_multiple: Starting batch fetch for {len(urls)} URLs\")\n",
    "\n",
    "    if not urls or len(urls) > WEB_BATCH_MAX_URLS:\n",
    "        logger.warning(\n",
    "            f\"‚ö†Ô∏è web_fetch_multiple: Invalid URL list - {len(urls) if urls else 0} URLs (max {WEB_BATCH_MAX_URLS})\"\n",
    "        )\n",
    "        return {\n",
    "            \"results\": [],\n",
    "            \"status\": \"error\",\n",
    "            \"error\": f\"Invalid URL list (empty or too many URLs, max {WEB_BATCH_MAX_URLS})\",\n",
    "        }\n",
    "\n",
    "    results = []\n",
    "    success_count = 0\n",
    "\n",
    "    logger.debug(\n",
    "        f\"üìã web_fetch_multiple: Processing URLs: {[f'{url[:TITLE_SLICE_LENGTH]}...' if len(url) > TITLE_SLICE_LENGTH else url for url in urls]}\"\n",
    "    )\n",
    "\n",
    "    for i, url in enumerate(urls, 1):\n",
    "        logger.debug(f\"üîÑ web_fetch_multiple: Processing URL {i}/{len(urls)}: {url}\")\n",
    "\n",
    "        result = web_fetch(url, max_content_length)\n",
    "        results.append(result)\n",
    "\n",
    "        if result[\"status\"] == \"success\":\n",
    "            success_count += 1\n",
    "            logger.debug(f\"‚úÖ web_fetch_multiple: URL {i}/{len(urls)} successful\")\n",
    "        else:\n",
    "            logger.debug(\n",
    "                f\"‚ùå web_fetch_multiple: URL {i}/{len(urls)} failed: {result.get('error', 'Unknown error')}\"\n",
    "            )\n",
    "\n",
    "        # Brief delay to be respectful\n",
    "        time.sleep(URL_FETCH_DELAY)\n",
    "\n",
    "    logger.info(\n",
    "        f\"üèÅ web_fetch_multiple: Completed batch - {success_count}/{len(urls)} successful\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"total_urls\": len(urls),\n",
    "        \"successful\": success_count,\n",
    "        \"failed\": len(urls) - success_count,\n",
    "        \"status\": \"completed\",\n",
    "    }\n",
    "\n",
    "\n",
    "def save_report(\n",
    "    content: str, task_description: str, reports_dir: str = \"reports\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Save timestamped Markdown report to disk with auto-generated filename.\n",
    "\n",
    "    Args:\n",
    "        content: Report content (plain text or Markdown). Auto-adds title if missing.\n",
    "        task_description: Brief task description for filename generation.\n",
    "        reports_dir: Output directory (default: \"reports\"). Created if missing.\n",
    "\n",
    "    Returns:\n",
    "        Dict with keys: status (\"success\"/\"error\"), filepath, filename, error\n",
    "\n",
    "    Examples:\n",
    "        save_report(\"# Analysis\\n\\nFindings...\", \"market research 2024\")\n",
    "        # ‚Üí reports/20250821_1430_market_research.md\n",
    "\n",
    "        save_report(draft_text, \"AI impact assessment\")\n",
    "        # ‚Üí reports/20250821_1431_ai_impact.md\n",
    "\n",
    "    Filename: YYYYMMDD_HHMM_key_words.md (auto-numbered if exists)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure reports directory exists\n",
    "        reports_path = Path(reports_dir)\n",
    "        reports_path.mkdir(exist_ok=True)\n",
    "\n",
    "        # Generate timestamped filename\n",
    "        timestamp = datetime.now()\n",
    "        date_time = timestamp.strftime(\"%Y%m%d_%H%M\")\n",
    "        task_name = _extract_task_name(task_description)\n",
    "\n",
    "        filename = f\"{date_time}_{task_name}.md\"\n",
    "        filepath = reports_path / filename\n",
    "\n",
    "        # Handle filename conflicts with counter\n",
    "        counter = 1\n",
    "        while filepath.exists():\n",
    "            filename = f\"{date_time}_{task_name}_{counter}.md\"\n",
    "            filepath = reports_path / filename\n",
    "            counter += 1\n",
    "\n",
    "        # Format content with title if needed\n",
    "        formatted_content = _format_content(content, task_description, timestamp)\n",
    "\n",
    "        # Save to disk using Path object\n",
    "        filepath.write_text(formatted_content, encoding=\"utf-8\")\n",
    "        logger.info(f\"üìÑ Report saved: {filepath}\")\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"filepath\": str(filepath),\n",
    "            \"filename\": filename,\n",
    "            \"timestamp\": timestamp.isoformat(),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to save report: {str(e)}\"\n",
    "        logger.error(f\"‚ùå {error_msg}\")\n",
    "        return {\"status\": \"error\", \"error\": error_msg, \"task\": task_description}\n",
    "\n",
    "\n",
    "def _extract_task_name(task: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract 2-3 meaningful words from task description for filename.\n",
    "\n",
    "    Args:\n",
    "        task: The task description string\n",
    "\n",
    "    Returns:\n",
    "        Underscore-separated words suitable for filename\n",
    "    \"\"\"\n",
    "    # Clean special characters and normalize\n",
    "    clean_task = re.sub(r\"[^\\w\\s]\", \" \", task.lower())\n",
    "    words = [w for w in clean_task.split() if len(w) > 2]\n",
    "\n",
    "    # Filter common stop words\n",
    "    stop_words = {\n",
    "        \"the\",\n",
    "        \"and\",\n",
    "        \"for\",\n",
    "        \"with\",\n",
    "        \"from\",\n",
    "        \"about\",\n",
    "        \"into\",\n",
    "        \"through\",\n",
    "        \"during\",\n",
    "        \"before\",\n",
    "        \"after\",\n",
    "        \"above\",\n",
    "        \"below\",\n",
    "        \"over\",\n",
    "        \"under\",\n",
    "    }\n",
    "    meaningful = [w for w in words if w not in stop_words][:TASK_MAX_MEANINGFUL_WORDS]\n",
    "\n",
    "    return \"_\".join(meaningful) if meaningful else \"report\"\n",
    "\n",
    "\n",
    "def _format_content(content: str, task: str, timestamp: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Format content with title and timestamp if needed.\n",
    "\n",
    "    Args:\n",
    "        content: Raw content to format\n",
    "        task: Task description for title generation\n",
    "        timestamp: When the report was created\n",
    "\n",
    "    Returns:\n",
    "        Formatted Markdown content\n",
    "    \"\"\"\n",
    "    # If content already has a Markdown title, use as-is\n",
    "    if content.strip().startswith(\"#\"):\n",
    "        return content\n",
    "\n",
    "    # Add title and timestamp for plain text content\n",
    "    formatted_title = f\"# Report: {task}\"\n",
    "    timestamp_line = f\"*Generated: {timestamp.strftime('%Y-%m-%d %H:%M')}*\"\n",
    "\n",
    "    return f\"{formatted_title}\\n\\n{timestamp_line}\\n\\n{content}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291cb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REGISTER FUNCTIONS AS TOOLS\n",
    "\n",
    "wiki_search_tool = FunctionTool(\n",
    "    func=wiki_search,\n",
    "    name=\"wiki_search\",\n",
    "    description=\"Search Wikipedia for information.\",\n",
    ")\n",
    "web_search_tool = FunctionTool(\n",
    "    func=web_search, name=\"web_search\", description=\"Search the web for information.\"\n",
    ")\n",
    "web_fetch_tool = FunctionTool(\n",
    "    func=web_fetch, name=\"web_fetch\", description=\"Fetch content from a web page.\"\n",
    ")\n",
    "web_fetch_multiple_tool = FunctionTool(\n",
    "    func=web_fetch_multiple,\n",
    "    name=\"web_fetch_multiple\",\n",
    "    description=\"Fetch content from multiple web pages.\",\n",
    ")\n",
    "save_report_tool = FunctionTool(\n",
    "    func=save_report, name=\"save_report\", description=\"Save the research report.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b446dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UTILITY FUNCTIONS\n",
    "def log_event_enhanced(\n",
    "    event,\n",
    "    total_prompt_tokens: int = 0,\n",
    "    total_completion_tokens: int = 0,\n",
    "    total_tokens: int = 0,\n",
    "    message_count: int = 0,\n",
    "):\n",
    "    \"\"\"Enhanced agent-aware logging with clear token flow tracking and running totals\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    event_id = getattr(event, \"id\", \"N/A\")\n",
    "\n",
    "    # Agent-specific emojis and formatting\n",
    "    agent_config = {\n",
    "        \"Planner\": {\"emoji\": \"üß≠\", \"role\": \"PLANNER\"},\n",
    "        \"Researcher\": {\"emoji\": \"üîç\", \"role\": \"RESEARCHER\"},\n",
    "        \"Critic\": {\"emoji\": \"üß™\", \"role\": \"CRITIC\"},\n",
    "        \"Editor\": {\"emoji\": \"‚úçÔ∏è\", \"role\": \"EDITOR\"},\n",
    "    }\n",
    "\n",
    "    # Get agent info\n",
    "    source = getattr(event, \"source\", \"Unknown\")\n",
    "    event_type = getattr(event, \"type\", type(event).__name__)\n",
    "    config = agent_config.get(source, {\"emoji\": \"ü§ñ\", \"role\": \"UNKNOWN\"})\n",
    "\n",
    "    # Extract current event token information (for display only - already counted in totals)\n",
    "    current_prompt = 0\n",
    "    current_completion = 0\n",
    "    current_total = 0\n",
    "\n",
    "    if hasattr(event, \"models_usage\") and event.models_usage:\n",
    "        current_prompt = event.models_usage.prompt_tokens\n",
    "        current_completion = event.models_usage.completion_tokens\n",
    "        current_total = current_prompt + current_completion\n",
    "\n",
    "    # Build the enhanced 4-line structure with clear token flow using exact field names\n",
    "    line1 = f\"Agent: {config['emoji']} {config['role']} | Type: {event_type} | Message #{message_count}\"\n",
    "    line2 = \"\"  # Reserved for future functional info\n",
    "\n",
    "    if current_total > 0:\n",
    "        # Simplified token display using exact field names from event payload\n",
    "        line3 = f\"Tokens: prompt_tokens:{current_prompt} completion_tokens:{current_completion}  Running Total:{total_tokens}\"\n",
    "    else:\n",
    "        line3 = f\"Tokens: None (no model call) ‚Üí Running Total:{total_tokens}\"\n",
    "\n",
    "    line4 = f\"Timestamp: {timestamp} | Event ID: {event_id}\"\n",
    "\n",
    "    # Format the log output with enhanced visual structure\n",
    "    separator_line = \"‚îÅ\" * 80\n",
    "    content_preview = str(getattr(event, \"content\", str(event)))\n",
    "\n",
    "    # Truncate very long content for readability\n",
    "    if len(content_preview) > 500:\n",
    "        content_preview = (\n",
    "            content_preview[:500] + \"\\n... [Content truncated for display] ...\"\n",
    "        )\n",
    "\n",
    "    logger.info(\n",
    "        f\"\"\"\n",
    "{separator_line}\n",
    "{line1}\n",
    "{line2}\n",
    "{line3}\n",
    "{line4}\n",
    "{separator_line}\n",
    "{content_preview}\n",
    "{separator_line}\n",
    "\"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SYSTEM PROMPTS\n",
    "\n",
    "### References\n",
    "# https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\n",
    "# https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/prompt-engineering-for-openai%E2%80%99s-o1-and-o3-mini-reasoning-models/4374010\n",
    "# https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf\n",
    "today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "PLANNER_SYSTEM_PROMPT = dedent(\n",
    "    f\"\"\"Strategic Research Planner. Convert user queries into executable research specifications. Today is {today_str}.\n",
    "\n",
    "PRIMARY FUNCTION: Query decomposition and scope definition. \n",
    "- Decompose queries into specific, answerable research questions. What decisions will this research inform? \n",
    "- Define completion criteria: Set evidence thresholds: Established facts (1-2 sources), trends (3+ sources), contested claims (5+ sources)\n",
    "- Define scope boundaries and exclusions explicitly. Specify temporal focus: current (2024-2025), recent trends (2020-2025), or historical analysis\n",
    "- Specify output format and user needs\n",
    "- PLANNING ONLY: No research execution or evidence assessment\n",
    "\n",
    "RESOURCE LIMITS:\n",
    "- MAX_QUESTIONS: 10 per research brief\n",
    "- MAX_CRITIC_INTERACTIONS: 3\n",
    "\n",
    "MANDATORY WORKFLOW:\n",
    "1. Create research brief with questions, evidence thresholds, and scope limits\n",
    "2. Submit to CRITIC for feasibility review\n",
    "3. Revise once if CRITIC flags issues\n",
    "4. Declare \"PLAN_APPROVED\" after CRITIC approval OR after MAX_CRITIC_INTERACTIONS reached\n",
    "\n",
    "FAILURE MODES:\n",
    "- SCOPE_EXCEEDED: Query requires specialized databases or paid access\n",
    "- CRITIC_REJECTED: Plan unfeasible after MAX_CRITIC_INTERACTIONS revision attempts\n",
    "\n",
    "OUTPUT: Structured brief ready for RESEARCHER execution\n",
    "COMPLETION: Hand off to RESEARCHER after CRITIC approval\n",
    "ESCALATION: CRITIC rejection after MAX_CRITIC_INTERACTIONS attempts = SCOPE_EXCEEDED\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "RESEARCHER_SYSTEM_PROMPT = dedent(\n",
    "    f\"\"\"Senior Research Analyst. Execute targeted research using available tools with strict resource management. Today is {today_str}.\n",
    "\n",
    "CORE FUNCTION:\n",
    "- Execute research questions, gather evidence meeting specified thresholds\n",
    "- Gather evidence, respecting the specified source thresholds and search heuristics.\n",
    "\n",
    "RESOURCE MANAGEMENT & LOOP PREVENTION:\n",
    "- MAX 12 searches, 8 fetches. Auto-stop when diminishing returns detected\n",
    "- DIMINISHING_RETURNS: Automatically terminate a line of inquiry if <15% novel content is found across 2 consecutive searches.\n",
    "- CIRCULAR_DETECTION: Automatically terminate if 3+ searches share >70% term overlap.\n",
    "- The system will halt and report when budget is exhausted or all questions are researched, whichever comes first.\n",
    "\n",
    "SEARCH HEURISTICS:\n",
    "- Include year for current topics: \"AI adoption 2025\"\n",
    "- Geographic: \"EV sales Europe 2025\"\n",
    "- For contested topics, prioritize diverse source perspectives over source volume\n",
    "- Source priority: Primary > Institutional > Peer-reviewed > News\n",
    "\n",
    "OUTPUT:\n",
    "- Group findings by research question\n",
    "- Include source URLs and publication dates\n",
    "- Flag incomplete evidence areas\n",
    "- NO quality assessment (EDITOR's role)\n",
    "\n",
    "COMPLETION SIGNALS:\n",
    "- RESEARCH_COMPLETE (thresholds met)\n",
    "- SEARCH_EXHAUSTED (resource limits)\n",
    "- DATA_INACCESSIBLE (paywall barriers)\n",
    "- DIMINISHING_RETURNS (new info threshold not met)\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "CRITIC_SYSTEM_PROMPT = dedent(\n",
    "    f\"\"\"Domain-agnostic Critic. Provide focused feasibility and completeness review when explicitly called. Today is {today_str}.\n",
    "\n",
    "CORE FUNCTION:\n",
    "- PLAN_REVIEW: Assess feasibility, scope clarity, tool alignment, temporal boundaries. Feedback to PLANNER\n",
    "- ARTIFACT_REVIEW OR EDIT_REVIEW: Check completeness, clarity, strategic value, temporal accuracy. Feedback to EDITOR\n",
    "- NO RESEARCH execution\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "- APPROVED: Ready for execution/completion\n",
    "- REJECTED: [specific blocking issues] + [required changes]\n",
    "\n",
    "QUALITY LABELS (for all reviews):\n",
    "  - HIGH: Multiple credible sources, robust methodology\n",
    "  - MEDIUM: Single credible source or minor limitations\n",
    "  - LOW: Preliminary evidence or significant gaps\n",
    "  - INSUFFICIENT: Below minimum threshold for meaningful analysis\n",
    "\n",
    "REJECTION TRIGGERS:\n",
    "- Requires specialized databases/paid access\n",
    "- Vague success criteria or unlimited resource requirements  \n",
    "- Questions beyond search/fetch tool capabilities\n",
    "- Evidence insufficient for stated confidence claims\n",
    "\n",
    "RESOURCE LIMITS:\n",
    "- MAX_RESPONSE: 300 words\n",
    "- REVIEW_ONLY: No unsolicited feedback\"\"\"\n",
    ")\n",
    "\n",
    "EDITOR_SYSTEM_PROMPT = dedent(\n",
    "    \"\"\"Research Editorial Agent. Transform research into well-structured, actionable reports enabling strategic application.Today is {today_str}.\n",
    "\n",
    "CORE ROLE:\n",
    "- Synthesize findings with confidence indicators\n",
    "- Generate strategic insights bounded by evidence quality\n",
    "- Acknowledge data limitations transparently and apply confidence indicators to all claims\n",
    "- Save final report using save_report tool\n",
    "\n",
    "RESOURCE LIMITS:\n",
    "- MAX_CRITIC_INTERACTIONS: 2\n",
    "- MANDATORY: Use save_report tool for completion\n",
    "\n",
    "EVIDENCE STANDARDS:\n",
    "- High confidence: Multiple credible sources, recent data\n",
    "- Medium confidence: Single credible source or methodological limits\n",
    "- Low confidence: Preliminary/conflicting evidence, significant gaps\n",
    "- NO INSIGHTS beyond evidence boundaries\n",
    "\n",
    "QUALITY GATE: Would this evidence support the strategic conclusions under peer review? If no, qualify or remove.\n",
    "\n",
    "ADAPTIVE REPORT STRUCTURE:\n",
    "## EXECUTIVE SUMMARY\n",
    "##  CORE ANALYSIS based on research type and findings available:\n",
    "- Business analysis: Market data, competitive landscape, financial metrics\n",
    "- Technology assessment: Adoption rates, capabilities, implementation barriers\n",
    "- Economic impact: Quantified effects, regional variations, timeline projections\n",
    "- Sectoral analysis: Industry trends, key players, regulatory environment\n",
    "\n",
    "## ACTIONABLE RECOMMENDATIONS & NEXT STEPS\n",
    "[Based on high-confidence findings only]\n",
    "\n",
    "## LIMITATIONS & GAPS\n",
    "[Explicit acknowledgment of incomplete data]\n",
    "\n",
    "## SOURCE CITATIONS\n",
    "[Full citation list]\n",
    "\n",
    "COMPLETION PROTOCOL:\n",
    "1. Save report using save_report tool\n",
    "2. Output: \"REPORT_SAVED. TASK_COMPLETE. TERMINATE\"\n",
    "3. MANDATORY: After save_report, respond only with 'REPORT_SAVED. TASK_COMPLETE. TERMINATE' and provide no additional content\"\n",
    "\n",
    "FAILURE MODES:\n",
    "- INSUFFICIENT_EVIDENCE: Cannot generate meaningful synthesis\n",
    "- CRITIC_REJECTION: Report lacks evidence support. Proceed with qualified report after MAX_CRITIC_INTERACTIONS\n",
    "\n",
    "ESCALATION: Call CRITIC if evidence insufficient for meaningful synthesis. Revise until MAX_CRITIC_INTERACTIONS then deliver with limitations acknowledged.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGENT SETUP\n",
    "\n",
    "\n",
    "planner = AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    model_client=gemini_model_client,\n",
    "    system_message=PLANNER_SYSTEM_PROMPT,\n",
    "    description=\"Creates and adapts research plans, handles replanning when research hits obstacles\",\n",
    ")\n",
    "\n",
    "researcher = AssistantAgent(\n",
    "    name=\"Researcher\",\n",
    "    description=\"Expert research agent that strategically uses multiple tools to gather comprehensive and factual evidence to produce well-researched draft reports.\",\n",
    "    model_client=gemini_model_client,\n",
    "    tools=[wiki_search_tool, web_search_tool, web_fetch_tool, web_fetch_multiple_tool],\n",
    "    reflect_on_tool_use=False,\n",
    "    system_message=RESEARCHER_SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "critic = AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    model_client=gemini_model_client,\n",
    "    system_message=CRITIC_SYSTEM_PROMPT,\n",
    "    description=\"Reviews and provides constructive criticism; outputs 'APPROVED: [...]' when ready.\",\n",
    ")\n",
    "\n",
    "\n",
    "editor = AssistantAgent(\n",
    "    name=\"Editor\",\n",
    "    description=\"Formats approved drafts with proper citations, adapts structure to content type.\",\n",
    "    model_client=gemini_model_client,\n",
    "    tools=[save_report_tool],\n",
    "    system_message=EDITOR_SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "__SELECTOR_PROMPT = \"\"\"Select the most logical next agent based on conversation flow and current needs.\n",
    "\n",
    "AGENT CAPABILITIES:\n",
    "{roles}\n",
    "\n",
    "CONVERSATION CONTEXT:\n",
    "{history}\n",
    "\n",
    "SELECTION LOGIC:\n",
    "- Follow natural progression of work\n",
    "- Enable iterative refinement between agents\n",
    "- Consider what specific expertise is needed now\n",
    "- Allow organic handoffs based on quality and completeness\n",
    "\n",
    "Available agents: {participants}\n",
    "\n",
    "Return only the agent name.\"\"\"\n",
    "\n",
    "\n",
    "# Team configuration with constants\n",
    "max_messages = TASK_TERMINATION_MAX_MESSAGES\n",
    "txt_termination = TextMentionTermination(\"TERMINATE\")\n",
    "termination_condition = (\n",
    "    MaxMessageTermination(max_messages=max_messages) | txt_termination\n",
    ")\n",
    "\n",
    "# Build SelectorGroupChat\n",
    "\n",
    "model_context = BufferedChatCompletionContext(buffer_size=CONVERSATION_BUFFER_SIZE)\n",
    "\n",
    "team = SelectorGroupChat(\n",
    "    name=\"Deep Research Team\",\n",
    "    description=\"A team of specialized agents working together to conduct deep research.\",\n",
    "    model_context=model_context,\n",
    "    participants=[planner, researcher, critic, editor],\n",
    "    model_client=gemini_model_client,\n",
    "    selector_prompt=__SELECTOR_PROMPT,\n",
    "    termination_condition=termination_condition,\n",
    "    emit_team_events=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETUP TASK RUN\n",
    "\n",
    "\n",
    "# @tenacity.retry(\n",
    "#     wait=tenacity.wait_exponential(multiplier=1, min=60, max=120),\n",
    "#     stop=tenacity.stop_after_attempt(2),\n",
    "#     retry=tenacity.retry_if_exception_type(Exception),\n",
    "# )\n",
    "async def run_task(task_text: str):\n",
    "    \"\"\"\n",
    "    Execute a multi-agent research task with robust termination handling.\n",
    "\n",
    "    Args:\n",
    "        task_text (str): The research task description\n",
    "\n",
    "    Returns:\n",
    "        str | None: Final report content or None if task incomplete\n",
    "    \"\"\"\n",
    "    final_report = None\n",
    "    task_completed = False\n",
    "    report_saved = False\n",
    "\n",
    "    # Proper local scope variables\n",
    "    post_save_iterations = 0\n",
    "    message_count = 0\n",
    "    tool_call_count = 0\n",
    "\n",
    "    # Token tracking variables\n",
    "    total_prompt_tokens = 0\n",
    "    total_completion_tokens = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    # Enhanced termination signals\n",
    "    termination_signals = [\n",
    "        \"TERMINATE\",\n",
    "        \"RESEARCH TASK COMPLETE\",\n",
    "        \"EVIDENCE_REPORT_COMPLETE\",\n",
    "        \"FINAL REPORT SAVED\",\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"üöÄ Starting task: {task_text}\\n\\n\")\n",
    "\n",
    "        # Enhanced event logging with structured format\n",
    "        async for event in team.run_stream(task=task_text):\n",
    "\n",
    "            # Increment message counter for any substantial event\n",
    "            if hasattr(event, \"content\") or hasattr(event, \"tool_calls\"):\n",
    "                message_count += 1\n",
    "\n",
    "            # Track tokens if available\n",
    "            if hasattr(event, \"models_usage\") and event.models_usage:\n",
    "                current_prompt = event.models_usage.prompt_tokens\n",
    "                current_completion = event.models_usage.completion_tokens\n",
    "                current_total = current_prompt + current_completion\n",
    "\n",
    "                # Update running totals\n",
    "                total_prompt_tokens += current_prompt\n",
    "                total_completion_tokens += current_completion\n",
    "                total_tokens += current_total\n",
    "\n",
    "            # Enhanced structured logging with message count\n",
    "            log_event_enhanced(\n",
    "                event,\n",
    "                total_prompt_tokens,\n",
    "                total_completion_tokens,\n",
    "                total_tokens,\n",
    "                message_count,\n",
    "            )\n",
    "\n",
    "            # Check for tool call events (save_report completion)\n",
    "            if hasattr(event, \"tool_calls\") and event.tool_calls:\n",
    "                tool_call_count += len(event.tool_calls)\n",
    "                for tool_call in event.tool_calls:\n",
    "                    if (\n",
    "                        hasattr(tool_call, \"function\")\n",
    "                        and tool_call.function.name == \"save_report\"\n",
    "                    ):\n",
    "                        logger.info(\n",
    "                            f\"üìÑ Report save tool called - marking as saved (Tool call #{tool_call_count})\"\n",
    "                        )\n",
    "                        report_saved = True\n",
    "                    elif hasattr(tool_call, \"name\") and tool_call.name == \"save_report\":\n",
    "                        logger.info(\n",
    "                            f\"üìÑ Report save tool called - marking as saved (Tool call #{tool_call_count})\"\n",
    "                        )\n",
    "                        report_saved = True\n",
    "\n",
    "            # Check for termination signals in message content\n",
    "            if hasattr(event, \"content\") and isinstance(event.content, str):\n",
    "                content_upper = event.content.upper()\n",
    "\n",
    "                # Check for any termination signal\n",
    "                for signal in termination_signals:\n",
    "                    if signal.upper() in content_upper:\n",
    "                        final_report = event.content.split(signal, 1)[0].strip()\n",
    "                        task_completed = True\n",
    "                        logger.info(\n",
    "                            f\"\\n\\n‚úÖ Task completed with '{signal}' signal after {message_count} messages\"\n",
    "                        )\n",
    "                        logger.info(\n",
    "                            f\"üìä Final Token Usage - Total: {total_tokens} (prompt: {total_prompt_tokens}, completion: {total_completion_tokens})\"\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                if task_completed:\n",
    "                    break\n",
    "\n",
    "            # Enhanced timeout with report save detection (proper scoping)\n",
    "            if report_saved and not task_completed:\n",
    "                post_save_iterations += 1\n",
    "                logger.warning(\n",
    "                    f\"üìÑ Report saved but no termination signal detected. Post-save iteration: {post_save_iterations}/3\"\n",
    "                )\n",
    "\n",
    "                if post_save_iterations > 3:  # Allow 3 iterations post-save\n",
    "                    logger.info(\n",
    "                        f\"‚è∞ Timeout after report save - assuming completion after {message_count} messages\"\n",
    "                    )\n",
    "                    final_report = (\n",
    "                        \"Report saved successfully but termination signal not received.\"\n",
    "                    )\n",
    "                    task_completed = True\n",
    "                    break\n",
    "\n",
    "            if hasattr(event, \"models_usage\") and event.models_usage:\n",
    "                # This event involved a model API call - apply rate limiting\n",
    "                logger.info(\n",
    "                    f\"\\n\\n‚è≥ Model API call detected, waiting {API_CALL_DELAY_SECONDS} seconds. (Message #{message_count})\\n\\n\"\n",
    "                )\n",
    "                await asyncio.sleep(API_CALL_DELAY_SECONDS)\n",
    "            else:\n",
    "                # Non-API event (planning, internal processing) - minimal delay\n",
    "                logger.debug(\n",
    "                    f\"\\n\\nüí® Non-API event, brief pause ({NON_API_EVENT_DELAY}s) (Message #{message_count})\\n\\n\"\n",
    "                )\n",
    "                await asyncio.sleep(NON_API_EVENT_DELAY)\n",
    "\n",
    "        # Log final totals and statistics\n",
    "        if not task_completed:\n",
    "            logger.warning(\n",
    "                f\"‚ö†Ô∏è Task reached end of stream without clear termination after {message_count} messages\"\n",
    "            )\n",
    "            if report_saved:\n",
    "                logger.info(\"üìÑ Report was saved - considering task successful\")\n",
    "                final_report = \"Task completed with report save but without explicit termination signal.\"\n",
    "                task_completed = True\n",
    "\n",
    "        # Final statistics logging\n",
    "        logger.info(\n",
    "            f\"\"\"\n",
    "üìä TASK COMPLETION STATISTICS:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "‚úÖ Task Completed: {task_completed}\n",
    "üìÑ Report Saved: {report_saved}\n",
    "üí¨ Total Messages: {message_count}\n",
    "üîß Tool Calls: {tool_call_count}\n",
    "üèÅ Post-Save Iterations: {post_save_iterations}\n",
    "üéØ Tokens Used: {total_tokens} (prompt: {total_prompt_tokens}, completion: {total_completion_tokens})\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "        return final_report if task_completed else None\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"\\n\\n‚ùå Exception during task execution: {e}\")\n",
    "        logger.info(\n",
    "            f\"üìä Error at Message #{message_count}, Token Usage: {total_tokens} (prompt: {total_prompt_tokens}, completion: {total_completion_tokens})\"\n",
    "        )\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        await _save_team_state()\n",
    "\n",
    "\n",
    "async def _save_team_state():\n",
    "    \"\"\"Helper function to save team state with error handling using Path objects.\"\"\"\n",
    "    try:\n",
    "        state = await team.save_state()\n",
    "        state_file = Path(\"team_state.json\")\n",
    "\n",
    "        with state_file.open(\"w\") as f:\n",
    "            json.dump(state, f, indent=2)\n",
    "        logger.info(\"üíæ Team state saved successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to save team state: {e}\")\n",
    "\n",
    "\n",
    "async def resume_from_saved_state():\n",
    "    \"\"\"Resume execution from previously saved team state using Path objects.\"\"\"\n",
    "    try:\n",
    "        state_file = Path(\"team_state.json\")\n",
    "\n",
    "        with state_file.open(\"r\") as f:\n",
    "            saved_state = json.load(f)\n",
    "\n",
    "        await team.load_state(saved_state)\n",
    "        logger.info(\"üîÑ Resuming from saved state\")\n",
    "\n",
    "        async for event in team.run_stream():\n",
    "            logger.info(f\"üìù Resume Event: {event}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"‚ùå No saved state file found\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to resume from saved state: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb513d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN TASK\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    __SAMPLE_QUERY_1 = \"Indian steel sector growth post modernization and growth prospects in an era of US tariffs and reduce government protection through trade barriers and cheaper import options from China\"\n",
    "\n",
    "    __SAMPLE_QUERY_2 = \"How government and governance factors improved economy and lives of indians during Modi and Pre-Modi starting from 1991\"\n",
    "\n",
    "    __SAMPLE_QUERY_3 = \"Sectoral growth based on cyclics for 2025 and macro economic pressure and trade tariffs and uncertainty, which sectors are best poised for maximum investment returns in terms of % for the next year for a moderate to average risk profile investments\"\n",
    "\n",
    "    __SAMPLE_QUERY_4 = \"Hyperscaler investments in data centers and cloud infrastructure for AI growth is not matching the proposed productivity gains in GDP. Are we witnessing a bubble? Is % of global GDP being invested in AI infrastructure matches the productivity gain percentages?\"\n",
    "\n",
    "    __SAMPLE_QUERY_5 = \"If neural networks are foundation of LLMs and based on the human brain; Are LLMs given tools during training? Humans learn with tool usage, What are current trends on tool usage in LLM training?\"\n",
    "\n",
    "    __SAMPLE_QUERY_6 = f\"Today is {today_str}. Analyze stock price performance of Nvidia in the past month, compare it with top 3 listed POWER Producers in India.\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        output = asyncio.run(run_task(__SAMPLE_QUERY_1))\n",
    "        if output:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"üéØ FINAL REPORT\")\n",
    "            print(\"=\" * 60)\n",
    "            print(output)\n",
    "        else:\n",
    "            print(\"‚ùå Task did not complete successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Fatal error: {e}\")\n",
    "        print(f\"‚ùå Execution failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ef532",
   "metadata": {},
   "source": [
    "> **Note:** All values are approximate and reflect estimates as of **August 2025**. Word, token, sentence, and character counts can vary by writing style and tokenization method.\n",
    "\n",
    "- Tokens calculated as `words √∑ 0.75`.\n",
    "- Sentences calculated as `words √∑ 15‚Äì20`.\n",
    "- Characters calculated as `words √ó 4‚Äì5`.\n",
    "\n",
    "| Article Type / Measure         | Approx Words | Approx Sentences | Approx Tokens | Approx Characters | Notes                               | Suggested Summary (Tokens / Chars)     |\n",
    "| ------------------------------ | ------------ | ---------------- | ------------- | ----------------- | ----------------------------------- | -------------------------------------- |\n",
    "| Short text (60 tokens)         | ~45          | ~2‚Äì3             | ~60           | ~180‚Äì225          | Short paragraph / social media post | ~10 tokens / ~40‚Äì50 chars              |\n",
    "| Blog article                   | 1,000‚Äì1,800  | ~50‚Äì120          | ~1,300‚Äì2,400  | ~4,000‚Äì9,000      | Typical online blog length          | ~150‚Äì360 tokens / ~400‚Äì900 chars       |\n",
    "| NYT Op-Ed                      | 800‚Äì1,200    | ~40‚Äì80           | ~1,050‚Äì1,600  | ~3,200‚Äì6,000      | Opinion/editorial piece             | ~100‚Äì240 tokens / ~320‚Äì600 chars       |\n",
    "| Research article (web/journal) | 3,000‚Äì7,000  | ~150‚Äì470         | ~4,000‚Äì9,300  | ~12,000‚Äì35,000    | Standard journal or web publication | ~400‚Äì1,400 tokens / ~1,200‚Äì3,500 chars |\n",
    "| arXiv preprint                 | 6,000‚Äì12,000 | ~300‚Äì800         | ~8,000‚Äì16,000 | ~24,000‚Äì60,000    | Preprint scientific paper           | ~800‚Äì1,600 tokens / ~2,400‚Äì6,000 chars |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
