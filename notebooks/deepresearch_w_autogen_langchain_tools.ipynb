{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bc3cfa",
   "metadata": {},
   "source": [
    "# ü§ñ Multi-Agent Deep Research System\n",
    "\n",
    "This notebook showcases how to harness the combined power of **AutoGen** and **LangChain** tools to automate and elevate deep research workflows. At its core, the system coordinates a network of specialized agents‚Äîeach executing a distinct role in the research and report generation workflow. Together, these agents collect data, analyze findings, and produce polished, insight-driven reports.\n",
    "\n",
    "[Open in Colab](https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb) <a href=\"https://colab.research.google.com/github/miztiik/taars/blob/master/notebooks/deepresearch_w_autogen_langchain_tools.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## üß† Agent Roles\n",
    "\n",
    "- **üß≠ Planner**: Defines research scope, objectives, and success criteria\n",
    "- **üîç Researcher**: Gathers evidence using `wiki_search`, `web_research` tools with intelligent source selection\n",
    "- **üß™ Critic**: Reviews plans and outputs for quality and completeness using approval signals\n",
    "- **‚úçÔ∏è Editor**: Formats final reports with proper citations and saves using `save_report` tool\n",
    "\n",
    "## üîÑ System Architecture\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User Query] --> B[üß≠ Planner]\n",
    "    B --> C{üß™ Critic Review}\n",
    "    C -->|PLAN_APPROVED| D[üîç Researcher]\n",
    "    C -->|NEEDS_REFINEMENT| B\n",
    "    D --> E{üß™ Critic Review}\n",
    "    E -->|RESEARCH_APPROVED| F[‚úçÔ∏è Editor]\n",
    "    E -->|NEEDS_REFINEMENT| D\n",
    "    F --> G[Final Report]\n",
    "```\n",
    "\n",
    "## üöÄ Quick Start\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Set environment variables:\n",
    "\n",
    "```bash\n",
    "# Required: Gemini API (or configure other models in cells below)\n",
    "export GEMINI_API_KEY=\"your_api_key\"\n",
    "export GEMINI_MODEL_NAME=\"gemini-1.5-flash\"\n",
    "export GEMINI_BASE_URL=\"https://generativelanguage.googleapis.com/v1beta/\"\n",
    "```\n",
    "\n",
    "### Run Research Task\n",
    "\n",
    "1. **Execute all cells** in sequence\n",
    "2. **Modify the query** in the final cell:\n",
    "   ```python\n",
    "   output = asyncio.run(run_task(\"Your research question here\"))\n",
    "   ```\n",
    "3. **Monitor progress** in real-time through cell outputs\n",
    "\n",
    "## üìã Example Queries\n",
    "\n",
    "- **Financial Analysis**: `\"Indian steel sector growth prospects in an era of US tariffs\"`\n",
    "- **Economic Research**: `\"Government factors that improved Indian economy during Modi era\"`\n",
    "- **Tech Industry**: `\"Are we witnessing an AI infrastructure bubble? GDP investment vs productivity gains\"`\n",
    "- **AI/ML Trends**: `\"Current trends in tool usage during LLM training\"`\n",
    "\n",
    "## üìä Outputs & Monitoring\n",
    "\n",
    "| Output Type | Location                                          | Description                                            |\n",
    "| ----------- | ------------------------------------------------- | ------------------------------------------------------ |\n",
    "| **Reports** | `./reports/`                                      | Timestamped Markdown reports (auto-saved)              |\n",
    "| **Logs**    | `./logs/YYYYMMDD_HHMM_deep_research_agent.log`    | Timestamped execution logs with token usage            |\n",
    "| **State**   | `./YYYYMMDD_HHMM_[task_keywords]_team_state.json` | Task-specific conversation state for resume capability |\n",
    "\n",
    "## üîÑ **Resume Functionality**\n",
    "\n",
    "```python\n",
    "# Auto-resume from most recent state file\n",
    "await resume_from_saved_state()\n",
    "\n",
    "# Resume from specific state file\n",
    "await resume_from_saved_state(\"20250824_1430_green_hydrogen_viability_team_state.json\")\n",
    "\n",
    "# List all available state files\n",
    "list_team_state_files()\n",
    "```\n",
    "\n",
    "## üìù TODO & Roadmap\n",
    "\n",
    "- [ ] **Specialized Models**: Different LLMs for different agent roles (planning vs research vs writing)\n",
    "- [ ] **Semantic Depth Search**: Advanced content extraction with semantic similarity scoring\n",
    "- [ ] **Source Verification**: Cross-reference validation and fact-checking workflows\n",
    "- [ ] **Domain-Specific Tools**: Specialized research tools for finance, science, law, etc.\n",
    "- [ ] **Agent Control Flow Logging**: Meaningful event logging for agent-to-agent handoffs\n",
    "- [ ] **Organic Flow Orchestration**: Improved prompts for natural, adaptive conversation flow\n",
    "- [ ] **Streaming UI**: Real-time progress visualization and intervention capability\n",
    "- [ ] **Performance Metrics**: Research quality scoring and optimization analytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "%pip install -qU ipykernel\n",
    "%pip install -qU loguru\n",
    "%pip install -qU python-dotenv\n",
    "\n",
    "%pip install -qU autogen-agentchat\n",
    "%pip install -qU autogen-ext\n",
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-community\n",
    "%pip install -qU wikipedia\n",
    "%pip install -qU selenium unstructured\n",
    "%pip install -qU lxml\n",
    "%pip install -qU ddgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4222bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GOOGLE COLAB LINE WRAPPING\n",
    "# https://stackoverflow.com/questions/58890109/line-wrapping-in-collaboratory-google-results\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def set_css():\n",
    "    display(\n",
    "        HTML(\n",
    "            \"\"\"\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "get_ipython().events.register(\"pre_run_cell\", set_css)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %aimport -langchain_community\n",
    "# Automatically reload modules before executing code\n",
    "\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48776430",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERIC IMPORTS\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Annotated, Tuple\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import nest_asyncio\n",
    "import tenacity\n",
    "from loguru import logger\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS\n",
    "\n",
    "## LOG CONFIG\n",
    "LOG_ROTATION_SIZE = \"10 MB\"\n",
    "LOG_RETENTION_DAYS = \"7 days\"\n",
    "\n",
    "## AUTOGEN CONFIG\n",
    "CONVERSATION_BUFFER_SIZE = 10\n",
    "TASK_TERMINATION_MAX_MESSAGES = 100\n",
    "API_CALL_DELAY_SECONDS = int(\n",
    "    os.environ.get(\"API_CALL_DELAY_SECONDS\", \"59\")\n",
    ")  # 59 seconds = 1.02 RPM\n",
    "NON_API_EVENT_DELAY = 10  # Small delay for non-API events\n",
    "\n",
    "## TOOL CONFIG\n",
    "WIKI_MAX_RESULTS = 5\n",
    "WIKI_MAX_CHARS = 5000\n",
    "WIKIPEDIA_MAX_DOCS = 2\n",
    "DDGS_MAX_RESULTS = 3\n",
    "WEB_CONTENT_MAX_LENGTH = 15000\n",
    "WEB_CONTENT_MIN_LENGTH = 300\n",
    "WEB_BATCH_MAX_URLS = 5\n",
    "SELENIUM_WINDOW_SIZE = \"1920,1080\"\n",
    "BROWSER_USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\"\n",
    "TITLE_SLICE_LENGTH = 50\n",
    "TOP_RESULTS_COUNT = 3\n",
    "TASK_MAX_MEANINGFUL_WORDS = 3\n",
    "CRITIC_MAX_WORDS = 500\n",
    "URL_FETCH_DELAY = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOGGING CONFIG\n",
    "notebook_dir = Path.cwd()\n",
    "log_dir = notebook_dir / \"logs\"\n",
    "\n",
    "# Generate timestamped log filename\n",
    "timestamp = datetime.now()\n",
    "log_timestamp = timestamp.strftime(\"%Y%m%d_%H%M\")\n",
    "log_file = log_dir / f\"{log_timestamp}_deep_research_agent.log\"\n",
    "\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if not getattr(sys, \"_loguru_configured\", False):\n",
    "    logger.remove()\n",
    "    logger.add(\n",
    "        str(log_file),\n",
    "        level=\"DEBUG\",\n",
    "        rotation=\"10 MB\",\n",
    "        retention=\"7 days\",\n",
    "        compression=\"zip\",\n",
    "        enqueue=True,\n",
    "    )\n",
    "    logger.add(sys.stderr, colorize=True, level=\"WARNING\")\n",
    "    logger.add(sys.stdout, colorize=True, level=\"INFO\")\n",
    "    sys._loguru_configured = True\n",
    "\n",
    "logger.info(f\"‚úÖ Logging configured successfully - Log file: {log_file.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.messages import StopMessage\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_core.model_context import BufferedChatCompletionContext\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_community.document_loaders import SeleniumURLLoader\n",
    "from ddgs import DDGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef193373",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GEMINI MODEL CLIENT\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "load_dotenv(os.path.join(\"..\", \".env\"))\n",
    "\n",
    "# Confirm the API key is set\n",
    "assert os.environ[\"GEMINI_API_KEY\"], \"GEMINI_API_KEY is not set\"\n",
    "assert os.environ[\"GEMINI_MODEL_NAME\"], \"GEMINI_MODEL_NAME is not set\"\n",
    "assert os.environ[\"GEMINI_BASE_URL\"], \"GEMINI_BASE_URL is not set\"\n",
    "\n",
    "\n",
    "gemini_model_info = ModelInfo(\n",
    "    vision=False,\n",
    "    function_calling=True,\n",
    "    json_output=True,\n",
    "    family=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    structured_output=True,\n",
    ")\n",
    "\n",
    "gemini_model_client = OpenAIChatCompletionClient(\n",
    "    model=os.environ[\"GEMINI_MODEL_NAME\"],\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    base_url=os.environ[\"GEMINI_BASE_URL\"],\n",
    "    model_info=gemini_model_info,\n",
    "    max_retries=3,\n",
    "    parallel_tool_calls=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30311843",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AZURE OPENAI MODEL CLIENT\n",
    "# from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "## Confirm the API key is set\n",
    "# assert os.environ[\"AZURE_OAI_DEPLOYMENT\"], \"AZURE_OAI_DEPLOYMENT is not set\"\n",
    "# assert os.environ[\"AZURE_OAI_MODEL_NAME\"], \"AZURE_OAI_MODEL_NAME is not set\"\n",
    "# assert os.environ[\"AZURE_OAI_MODEL_VERSION\"], \"AZURE_OAI_MODEL_VERSION is not set\"\n",
    "# assert os.environ[\"AZURE_OAI_BASE_URL\"], \"AZURE_OAI_BASE_URL is not set\"\n",
    "\n",
    "# az_oai_model_client = AzureOpenAIChatCompletionClient(\n",
    "#     azure_deployment=os.environ[\"AZURE_OAI_DEPLOYMENT\"],\n",
    "#     model=os.environ[\"AZURE_OAI_MODEL_NAME\"],\n",
    "#     api_version=os.environ[\"AZURE_OAI_MODEL_VERSION\"],\n",
    "#     azure_endpoint=os.environ[\"AZURE_OAI_BASE_URL\"],\n",
    "\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGENT TOOLS\n",
    "\n",
    "\n",
    "wiki_api = WikipediaAPIWrapper(\n",
    "    top_k_results=WIKI_MAX_RESULTS, doc_content_chars_max=WIKI_MAX_CHARS\n",
    ")\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api)\n",
    "\n",
    "\n",
    "def wiki_full_search(input: str) -> str:\n",
    "    \"\"\"Search Wikipedia for a query and return maximum 2 results.\"\"\"\n",
    "    logger.info(f\"üîç wiki_full_search: Starting search for '{input}'\")\n",
    "\n",
    "    try:\n",
    "        search_docs = WikipediaLoader(\n",
    "            query=input, load_max_docs=WIKIPEDIA_MAX_DOCS\n",
    "        ).load()\n",
    "\n",
    "        if not search_docs:\n",
    "            logger.warning(f\"‚ö†Ô∏è wiki_full_search: No documents found for '{input}'\")\n",
    "            return f\"No Wikipedia articles found for query: {input}\"\n",
    "\n",
    "        logger.info(\n",
    "            f\"‚úÖ wiki_full_search: Found {len(search_docs)} documents for '{input}'\"\n",
    "        )\n",
    "\n",
    "        formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "            [\n",
    "                f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "                for doc in search_docs\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        content_length = len(formatted_search_docs)\n",
    "        logger.info(\n",
    "            f\"üìä wiki_full_search: Returning {content_length} characters for '{input}'\"\n",
    "        )\n",
    "\n",
    "        return formatted_search_docs\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå wiki_full_search failed for '{input}': {str(e)}\")\n",
    "        return f\"Error searching Wikipedia for '{input}': {str(e)}\"\n",
    "\n",
    "\n",
    "def wiki_search(q: str) -> dict:\n",
    "    \"\"\"Return structured output including text and source.\"\"\"\n",
    "    logger.info(f\"üîç wiki_search: Starting search for '{q}'\")\n",
    "\n",
    "    try:\n",
    "        result = wiki_tool.run(q)\n",
    "\n",
    "        if not result or result.strip() == \"\":\n",
    "            logger.warning(f\"‚ö†Ô∏è wiki_search: Empty result for '{q}'\")\n",
    "            return {\"text\": \"No results found\", \"source\": \"Wikipedia\", \"query\": q}\n",
    "\n",
    "        result_length = len(result)\n",
    "        logger.info(f\"‚úÖ wiki_search: Retrieved {result_length} characters for '{q}'\")\n",
    "\n",
    "        return {\"text\": result, \"source\": \"Wikipedia\", \"query\": q}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå wiki_search failed for '{q}': {str(e)}\")\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None, \"query\": q}\n",
    "\n",
    "\n",
    "def web_search(q: str) -> dict:\n",
    "    \"\"\"`\n",
    "    Performs a web search across multiple search backends (Google, Brave, Bing, Yahoo)\n",
    "    using DuckDuckGo's API to gather relevant results for research queries.\n",
    "\n",
    "    Args:\n",
    "        q (str): The search query string. Should be specific and well-formed\n",
    "                for optimal results.\n",
    "\n",
    "    Returns:\n",
    "        dict: A structured response containing:\n",
    "            - text (list): List of search result dictionaries, each containing:\n",
    "                * title: Article/page title\n",
    "                * href: URL link\n",
    "                * body: Content snippet/description\n",
    "            - source (str): Search engine identifier (\"DuckDuckGo\")\n",
    "            - query (str): The original search query\n",
    "                for optimal results.\n",
    "    \"\"\"\n",
    "    logger.info(f\"üåê web_search: Starting web search for '{q}'\")\n",
    "    try:\n",
    "        results = DDGS().text(\n",
    "            q,\n",
    "            region=\"us-en\",\n",
    "            safesearch=\"off\",\n",
    "            max_results=DDGS_MAX_RESULTS,\n",
    "            backend=\"google, brave, bing, yahoo\",\n",
    "        )\n",
    "\n",
    "        if not results:\n",
    "            logger.warning(f\"‚ö†Ô∏è web_search: No results found for '{q}'\")\n",
    "            return {\n",
    "                \"text\": [],\n",
    "                \"source\": \"DuckDuckGo\",\n",
    "                \"query\": q,\n",
    "                \"results_found\": 0,\n",
    "            }\n",
    "\n",
    "        logger.info(f\"‚úÖ web_search: Found {len(results)} results for '{q}'\")\n",
    "\n",
    "        # Log sample of top results for debugging\n",
    "        if results:\n",
    "            top_titles = [\n",
    "                r.get(\"title\", \"No title\")[:TITLE_SLICE_LENGTH]\n",
    "                for r in results[:TOP_RESULTS_COUNT]\n",
    "            ]\n",
    "            logger.debug(\n",
    "                f\"üìã web_search: Logging {TOP_RESULTS_COUNT} results for '{q}': {top_titles}\"\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"text\": results,\n",
    "            \"source\": \"DuckDuckGo\",\n",
    "            \"query\": q,\n",
    "            \"results_found\": len(results),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå web_search failed for '{q}': {str(e)}\")\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"source\": None, \"query\": q}\n",
    "\n",
    "\n",
    "def web_fetch(\n",
    "    url: str, max_content_length: int = WEB_CONTENT_MAX_LENGTH\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch web page content using Selenium for JavaScript-heavy sites.\n",
    "\n",
    "    Args:\n",
    "        url: The URL to fetch content from\n",
    "        max_content_length: Maximum content length to return. Defaults to WEB_CONTENT_MAX_LENGTH\n",
    "\n",
    "    Returns:\n",
    "        Dict with keys: content, url, status, error (if any)\n",
    "    \"\"\"\n",
    "    logger.info(\n",
    "        f\"üåê web_fetch: Starting fetch for {url} (max_length: {max_content_length})\"\n",
    "    )\n",
    "\n",
    "    loader = None\n",
    "\n",
    "    try:\n",
    "        # Validate URL\n",
    "        if not url or not url.startswith((\"http://\", \"https://\")):\n",
    "            return {\n",
    "                \"content\": \"\",\n",
    "                \"url\": url,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"Invalid URL format\",\n",
    "            }\n",
    "\n",
    "        # Configure Selenium loader\n",
    "        loader = SeleniumURLLoader(\n",
    "            urls=[url],\n",
    "            continue_on_failure=True,\n",
    "            arguments=_get_selenium_arguments(),\n",
    "            browser=\"chrome\",\n",
    "        )\n",
    "\n",
    "        # Load content\n",
    "        logger.info(f\"üì• web_fetch: Loading content from {url}\")\n",
    "        documents = loader.load()\n",
    "\n",
    "        if not documents:\n",
    "            logger.warning(f\"‚ö†Ô∏è web_fetch: No documents loaded from {url}\")\n",
    "            return {\n",
    "                \"content\": \"\",\n",
    "                \"url\": url,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"No content could be loaded from URL\",\n",
    "            }\n",
    "\n",
    "        # Process content\n",
    "        content = documents[0].page_content.strip()\n",
    "        original_length = len(content)\n",
    "\n",
    "        logger.debug(f\"üìä web_fetch: Loaded {original_length} characters from {url}\")\n",
    "\n",
    "        if len(content) < WEB_CONTENT_MIN_LENGTH:\n",
    "            logger.warning(\n",
    "                f\"‚ö†Ô∏è web_fetch: Content too short ({len(content)} chars) from {url}\"\n",
    "            )\n",
    "            return {\n",
    "                \"content\": content,\n",
    "                \"url\": url,\n",
    "                \"status\": \"warning\",\n",
    "                \"error\": \"Content appears too short, may indicate loading issues\",\n",
    "            }\n",
    "\n",
    "        # Truncate if too long\n",
    "        if len(content) > max_content_length:\n",
    "            content = content[:max_content_length] + \"\\n\\n[Content truncated...]\"\n",
    "            logger.info(\n",
    "                f\"‚úÇÔ∏è web_fetch: Content truncated from {original_length} to {max_content_length} chars for {url}\"\n",
    "            )\n",
    "\n",
    "        logger.info(\n",
    "            f\"‚úÖ web_fetch: Successfully fetched {len(content)} characters from {url}\"\n",
    "        )\n",
    "\n",
    "        return {\"content\": content, \"url\": url, \"status\": \"success\", \"error\": None}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå web_fetch failed for {url}: {str(e)}\")\n",
    "        return {\n",
    "            \"content\": \"\",\n",
    "            \"url\": url,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": f\"Failed to fetch content: {str(e)}\",\n",
    "        }\n",
    "\n",
    "    finally:\n",
    "        # CRITICAL: Clean up browser resources\n",
    "        if loader and hasattr(loader, \"web_driver\") and loader.web_driver:\n",
    "            try:\n",
    "                loader.web_driver.quit()\n",
    "                logger.debug(f\"üßπ web_fetch: Browser cleaned up for {url}\")\n",
    "            except Exception as cleanup_error:\n",
    "                logger.warning(f\"‚ö†Ô∏è web_fetch: Browser cleanup failed: {cleanup_error}\")\n",
    "\n",
    "\n",
    "def _get_selenium_arguments() -> List[str]:\n",
    "    \"\"\"Get optimized Selenium browser arguments for reliability and stealth.\n",
    "    Returns:\n",
    "        List of browser arguments\n",
    "    \"\"\"\n",
    "    return [\n",
    "        # Core stability\n",
    "        \"--headless\",\n",
    "        \"--no-sandbox\",\n",
    "        \"--disable-dev-shm-usage\",\n",
    "        \"--disable-gpu\",\n",
    "        f\"--window-size={SELENIUM_WINDOW_SIZE}\",\n",
    "        # Performance\n",
    "        \"--disable-extensions\",\n",
    "        \"--disable-plugins\",\n",
    "        \"--disable-images\",\n",
    "        \"--disable-javascript\",\n",
    "        # Timeout and connection settings\n",
    "        \"--timeout=60000\",  # 60 second timeout\n",
    "        \"--page-load-strategy=eager\",  # Don't wait for all resources\n",
    "        \"--disable-background-timer-throttling\",\n",
    "        \"--disable-renderer-backgrounding\",\n",
    "        # Network optimizations\n",
    "        \"--aggressive-cache-discard\",\n",
    "        \"--disable-background-networking\",\n",
    "        # Stealth and compatibility\n",
    "        \"--disable-blink-features=AutomationControlled\",\n",
    "        f\"--user-agent={BROWSER_USER_AGENT}\",\n",
    "        # GDPR/Cookie banner handling\n",
    "        \"--disable-notifications\",\n",
    "        \"--disable-infobars\",\n",
    "        \"--disable-default-apps\",\n",
    "        # Security bypasses (use cautiously)\n",
    "        \"--ignore-certificate-errors\",\n",
    "        \"--ignore-ssl-errors\",\n",
    "        \"--allow-running-insecure-content\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def web_fetch_multiple(\n",
    "    urls: List[str], max_content_length: int = WEB_CONTENT_MAX_LENGTH\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch content from multiple URLs efficiently.\n",
    "\n",
    "    Args:\n",
    "        urls: List of URLs to fetch\n",
    "        max_content_length: Maximum content length per URL\n",
    "\n",
    "    Returns:\n",
    "        Dict with results for each URL and summary statistics\n",
    "    \"\"\"\n",
    "    logger.info(f\"üåê web_fetch_multiple: Starting batch fetch for {len(urls)} URLs\")\n",
    "\n",
    "    if not urls or len(urls) > WEB_BATCH_MAX_URLS:\n",
    "        logger.warning(\n",
    "            f\"‚ö†Ô∏è web_fetch_multiple: Invalid URL list - {len(urls) if urls else 0} URLs (max {WEB_BATCH_MAX_URLS})\"\n",
    "        )\n",
    "        return {\n",
    "            \"results\": [],\n",
    "            \"status\": \"error\",\n",
    "            \"error\": f\"Invalid URL list (empty or too many URLs, max {WEB_BATCH_MAX_URLS})\",\n",
    "        }\n",
    "\n",
    "    results = []\n",
    "    success_count = 0\n",
    "\n",
    "    logger.debug(\n",
    "        f\"üìã web_fetch_multiple: Processing URLs: {[f'{url[:TITLE_SLICE_LENGTH]}...' if len(url) > TITLE_SLICE_LENGTH else url for url in urls]}\"\n",
    "    )\n",
    "\n",
    "    for i, url in enumerate(urls, 1):\n",
    "        logger.debug(f\"üîÑ web_fetch_multiple: Processing URL {i}/{len(urls)}: {url}\")\n",
    "\n",
    "        result = web_fetch(url, max_content_length)\n",
    "        results.append(result)\n",
    "\n",
    "        if result[\"status\"] == \"success\":\n",
    "            success_count += 1\n",
    "            logger.debug(f\"‚úÖ web_fetch_multiple: URL {i}/{len(urls)} successful\")\n",
    "        else:\n",
    "            logger.debug(\n",
    "                f\"‚ùå web_fetch_multiple: URL {i}/{len(urls)} failed: {result.get('error', 'Unknown error')}\"\n",
    "            )\n",
    "\n",
    "        # Brief delay to be respectful\n",
    "        time.sleep(URL_FETCH_DELAY)\n",
    "\n",
    "    logger.info(\n",
    "        f\"üèÅ web_fetch_multiple: Completed batch - {success_count}/{len(urls)} successful\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"total_urls\": len(urls),\n",
    "        \"successful\": success_count,\n",
    "        \"failed\": len(urls) - success_count,\n",
    "        \"status\": \"completed\",\n",
    "    }\n",
    "\n",
    "\n",
    "def web_research(\n",
    "    query: str, max_content_length: int = WEB_CONTENT_MAX_LENGTH\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Complete web research workflow: search + selective content fetching.\n",
    "\n",
    "    Combines web_search and web_fetch_multiple to provide comprehensive\n",
    "    research results with both search snippets and full content.\n",
    "    Uses DDGS_MAX_RESULTS to determine how many URLs to fetch content from.\n",
    "\n",
    "    Args:\n",
    "        query: Search query string\n",
    "        max_content_length: Maximum content length per fetched page\n",
    "\n",
    "    Returns:\n",
    "        Dict containing:\n",
    "            - search_results: Original search results from web_search\n",
    "            - fetched_content: Full content from top N URLs (N = DDGS_MAX_RESULTS)\n",
    "            - summary: Aggregated statistics\n",
    "            - errors: Any fetch failures\n",
    "    \"\"\"\n",
    "    logger.info(\n",
    "        f\"üî¨ web_research: Starting comprehensive research for '{query}' (will fetch top {DDGS_MAX_RESULTS} URLs)\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Step 1: Get search results (automatically limited by DDGS_MAX_RESULTS)\n",
    "        search_response = web_search(query)\n",
    "\n",
    "        if not search_response.get(\"text\") or search_response[\"results_found\"] == 0:\n",
    "            logger.warning(f\"‚ö†Ô∏è web_research: No search results for '{query}'\")\n",
    "            return {\n",
    "                \"search_results\": search_response,\n",
    "                \"fetched_content\": [],\n",
    "                \"summary\": {\"total_searched\": 0, \"total_fetched\": 0, \"success_rate\": 0},\n",
    "                \"errors\": [\"No search results found\"],\n",
    "            }\n",
    "\n",
    "        # Step 2: Extract ALL URLs from search results (already limited by DDGS_MAX_RESULTS)\n",
    "        search_results = search_response[\"text\"]\n",
    "        top_urls = [\n",
    "            result.get(\"href\") for result in search_results if result.get(\"href\")\n",
    "        ]\n",
    "\n",
    "        if not top_urls:\n",
    "            logger.warning(\n",
    "                f\"‚ö†Ô∏è web_research: No valid URLs found in search results for '{query}'\"\n",
    "            )\n",
    "            return {\n",
    "                \"search_results\": search_response,\n",
    "                \"fetched_content\": [],\n",
    "                \"summary\": {\n",
    "                    \"total_searched\": len(search_results),\n",
    "                    \"total_fetched\": 0,\n",
    "                    \"success_rate\": 0,\n",
    "                },\n",
    "                \"errors\": [\"No valid URLs in search results\"],\n",
    "            }\n",
    "\n",
    "        # Step 3: Fetch full content from all URLs (already limited by DDGS_MAX_RESULTS)\n",
    "        logger.info(\n",
    "            f\"üì• web_research: Fetching content from {len(top_urls)} URLs (max from DDGS_MAX_RESULTS={DDGS_MAX_RESULTS})\"\n",
    "        )\n",
    "        fetch_response = web_fetch_multiple(top_urls, max_content_length)\n",
    "\n",
    "        # Step 4: Calculate summary statistics\n",
    "        successful_fetches = sum(\n",
    "            1 for result in fetch_response[\"results\"] if result[\"status\"] == \"success\"\n",
    "        )\n",
    "        success_rate = (successful_fetches / len(top_urls)) * 100 if top_urls else 0\n",
    "\n",
    "        summary = {\n",
    "            \"total_searched\": len(search_results),\n",
    "            \"total_fetched\": len(top_urls),\n",
    "            \"successful_fetches\": successful_fetches,\n",
    "            \"success_rate\": round(success_rate, 1),\n",
    "            \"query\": query,\n",
    "            \"max_urls_limit\": DDGS_MAX_RESULTS,\n",
    "        }\n",
    "\n",
    "        # Step 5: Collect any errors\n",
    "        errors = []\n",
    "        if fetch_response[\"failed\"] > 0:\n",
    "            failed_urls = [\n",
    "                r[\"url\"] for r in fetch_response[\"results\"] if r[\"status\"] != \"success\"\n",
    "            ]\n",
    "            errors.append(\n",
    "                f\"Failed to fetch {fetch_response['failed']} URLs: {failed_urls[:3]}\"\n",
    "            )\n",
    "\n",
    "        logger.info(\n",
    "            f\"‚úÖ web_research: Completed for '{query}' - \"\n",
    "            f\"{successful_fetches}/{len(top_urls)} fetches successful ({success_rate}%)\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"search_results\": search_response,\n",
    "            \"fetched_content\": fetch_response[\"results\"],\n",
    "            \"summary\": summary,\n",
    "            \"errors\": errors,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå web_research failed for '{query}': {str(e)}\")\n",
    "        return {\n",
    "            \"search_results\": {},\n",
    "            \"fetched_content\": [],\n",
    "            \"summary\": {\"total_searched\": 0, \"total_fetched\": 0, \"success_rate\": 0},\n",
    "            \"errors\": [f\"Research pipeline failed: {str(e)}\"],\n",
    "        }\n",
    "\n",
    "\n",
    "def save_report(\n",
    "    content: str, task_description: str, reports_dir: str = \"reports\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Save timestamped Markdown report to disk with auto-generated filename.\n",
    "\n",
    "    Args:\n",
    "        content: Report content (plain text or Markdown). Auto-adds title if missing.\n",
    "        task_description: Brief task description for filename generation.\n",
    "        reports_dir: Output directory (default: \"reports\"). Created if missing.\n",
    "\n",
    "    Returns:\n",
    "        Dict with keys: status (\"success\"/\"error\"), filepath, filename, error\n",
    "\n",
    "    Examples:\n",
    "        save_report(\"# Analysis\\n\\nFindings...\", \"market research 2024\")\n",
    "        # ‚Üí reports/20250824_1430_15_market_research.md\n",
    "\n",
    "        save_report(draft_text, \"AI impact assessment\")\n",
    "        # ‚Üí reports/20250824_1431_22_ai_impact.md\n",
    "\n",
    "    Filename: YYYYMMDD_HHMM_SS_key_words.md (auto-numbered if exists)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure reports directory exists\n",
    "        reports_path = Path(reports_dir)\n",
    "        reports_path.mkdir(exist_ok=True)\n",
    "\n",
    "        # Generate timestamped filename with seconds for better uniqueness\n",
    "        timestamp = datetime.now()\n",
    "        date_time = timestamp.strftime(\"%Y%m%d_%H%M_%S\")\n",
    "        task_name = _extract_task_name(task_description)\n",
    "\n",
    "        filename = f\"{date_time}_{task_name}.md\"\n",
    "        filepath = reports_path / filename\n",
    "\n",
    "        # Handle filename conflicts with counter\n",
    "        counter = 1\n",
    "        while filepath.exists():\n",
    "            filename = f\"{date_time}_{task_name}_{counter}.md\"\n",
    "            filepath = reports_path / filename\n",
    "            counter += 1\n",
    "\n",
    "        # Format content with title if needed\n",
    "        formatted_content = _format_content(content, task_description, timestamp)\n",
    "\n",
    "        # Save to disk using Path object\n",
    "        filepath.write_text(formatted_content, encoding=\"utf-8\")\n",
    "        logger.info(f\"üìÑ Report saved: {filepath}\")\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"filepath\": str(filepath),\n",
    "            \"filename\": filename,\n",
    "            \"timestamp\": timestamp.isoformat(),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to save report: {str(e)}\"\n",
    "        logger.error(f\"‚ùå {error_msg}\")\n",
    "        return {\"status\": \"error\", \"error\": error_msg, \"task\": task_description}\n",
    "\n",
    "\n",
    "def _extract_task_name(task: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract 2-3 meaningful words from task description for filename.\n",
    "\n",
    "    Args:\n",
    "        task: The task description string\n",
    "\n",
    "    Returns:\n",
    "        Underscore-separated words suitable for filename\n",
    "    \"\"\"\n",
    "    # Clean special characters and normalize\n",
    "    clean_task = re.sub(r\"[^\\w\\s]\", \" \", task.lower())\n",
    "    words = [w for w in clean_task.split() if len(w) > 2]\n",
    "\n",
    "    # Filter common stop words\n",
    "    stop_words = {\n",
    "        \"the\",\n",
    "        \"and\",\n",
    "        \"for\",\n",
    "        \"with\",\n",
    "        \"from\",\n",
    "        \"about\",\n",
    "        \"into\",\n",
    "        \"through\",\n",
    "        \"during\",\n",
    "        \"before\",\n",
    "        \"after\",\n",
    "        \"above\",\n",
    "        \"below\",\n",
    "        \"over\",\n",
    "        \"under\",\n",
    "    }\n",
    "    meaningful = [w for w in words if w not in stop_words][:TASK_MAX_MEANINGFUL_WORDS]\n",
    "\n",
    "    return \"_\".join(meaningful) if meaningful else \"report\"\n",
    "\n",
    "\n",
    "def _format_content(content: str, task: str, timestamp: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Format content with title and timestamp if needed.\n",
    "\n",
    "    Args:\n",
    "        content: Raw content to format\n",
    "        task: Task description for title generation\n",
    "        timestamp: When the report was created\n",
    "\n",
    "    Returns:\n",
    "        Formatted Markdown content\n",
    "    \"\"\"\n",
    "    # If content already has a Markdown title, use as-is\n",
    "    if content.strip().startswith(\"#\"):\n",
    "        return content\n",
    "\n",
    "    # Add title and timestamp for plain text content\n",
    "    formatted_title = f\"# Report: {task}\"\n",
    "    timestamp_line = f\"*Generated: {timestamp.strftime('%Y-%m-%d %H:%M')}*\"\n",
    "\n",
    "    return f\"{formatted_title}\\n\\n{timestamp_line}\\n\\n{content}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291cb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REGISTER FUNCTIONS AS TOOLS\n",
    "\n",
    "wiki_search_tool = FunctionTool(\n",
    "    func=wiki_search,\n",
    "    name=\"wiki_search\",\n",
    "    description=\"Search Wikipedia for information.\",\n",
    ")\n",
    "web_search_tool = FunctionTool(\n",
    "    func=web_search,\n",
    "    name=\"web_search\",\n",
    "    description=\"Search the given query and get list of URLs.\",\n",
    ")\n",
    "web_fetch_tool = FunctionTool(\n",
    "    func=web_fetch, name=\"web_fetch\", description=\"Fetch content from a web page.\"\n",
    ")\n",
    "web_fetch_multiple_tool = FunctionTool(\n",
    "    func=web_fetch_multiple,\n",
    "    name=\"web_fetch_multiple\",\n",
    "    description=\"Fetch content from multiple web pages.\",\n",
    ")\n",
    "web_research_tool = FunctionTool(\n",
    "    func=web_research,\n",
    "    name=\"web_research\",\n",
    "    description=\"Complete web research: search + fetch full content from top results.\",\n",
    ")\n",
    "save_report_tool = FunctionTool(\n",
    "    func=save_report, name=\"save_report\", description=\"Save the research report.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b446dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UTILITY FUNCTIONS\n",
    "\n",
    "# Global token accounting - managed by log_event_enhanced\n",
    "_token_accounting = {\n",
    "    \"total_prompt_tokens\": 0,\n",
    "    \"total_completion_tokens\": 0,\n",
    "    \"total_tokens\": 0,\n",
    "    \"llm_call_count\": 0,\n",
    "    \"processed_event_ids\": set(),\n",
    "}\n",
    "\n",
    "\n",
    "def reset_token_accounting():\n",
    "    \"\"\"Reset global token accounting for new task.\"\"\"\n",
    "    global _token_accounting\n",
    "    _token_accounting = {\n",
    "        \"total_prompt_tokens\": 0,\n",
    "        \"total_completion_tokens\": 0,\n",
    "        \"total_tokens\": 0,\n",
    "        \"llm_call_count\": 0,\n",
    "        \"processed_event_ids\": set(),\n",
    "    }\n",
    "    logger.debug(\"üîÑ Token accounting reset for new task\")\n",
    "\n",
    "\n",
    "def get_token_stats():\n",
    "    \"\"\"Get current token statistics.\"\"\"\n",
    "    return _token_accounting.copy()\n",
    "\n",
    "\n",
    "def determine_event_delay(event, event_count: int) -> float:\n",
    "    \"\"\"\n",
    "    Determine appropriate delay for different event types based on API usage patterns.\n",
    "\n",
    "    Logic: API-bound operations (model calls, tool calls, agent selections) get longer delay\n",
    "    to respect rate limits. Internal processing events get minimal delay.\n",
    "\n",
    "    Args:\n",
    "        event: The event object from the team stream\n",
    "        event_count: Total number of events processed (for logging context)\n",
    "\n",
    "    Returns:\n",
    "        float: Delay in seconds\n",
    "    \"\"\"\n",
    "    # Check for model/LLM API usage (includes token-consuming calls)\n",
    "    has_model_usage = hasattr(event, \"models_usage\") and event.models_usage\n",
    "\n",
    "    # Check for tool API calls\n",
    "    has_tool_calls = hasattr(event, \"tool_calls\") and event.tool_calls\n",
    "\n",
    "    # Check for agent selection logic (often uses LLM reasoning but may not show tokens)\n",
    "    event_type = getattr(event, \"type\", type(event).__name__)\n",
    "    is_agent_selection = (\n",
    "        \"select\" in event_type.lower() or \"speaker\" in event_type.lower()\n",
    "    )\n",
    "\n",
    "    # API-bound operations get longer delay for rate limiting\n",
    "    if has_model_usage or has_tool_calls or is_agent_selection:\n",
    "        return API_CALL_DELAY_SECONDS\n",
    "    else:\n",
    "        return NON_API_EVENT_DELAY\n",
    "\n",
    "\n",
    "async def _save_team_state(task_text: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Save the current team conversation state to a timestamped JSON file.\n",
    "\n",
    "    Args:\n",
    "        task_text: The original task description for filename generation\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The saved filename if successful, None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate timestamped filename\n",
    "        timestamp = datetime.now()\n",
    "        date_time = timestamp.strftime(\"%Y%m%d_%H%M\")\n",
    "        task_name = _extract_task_name(task_text)\n",
    "        filename = f\"{date_time}_{task_name}_team_state.json\"\n",
    "\n",
    "        # Get conversation history from team\n",
    "        if hasattr(team, \"message_thread\") and team.message_thread:\n",
    "            # Convert messages to serializable format\n",
    "            messages = []\n",
    "            for msg in team.message_thread:\n",
    "                msg_dict = {\n",
    "                    \"source\": getattr(msg, \"source\", \"Unknown\"),\n",
    "                    \"content\": getattr(msg, \"content\", str(msg)),\n",
    "                    \"type\": type(msg).__name__,\n",
    "                    \"timestamp\": timestamp.isoformat(),\n",
    "                }\n",
    "                messages.append(msg_dict)\n",
    "\n",
    "            # Save state\n",
    "            state_data = {\n",
    "                \"task\": task_text,\n",
    "                \"timestamp\": timestamp.isoformat(),\n",
    "                \"messages\": messages,\n",
    "                \"token_stats\": get_token_stats(),\n",
    "                \"message_count\": len(messages),\n",
    "            }\n",
    "\n",
    "            # Write to file\n",
    "            filepath = Path(filename)\n",
    "            with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(state_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "            logger.info(f\"üíæ Team state saved: {filename}\")\n",
    "            return filename\n",
    "\n",
    "        else:\n",
    "            logger.warning(\"‚ö†Ô∏è No conversation history available to save\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to save team state: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def list_team_state_files() -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    List all available team state files in the current directory.\n",
    "\n",
    "    Returns:\n",
    "        List of dicts with file info: filename, timestamp, task_preview, size\n",
    "    \"\"\"\n",
    "    try:\n",
    "        state_files = []\n",
    "        current_dir = Path(\".\")\n",
    "\n",
    "        # Find all team state JSON files\n",
    "        for file_path in current_dir.glob(\"*_team_state.json\"):\n",
    "            try:\n",
    "                # Get file stats\n",
    "                stat = file_path.stat()\n",
    "\n",
    "                # Try to read basic info from file\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                file_info = {\n",
    "                    \"filename\": file_path.name,\n",
    "                    \"timestamp\": data.get(\"timestamp\", \"Unknown\"),\n",
    "                    \"task_preview\": (\n",
    "                        data.get(\"task\", \"\")[:100] + \"...\"\n",
    "                        if len(data.get(\"task\", \"\")) > 100\n",
    "                        else data.get(\"task\", \"\")\n",
    "                    ),\n",
    "                    \"message_count\": data.get(\"message_count\", 0),\n",
    "                    \"size_kb\": round(stat.st_size / 1024, 1),\n",
    "                    \"modified\": datetime.fromtimestamp(stat.st_mtime).strftime(\n",
    "                        \"%Y-%m-%d %H:%M\"\n",
    "                    ),\n",
    "                }\n",
    "                state_files.append(file_info)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Could not read state file {file_path.name}: {str(e)}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "        # Sort by timestamp (newest first)\n",
    "        state_files.sort(key=lambda x: x[\"timestamp\"], reverse=True)\n",
    "\n",
    "        logger.info(f\"üìã Found {len(state_files)} team state files\")\n",
    "        return state_files\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to list team state files: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "async def resume_from_saved_state(filename: Optional[str] = None) -> bool:\n",
    "    \"\"\"\n",
    "    Resume conversation from a saved team state file.\n",
    "\n",
    "    Args:\n",
    "        filename: Specific state file to resume from. If None, uses most recent.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if successfully resumed, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if filename is None:\n",
    "            # Find most recent state file\n",
    "            state_files = list_team_state_files()\n",
    "            if not state_files:\n",
    "                logger.warning(\"‚ö†Ô∏è No team state files found to resume from\")\n",
    "                return False\n",
    "            filename = state_files[0][\"filename\"]\n",
    "\n",
    "        # Load the state file\n",
    "        filepath = Path(filename)\n",
    "        if not filepath.exists():\n",
    "            logger.error(f\"‚ùå State file not found: {filename}\")\n",
    "            return False\n",
    "\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            state_data = json.load(f)\n",
    "\n",
    "        # Reset current token accounting\n",
    "        reset_token_accounting()\n",
    "\n",
    "        # Restore token stats if available\n",
    "        if \"token_stats\" in state_data:\n",
    "            global _token_accounting\n",
    "            _token_accounting.update(state_data[\"token_stats\"])\n",
    "\n",
    "        logger.info(f\"‚úÖ Successfully loaded state from {filename}\")\n",
    "        logger.info(f\"üìã Task: {state_data.get('task', 'Unknown')[:100]}...\")\n",
    "        logger.info(f\"üí¨ Messages: {state_data.get('message_count', 0)}\")\n",
    "        logger.info(f\"üîÑ Use run_task() to continue from where you left off\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to resume from state file {filename}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "async def safe_resume() -> bool:\n",
    "    \"\"\"\n",
    "    Safely resume from the most recent state file with error handling.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if resumed successfully, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return await resume_from_saved_state()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Safe resume failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def log_event_enhanced(event, event_count: int = 0):\n",
    "    \"\"\"\n",
    "    Enhanced agent-aware logging with centralized token accounting and API call tracking.\n",
    "\n",
    "    Args:\n",
    "        event: The event object from the team stream\n",
    "        event_count: Total number of events processed\n",
    "\n",
    "    Returns:\n",
    "        bool: True if this consumed tokens (measurable API usage), False otherwise\n",
    "    \"\"\"\n",
    "    global _token_accounting\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    event_id = getattr(event, \"id\", f\"event_{event_count}\")\n",
    "    event_type = getattr(event, \"type\", type(event).__name__)\n",
    "    consumed_tokens = False  # More accurate than \"is_llm_call\"\n",
    "\n",
    "    # Agent-specific emojis and formatting\n",
    "    agent_config = {\n",
    "        \"Planner\": {\"emoji\": \"üß≠\", \"role\": \"PLANNER\"},\n",
    "        \"Researcher\": {\"emoji\": \"üîç\", \"role\": \"RESEARCHER\"},\n",
    "        \"Critic\": {\"emoji\": \"‚öñÔ∏è\", \"role\": \"CRITIC\"},\n",
    "        \"Editor\": {\"emoji\": \"‚úçÔ∏è\", \"role\": \"EDITOR\"},\n",
    "    }\n",
    "\n",
    "    # Get agent info\n",
    "    source = getattr(event, \"source\", \"Unknown\")\n",
    "    config = agent_config.get(source, {\"emoji\": \"ü§ñ\", \"role\": \"UNKNOWN\"})\n",
    "\n",
    "    # CENTRALIZED TOKEN ACCOUNTING - only count once per unique event\n",
    "    current_prompt = 0\n",
    "    current_completion = 0\n",
    "    current_total = 0\n",
    "\n",
    "    if (\n",
    "        hasattr(event, \"models_usage\")\n",
    "        and event.models_usage\n",
    "        and event_id not in _token_accounting[\"processed_event_ids\"]\n",
    "    ):\n",
    "        current_prompt = event.models_usage.prompt_tokens\n",
    "        current_completion = event.models_usage.completion_tokens\n",
    "        current_total = current_prompt + current_completion\n",
    "\n",
    "        # Update global running totals ONLY for new events\n",
    "        _token_accounting[\"total_prompt_tokens\"] += current_prompt\n",
    "        _token_accounting[\"total_completion_tokens\"] += current_completion\n",
    "        _token_accounting[\"total_tokens\"] += current_total\n",
    "\n",
    "        # Mark this event as processed\n",
    "        _token_accounting[\"processed_event_ids\"].add(event_id)\n",
    "\n",
    "        # This consumed measurable tokens\n",
    "        _token_accounting[\"llm_call_count\"] += 1\n",
    "        consumed_tokens = True\n",
    "\n",
    "        logger.debug(\n",
    "            f\"üí∞ Token accounting: Event {event_id} - prompt:{current_prompt}, completion:{current_completion}, total:{current_total}\"\n",
    "        )\n",
    "\n",
    "    # Determine event classification for logging\n",
    "    has_tool_calls = hasattr(event, \"tool_calls\") and event.tool_calls\n",
    "    is_agent_selection = (\n",
    "        \"select\" in event_type.lower() or \"speaker\" in event_type.lower()\n",
    "    )\n",
    "\n",
    "    # Better event classification\n",
    "    if consumed_tokens:\n",
    "        call_info = f\"Token-Consuming Calls #{_token_accounting['llm_call_count']}\"\n",
    "    elif has_tool_calls:\n",
    "        call_info = \"Tool Execution\"\n",
    "    elif is_agent_selection:\n",
    "        call_info = \"Agent Selection Logic\"\n",
    "    else:\n",
    "        call_info = \"Internal Processing\"\n",
    "\n",
    "    line1 = f\"Agent: {config['emoji']} {config['role']} | Type: {event_type} | {call_info} | Total Events: #{event_count}\"\n",
    "    line2 = \"\"  # Reserved for future functional info\n",
    "\n",
    "    if consumed_tokens and current_total > 0:\n",
    "        # Show current event tokens + running totals for token-consuming calls\n",
    "        line3 = f\"Tokens: Current[prompt:{current_prompt}, completion:{current_completion}, total:{current_total}] ‚Üí Running Total: {_token_accounting['total_tokens']}\"\n",
    "    elif current_total > 0:\n",
    "        # Edge case: has tokens but not marked as token-consuming calls (investigation needed)\n",
    "        line3 = f\"‚ö†Ô∏è Tokens: {current_total} (has tokens but not marked as token-consuming) ‚Üí Running Total: {_token_accounting['total_tokens']}\"\n",
    "    else:\n",
    "        # No tokens for this event (normal for non-token-consuming events) - but show running total\n",
    "        line3 = f\"Tokens: 0 (no new tokens) ‚Üí Running Total: {_token_accounting['total_tokens']}\"\n",
    "\n",
    "    line4 = f\"Timestamp: {timestamp} | Event ID: {event_id}\"\n",
    "\n",
    "    # Format the log output with enhanced visual structure\n",
    "    separator_line = \"‚îÅ\" * 80\n",
    "    content_preview = str(getattr(event, \"content\", str(event)))\n",
    "\n",
    "    logger.info(\n",
    "        f\"\"\"\n",
    "{separator_line}\n",
    "Event:{event}\n",
    "{separator_line}\n",
    "{line1}\n",
    "{line2}\n",
    "{line3}\n",
    "{line4}\n",
    "{separator_line}\n",
    "{content_preview}\n",
    "{separator_line}\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    return consumed_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SYSTEM PROMPTS\n",
    "\n",
    "### References\n",
    "# https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\n",
    "# https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/prompt-engineering-for-openai%E2%80%99s-o1-and-o3-mini-reasoning-models/4374010\n",
    "# https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf\n",
    "today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "PLANNER_SYSTEM_PROMPT = dedent(\n",
    "    f\"\"\"Strategic Research Planner. Convert user queries into executable research specifications. Today is {today_str}.\n",
    "\n",
    "CORE FUNCTION: Evaluate planning approaches and select the best research strategy.\n",
    "- Analyze user query for multiple possible research approaches\n",
    "- Identify the optimal research approach for the query, Consult Critic if needed\n",
    "- Structure the chosen approach into executable research questions\n",
    "- Set Scope and temporal boundaries for the research process\n",
    "- PLANNING ONLY: No research execution or evidence assessment\n",
    "\n",
    "PLAN TEMPLATE: Produce a methodical plan focusing on clear, practical steps.\n",
    "## Identify Key Objectives: \n",
    " - Clarify what questions each option aims to answer\n",
    " - Detail the data/info needed for evaluation\n",
    "## Specifies Expected Outcomes  \n",
    " - Possible findings or results  \n",
    "## Provide Evaluation Criteria\n",
    " - Metrics, benchmarks, or qualitative factors to compare options  \n",
    " - Criteria for success or viability  \n",
    "\n",
    "OUTPUT SIGNALS:\n",
    "- \"PLAN_CREATED ‚Üí @Critic\" (initial)\n",
    "- \"PLAN_REVISED ‚Üí @Critic\" (after revision)  \n",
    "- \"PLAN_APPROVED\" (ONLY after CRITIC \"APPROVED\")\n",
    "- \"PLAN_ABANDONED: [reason]\" (after 5 attempts)\n",
    "\n",
    "RESPONSE PROTOCOLS:\n",
    "- After CRITIC \"APPROVED: [...]\" ‚Üí Immediately respond with \"PLAN_APPROVED\"\n",
    "- After CRITIC \"REJECTED: [...]\" ‚Üí Revise plan ‚Üí \"PLAN_REVISED ‚Üí @Critic\"\n",
    "- Never declare \"PLAN_APPROVED\" without explicit CRITIC approval\n",
    "- Count revision attempts (max 5 before \"PLAN_ABANDONED\")\n",
    "\n",
    "COMPLETION SIGNALS:\n",
    "- MUST wait for CRITIC approval signal before proceeding\n",
    "- MUST declare \"PLAN_APPROVED\" to enable Researcher handoff\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "RESEARCHER_SYSTEM_PROMPT = dedent(\n",
    "    f\"\"\"Senior Research Analyst. Execute targeted research using wiki_search and web_research tools with strict resource management. Today is {today_str}.\n",
    "\n",
    "CORE FUNCTION:\n",
    "- Execute research questions, gather evidence meeting specified thresholds\n",
    "- Gather evidence, respecting the specified source thresholds and search heuristics.\n",
    "\n",
    "SIMPLIFIED TOOL DECISION TREE:\n",
    "- HISTORICAL/DEFINITION/ESTABLISHED FACT ‚Üí wiki_search only\n",
    "   Example: \"What is\", \"History of\", \"Definition\", \"Background of\"\n",
    "- CURRENT DATA/RECENT TRENDS/MARKET DATA/NEWS ‚Üí web_research (comprehensive search + content fetching)\n",
    "   Example: Contains \"2024\", \"2025\", \"current\", \"latest\", \"recent\", \"market\", \"stock price\", \"financial\"\n",
    "\n",
    "TOOL DETAILS:\n",
    "- wiki_search: Returns Wikipedia summaries for established facts and background\n",
    "- web_research: Performs complete workflow (web search + fetches top 3 URLs with full content). \n",
    "\n",
    "SEARCH HEURISTICS:\n",
    "- Include year for current topics: \"AI adoption 2025\"\n",
    "- Geographic specificity: \"EV sales Europe 2025\"\n",
    "- For contested topics, prioritize diverse source perspectives over source volume\n",
    "- Avoid paid sources, PDF, CSV, and other non-HTML content\n",
    "- Source priority: Primary > Institutional > Peer-reviewed > News\n",
    "\n",
    "EFFICIENCY RULES:\n",
    "- SUFFICIENT_EVIDENCE: Stop when confidence threshold reached\n",
    "- DIMINISHING_RETURNS: Automatically terminate if <20% new info across 2 searches\n",
    "- CIRCULAR_DETECTION: Automatically terminate if 3+ searches share >70% term overlap.\n",
    "- QUALITY_OVER_QUANTITY: 3 high-quality sources > 10 weak sources\n",
    "\n",
    "OUTPUT:\n",
    "- Group findings by research theme\n",
    "- Include source URLs and publication dates\n",
    "- Flag incomplete evidence areas\n",
    "- NO quality assessment (EDITOR's role)\n",
    "\n",
    "COMPLETION SIGNALS:\n",
    "- Evidence thresholds met ‚Üí \"RESEARCH_COMPLETE ‚Üí @Critic\"\n",
    "- RESEARCH_APPROVED (after critic approval)\n",
    "- Data inaccessible ‚Üí \"RESEARCH_BLOCKED: [reason]\"\n",
    "- DIMINISHING_RETURNS (new info threshold not met)\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "CRITIC_SYSTEM_PROMPT = dedent(\n",
    "    f\"\"\"Domain-agnostic Quality Assurance Expert. Systematic evaluation of research deliverables before stakeholder handoff. Today is {today_str}.\n",
    "\n",
    "CORE FUNCTION:\n",
    "- PLAN_REVIEW: Assess feasibility, scope clarity, domain expertise, tool alignment, temporal boundaries, success metrics.\n",
    "- RESEARCH_REVIEW: Check completeness, clarity, strategic value, temporal accuracy.\n",
    "- FINAL_REPORT_REVIEW: Evaluate actionability, clarity, and stakeholder value.\n",
    "\n",
    "QUALITY THRESHOLDS:\n",
    "Apply context-appropriate rigor - preliminary plans need different depth than final strategic recommendations. Balance thoroughness with practical constraints.\n",
    "- HIGH: Multiple credible sources, robust methodology\n",
    "- MEDIUM: Single credible source or minor limitations\n",
    "- LOW: Preliminary evidence or significant gaps\n",
    "- INSUFFICIENT: Below minimum threshold for meaningful analysis\n",
    "\n",
    "OUTPUT SIGNALS:\n",
    "- \"APPROVED: [key strengths that justify approval]\"\n",
    "- \"NEEDS_REFINEMENT: [primary issues] ‚Üí [suggested improvements]\"\n",
    "- \"MAJOR_GAPS: [critical deficiencies] ‚Üí [required additions]\"\n",
    "\n",
    "OPERATIONAL BOUNDARIES:\n",
    "- MAX_RESPONSE: 300 words\n",
    "- NO_RESEARCH: Quality assessment only\n",
    "- REVIEW_ONLY: No unsolicited feedback\"\"\"\n",
    ")\n",
    "\n",
    "EDITOR_SYSTEM_PROMPT = dedent(\n",
    "    f\"\"\"Senior Strategy Consultant. Transform research into executive-ready reports. Today is {today_str}.\n",
    "\n",
    "**MISSION**: Create actionable business intelligence for C-suite decision-makers.\n",
    "\n",
    "**WRITING APPROACH**: Write like a seasoned consultant - weave evidence strength naturally into your analysis. Strong data gets assertive language, limited data gets qualified language.\n",
    "\n",
    "**EVIDENCE LANGUAGE**:\n",
    "- Strong evidence: \"Our analysis demonstrates...\", \"Data consistently show...\", \"Evidence confirms...\"\n",
    "- Moderate evidence: \"Available data suggest...\", \"Analysis indicates...\", \"Current evidence points to...\"\n",
    "- Limited evidence: \"Preliminary findings suggest...\", \"Early indicators point to...\", \"Initial analysis suggests...\"\n",
    "\n",
    "**STRUCTURE** (adapt based on content):\n",
    "```\n",
    "# [Strategic Title - Business Impact]\n",
    "\n",
    "## Executive Summary\n",
    "**Key Finding**: [Insight with natural evidence qualifier]\n",
    "**Business Impact**: [Revenue/risk/opportunity] \n",
    "**Recommended Action**: [Specific next steps]\n",
    "\n",
    "## Strategic Analysis\n",
    "[Core findings - evidence strength flows naturally in narrative]\n",
    "\n",
    "### Market Dynamics / Competitive Position / Implementation Strategy\n",
    "[Use relevant sections - uncertainty woven into analysis naturally]\n",
    "\n",
    "## Recommendations  \n",
    "### Immediate (0-6 months) / Strategic (6-18 months)\n",
    "\n",
    "## Key Uncertainties & Next Steps\n",
    "[Natural discussion of data gaps and mitigation approaches]\n",
    "\n",
    "---\n",
    "**Sources**: [With publication dates]\n",
    "```\n",
    "\n",
    "**LANGUAGE**: Business-focused with natural evidence qualifiers. Every strategic claim includes source attribution and organic uncertainty assessment.\n",
    "\n",
    "**COMPLETION TRIGGERS**: Generate report ‚Üí save_report() ‚Üí \"REPORT_SAVED. TASK_COMPLETE. TERMINATE\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGENT SETUP\n",
    "\n",
    "\n",
    "planner = AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    model_client=gemini_model_client,\n",
    "    system_message=PLANNER_SYSTEM_PROMPT,\n",
    "    description=\"Creates and adapts research plans, handles replanning when research hits obstacles\",\n",
    ")\n",
    "\n",
    "researcher = AssistantAgent(\n",
    "    name=\"Researcher\",\n",
    "    description=\"Expert research agent that strategically uses wiki_search and web_research tools to gather comprehensive and factual evidence.\",\n",
    "    model_client=gemini_model_client,\n",
    "    tools=[wiki_search_tool, web_research_tool],\n",
    "    max_tool_iterations=1,\n",
    "    reflect_on_tool_use=True,\n",
    "    system_message=RESEARCHER_SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "critic = AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    model_client=gemini_model_client,\n",
    "    system_message=CRITIC_SYSTEM_PROMPT,\n",
    "    description=\"Reviews and provides constructive criticism; outputs 'APPROVED: [...]' when ready.\",\n",
    ")\n",
    "\n",
    "\n",
    "editor = AssistantAgent(\n",
    "    name=\"Editor\",\n",
    "    description=\"Formats approved drafts with proper citations, adapts structure to content type.\",\n",
    "    model_client=gemini_model_client,\n",
    "    tools=[save_report_tool],\n",
    "    system_message=EDITOR_SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "__SELECTOR_PROMPT = \"\"\"Smart agent selector with task progression awareness.\n",
    "\n",
    "AGENT CAPABILITIES:\n",
    "{roles}\n",
    "\n",
    "Available agents: \n",
    "{participants}\n",
    "\n",
    "Conversation history: \n",
    "{history}\n",
    "\n",
    "QUALITY CONTROL FLOW:\n",
    "1. Query ‚Üí Planner (creates plan)\n",
    "2. Plan ‚Üí Critic (feasibility review) \n",
    "3. Approved Plan ‚Üí Researcher (execution)\n",
    "4. Research ‚Üí Critic (quality review)\n",
    "5. Approved Research ‚Üí Editor (final report)\n",
    "\n",
    "ROUTING LOGIC:\n",
    "- No plan ‚Üí Planner\n",
    "- \"PLAN_CREATED\" or \"PLAN_REVISED\" ‚Üí Critic\n",
    "- \"PLAN_APPROVED\" ‚Üí Researcher\n",
    "- Research complete ‚Üí Critic\n",
    "- \"RESEARCH_APPROVED\" ‚Üí Editor\n",
    "- \"REPORT_SAVED\" ‚Üí TERMINATE\n",
    "\n",
    "QUALITY GATES: All plans and research require CRITIC approval\n",
    "\n",
    "Return only the next agent name.\"\"\"\n",
    "\n",
    "\n",
    "# Team configuration with constants\n",
    "max_messages = TASK_TERMINATION_MAX_MESSAGES\n",
    "txt_termination = TextMentionTermination(\"TERMINATE\")\n",
    "termination_condition = (\n",
    "    MaxMessageTermination(max_messages=max_messages) | txt_termination\n",
    ")\n",
    "\n",
    "# Build SelectorGroupChat\n",
    "\n",
    "model_context = BufferedChatCompletionContext(buffer_size=CONVERSATION_BUFFER_SIZE)\n",
    "\n",
    "team = SelectorGroupChat(\n",
    "    name=\"Deep Research Team\",\n",
    "    description=\"A team of specialized agents working together to conduct deep research.\",\n",
    "    model_context=model_context,\n",
    "    participants=[planner, researcher, critic, editor],\n",
    "    model_client=gemini_model_client,\n",
    "    selector_prompt=__SELECTOR_PROMPT,\n",
    "    termination_condition=termination_condition,\n",
    "    emit_team_events=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETUP TASK RUN\n",
    "\n",
    "\n",
    "# @tenacity.retry(\n",
    "#     wait=tenacity.wait_exponential(multiplier=1, min=60, max=120),\n",
    "#     stop=tenacity.stop_after_attempt(2),\n",
    "#     retry=tenacity.retry_if_exception_type(Exception),\n",
    "# )\n",
    "async def run_task(task_text: str):\n",
    "    \"\"\"\n",
    "    Execute a multi-agent research task with robust termination handling.\n",
    "\n",
    "    All token accounting is handled by log_event_enhanced().\n",
    "    Uses determine_event_delay() utility for clean delay logic.\n",
    "\n",
    "    Args:\n",
    "        task_text (str): The research task description\n",
    "\n",
    "    Returns:\n",
    "        str | None: Final report content or None if task incomplete\n",
    "    \"\"\"\n",
    "    final_report = None\n",
    "    task_completed = False\n",
    "\n",
    "    # Simple local variables\n",
    "    event_count = 0\n",
    "    tool_call_count = 0\n",
    "\n",
    "    # Reset token accounting for new task\n",
    "    reset_token_accounting()\n",
    "\n",
    "    # Streamlined termination signals - agents handle termination explicitly\n",
    "    termination_signals = [\n",
    "        \"TERMINATE\",\n",
    "        \"REPORT_SAVED\",\n",
    "        \"TASK_COMPLETE\",\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"üöÄ Starting task: {task_text}\\n\\n\")\n",
    "\n",
    "        async for event in team.run_stream(task=task_text):\n",
    "\n",
    "            # Increment total event counter\n",
    "            event_count += 1\n",
    "\n",
    "            # Centralized logging with token accounting - returns if this consumed tokens\n",
    "            consumed_tokens = log_event_enhanced(event, event_count)\n",
    "\n",
    "            # Track tool calls for statistics only\n",
    "            if hasattr(event, \"tool_calls\") and event.tool_calls:\n",
    "                tool_call_count += len(event.tool_calls)\n",
    "\n",
    "            # Check for termination signals in message content\n",
    "            if hasattr(event, \"content\") and isinstance(event.content, str):\n",
    "                content_upper = event.content.upper()\n",
    "\n",
    "                # Check for any termination signal\n",
    "                for signal in termination_signals:\n",
    "                    if signal.upper() in content_upper:\n",
    "                        final_report = event.content.split(signal, 1)[0].strip()\n",
    "                        task_completed = True\n",
    "\n",
    "                        # Get final stats from token accounting\n",
    "                        stats = get_token_stats()\n",
    "                        logger.info(\n",
    "                            f\"\\n\\n‚úÖ Task completed with '{signal}' signal after {event_count} total events ({stats['llm_call_count']} token-consuming calls)\"\n",
    "                        )\n",
    "                        logger.info(\n",
    "                            f\"üìä Final Token Usage - Total: {stats['total_tokens']} (prompt: {stats['total_prompt_tokens']}, completion: {stats['total_completion_tokens']})\"\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                if task_completed:\n",
    "                    break\n",
    "\n",
    "            # Apply simplified delay logic using utility function\n",
    "            delay = determine_event_delay(event, event_count)\n",
    "\n",
    "            if delay == API_CALL_DELAY_SECONDS:\n",
    "                stats = get_token_stats()\n",
    "                logger.info(\n",
    "                    f\"\\n\\n‚è≥ API-bound operation detected (event #{event_count}), waiting {delay} seconds. (Token-consuming calls: {stats['llm_call_count']})\\n\\n\"\n",
    "                )\n",
    "            else:\n",
    "                logger.debug(\n",
    "                    f\"\\n\\nüí® Internal processing event #{event_count}, brief pause ({delay}s)\\n\\n\"\n",
    "                )\n",
    "\n",
    "            await asyncio.sleep(delay)\n",
    "\n",
    "        # Log final totals and statistics\n",
    "        if not task_completed:\n",
    "            stats = get_token_stats()\n",
    "            logger.warning(\n",
    "                f\"‚ö†Ô∏è Task reached end of stream without clear termination after {event_count} events ({stats['llm_call_count']} token-consuming calls)\"\n",
    "            )\n",
    "\n",
    "        # Final statistics logging\n",
    "        stats = get_token_stats()\n",
    "        logger.info(\n",
    "            f\"\"\"\n",
    "üìä TASK COMPLETION STATISTICS:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "‚úÖ Task Completed: {task_completed}\n",
    "üî¢ Total Events: {event_count}\n",
    "ü§ñ Token-Consuming API Calls: {stats['llm_call_count']}\n",
    "üîß Tool Calls: {tool_call_count}\n",
    "üí∞ Tokens Used: {stats['total_tokens']} (prompt: {stats['total_prompt_tokens']}, completion: {stats['total_completion_tokens']})\n",
    "üîÑ Processed Unique Events: {len(stats['processed_event_ids'])}\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "        return final_report if task_completed else None\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"\\n\\n‚ùå Exception during task execution: {e}\")\n",
    "        stats = get_token_stats()\n",
    "        logger.info(\n",
    "            f\"üìä Error at Event #{event_count} (Token-consuming calls: {stats['llm_call_count']}), Token Usage: {stats['total_tokens']} (prompt: {stats['total_prompt_tokens']}, completion: {stats['total_completion_tokens']})\"\n",
    "        )\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        await _save_team_state(task_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb513d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN TASK\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    __SAMPLE_QUERY = [\n",
    "        \"Indian steel sector growth post modernization and growth prospects in an era of US tariffs and reduce government protection through trade barriers and cheaper import options from China\",\n",
    "        \"How government and governance factors improved economy and lives of indians during Modi and Pre-Modi starting from 1991\",\n",
    "        \"Sectoral growth based on cyclics for 2025 and macro economic pressure and trade tariffs and uncertainty, which sectors are best poised for maximum investment returns in terms of % for the next year for a moderate to average risk profile investments\",\n",
    "        \"Hyperscaler investments in data centers and cloud infrastructure for AI growth is not matching the proposed productivity gains in GDP. Are we witnessing a bubble? Is % of global GDP being invested in AI infrastructure matches the productivity gain percentages?\",\n",
    "        \"If neural networks are foundation of LLMs and based on the human brain; Are LLMs given tools during training? Humans learn with tool usage, What are current trends on tool usage in LLM training?\",\n",
    "        f\"Today is {today_str}. Analyze stock price performance of Nvidia in the past month, compare it with top 3 listed POWER Producers in India.\",\n",
    "        \"Evaluating the long-term viability of green hydrogen as a baseload power source in India given current electrolyzer costs, renewable energy tariffs, grid stability constraints, and projected policy support through 2035\",\n",
    "        \"Assessing whether India‚Äôs 2025-30 urban housing shortage can be resolved through large-scale 3D-printed construction without triggering systemic risk in NBFC and banking balance sheets exposed to real estate credit\",\n",
    "        \"Quantifying the impact of EU CBAM (Carbon Border Adjustment Mechanism) on India‚Äôs MSME-dominated textile export clusters in Tiruppur and Surat, including cascading effects on informal employment and regional GDP\",\n",
    "        \"Mapping supply-chain chokepoints for critical rare-earth elements (Neodymium, Dysprosium) essential for India‚Äôs EV and renewable energy targets, and evaluating geopolitical fallback strategies if China restricts exports\",\n",
    "        \"Determining whether India‚Äôs Unified Payments Interface (UPI) can scale to serve as the backbone for a sovereign digital currency (CBDC) while preserving offline transaction capability and financial inclusion in rural hinterlands\",\n",
    "        \"Analyzing if the projected 2025-30 growth in India‚Äôs domestic semiconductor consumption can justify the capital intensity of new fabs without sustained government subsidies and tax incentives that crowd out social-sector spending\",\n",
    "        \"Investigating whether India‚Äôs demographic dividend can offset the fiscal drag from rising health-care costs driven by lifestyle diseases, by modeling the combined effect of PM-JAY coverage expansion and private insurance penetration\",\n",
    "        \"Examining the systemic risk posed to Indian mutual funds and pension portfolios from concentrated exposure to Adani Group entities under evolving ESG disclosure norms and potential climate-litigation scenarios\",\n",
    "        \"Evaluating the comparative efficiency of India‚Äôs inland waterways versus dedicated freight corridors in reducing logistics costs for bulk commodities, while accounting for seasonal monsoon disruptions and inter-state regulatory friction\",\n",
    "        \"Determining if open-source foundation-model ecosystems (e.g., BLOOM, LLaMA derivatives) can reduce India‚Äôs reliance on proprietary LLM APIs, and measuring the incremental TCO of sovereign GPU clusters versus foreign cloud dependency\",\n",
    "    ]\n",
    "    try:\n",
    "\n",
    "        output = asyncio.run(run_task(random.choice(__SAMPLE_QUERY)))\n",
    "        if output:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"üéØ FINAL REPORT\")\n",
    "            print(\"=\" * 60)\n",
    "            print(output)\n",
    "        else:\n",
    "            print(\"‚ùå Task did not complete successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Fatal error: {e}\")\n",
    "        print(f\"‚ùå Execution failed: {e}\")\n",
    "\n",
    "    # Uncomment to test:\n",
    "    # file_info = list_team_state_files()\n",
    "    # await resume_from_saved_state(\"20250824_1430_green_hydrogen_viability_team_state.json\")\n",
    "    # await safe_resume()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cf96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEAM STATE MANAGEMENT EXAMPLES\n",
    "\n",
    "# Example: List all available team state files\n",
    "print(\"üìã Available Team State Files:\")\n",
    "print(\"=\" * 50)\n",
    "file_info = list_team_state_files()\n",
    "\n",
    "if file_info:\n",
    "    for info in file_info:\n",
    "        print(f\"üìÑ {info['filename']}\")\n",
    "        print(f\"   üìÖ Created: {info['timestamp']}\")\n",
    "        print(f\"   üí¨ Messages: {info['message_count']}\")\n",
    "        print(f\"   üìù Task: {info['task_preview']}\")\n",
    "        print(f\"   üíæ Size: {info['size_kb']} KB\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No team state files found.\")\n",
    "\n",
    "print(\"\\nüîÑ Resume Functions Available:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚Ä¢ await resume_from_saved_state() - Resume from most recent state file\")\n",
    "print(\"‚Ä¢ await resume_from_saved_state('filename.json') - Resume from specific file\")\n",
    "print(\"‚Ä¢ await safe_resume() - Resume with error handling\")\n",
    "\n",
    "# Example usage (commented out - uncomment to use):\n",
    "# await resume_from_saved_state()  # Resume from most recent\n",
    "# await resume_from_saved_state(\"20250824_1430_green_hydrogen_viability_team_state.json\")  # Specific file\n",
    "# await safe_resume()  # Safe resume with error handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ef532",
   "metadata": {},
   "source": [
    "> **Note:** All values are approximate and reflect estimates as of **August 2025**. Word, token, sentence, and character counts can vary by writing style and tokenization method.\n",
    "\n",
    "- Tokens calculated as `words √∑ 0.75`.\n",
    "- Sentences calculated as `words √∑ 15‚Äì20`.\n",
    "- Characters calculated as `words √ó 4‚Äì5`.\n",
    "\n",
    "| Article Type / Measure         | Approx Words | Approx Sentences | Approx Tokens | Approx Characters | Notes                               | Suggested Summary (Tokens / Chars)     |\n",
    "| ------------------------------ | ------------ | ---------------- | ------------- | ----------------- | ----------------------------------- | -------------------------------------- |\n",
    "| Short text (60 tokens)         | ~45          | ~2‚Äì3             | ~60           | ~180‚Äì225          | Short paragraph / social media post | ~10 tokens / ~40‚Äì50 chars              |\n",
    "| Blog article                   | 1,000‚Äì1,800  | ~50‚Äì120          | ~1,300‚Äì2,400  | ~4,000‚Äì9,000      | Typical online blog length          | ~150‚Äì360 tokens / ~400‚Äì900 chars       |\n",
    "| NYT Op-Ed                      | 800‚Äì1,200    | ~40‚Äì80           | ~1,050‚Äì1,600  | ~3,200‚Äì6,000      | Opinion/editorial piece             | ~100‚Äì240 tokens / ~320‚Äì600 chars       |\n",
    "| Research article (web/journal) | 3,000‚Äì7,000  | ~150‚Äì470         | ~4,000‚Äì9,300  | ~12,000‚Äì35,000    | Standard journal or web publication | ~400‚Äì1,400 tokens / ~1,200‚Äì3,500 chars |\n",
    "| arXiv preprint                 | 6,000‚Äì12,000 | ~300‚Äì800         | ~8,000‚Äì16,000 | ~24,000‚Äì60,000    | Preprint scientific paper           | ~800‚Äì1,600 tokens / ~2,400‚Äì6,000 chars |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
